>>>>>>>>>>>>>>>>>>>>>> Осовский С. Нейронные сети для обработки информации (2004).djvu >>>>>>>>>>>>>>>>>>>>>> 

СТАНИСЛАВ осовский

нвйгонньп сии
для ОБРАБОТКИ

ЗТЗЬАИ! И!

8|ЕС| МЕНКОМОШЕ
во РК2ЕТШАК2АМ|А
нчгокмдсзп

НЕЙРОННЬ|Е СЕТИ
для ОБРАБОТКИ
ИНФОРМАЦИИ

И ‚Д. Рудинског

УДК 004113226
ББК 32.813
0-75

РЕЦЕНЗЕН Т
доктор технических наук
И.Б. Фоминых

Осовский С.
0-75 Нейронные сети для обработки информации / Пер. с польского
И.Д. Рудинского. — М.: Финансы и статистика, 2002. — 344 с.: ил.

1$ВЪ1 5-279-02567-4

Представлены важнейшие разделы теории искусственных нейронных сетей. Основ-
ное внимание уделяется алгоритмам обучения и их применению для обработки измери-
тельной информации. Дается детальный обзор и описание важнейших методов обучения
сетей различной структуры, шшюстрируемые численными экспериментами с практически
подтверждеиными результатами.

Для аспирантов и иаучиых работников, интересующихся методами искусственного
интеллекта. Может быть полезна специалистам в области информатики, статистики, физи-
ки и технических дисциплин, а также специалистам биомедицииских отраслей знаний.

О   256_ 2002 УДК 004.0з2.2в
щщщ) — 1001 ББК 32.8113
1$ВЫ 83_72О7_187_Х (Польша) © Соругйфп Ьу Ойсупа ЧУуоашпйсга РОЩесМИсЕ

Щахзхашзкйе], 2000
1$ВЫ 5-279-02567-4 (Россия)

© Перевод на русский язык,
предисловие к русскому изданию, оформление.
Издательство "Финансы и статистика”, 2002

Содержание

К читателю

Предисловие к русскому издаиию

Предисловие

1. ВВЕДЕНИЕ

1.1.
1.2.
1.3.

Биологические основы функционирования нейрона . . . . . . . . . . . . . . . . . . . . . .
Первые модели нейронной сети . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Прикладные возможности нейронных сетей . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2. МОДЕЛИ НЕЙРОНОВ И МЕТОДЫ ИХ ОБУЧЕНИЯ

2.1. Персептрон . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2. Сигмоидальный нейрон . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.3. Нейрон типа “адалайн” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4. Инстар и оутстар Гроссберга . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.5. Нейроны типа ЩТА . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . 1 . . . . . . . . . . . . . . . . .

2.6. Модель нейрона Хебба . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.7. Стохастическая модель нейрона . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3. ОДНОНАПРАВЛЕННЫЕ МНОГОСЛОЙНЫЕ СЕТИ

СИГМОИДАЛЬНОГО ТИПА

3.1. Однослойная сеть . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.2. Многослойный персептрон . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.2.1. Структура персептронной сети . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.2.2. Ашоритм обратного распространения ошибки . . . . . . . . . . . . . . . . . . . .

3.3. Потоковые графы и их применение для генерации градиента . . . . . . . . . . . . . . .

3.4. Градиентные алгоритмы обучения сети . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.4.1. Основные положения . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.4.2. Алгоритм наискорейшего спуска . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.4.3. Алгоритм переменной метрики . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.4.4. Алгоритм Левенберга-Марквардта . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.4.5. Алгоритм сопряженных градиентов . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.5. Подбор коэффициента обучения . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.6. Эвристические методы обучения сети . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.6.1. Алгоритм Оийскргор . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . „ . . . . . . . .

3.6.2. Алгоритм КРКОР . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.7. Сравнение эффективности алгоритмов обучения . . . . . . . . . . . . . . . . . . . . . . . . .

3.8. Элементы глобальной оптимизации . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.8.1. Алгоритм имитации отжш-а . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.8.2. Генетические алгоритмы . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.9. Методы инициализации весов . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

16

17

1 9
20
22

25

26
27
32
34
37
40

46

47
50
50
5 1
55
60
60
62
63
65
67
68
71
71
73
73
75
78
81
86

6 Содержание

 

4. ПРОБЛЕМЫ ПРАКТИЧЕСКОГО ИСПОЛЬЗОВАНИЯ

ИСКУССТВЕННЫХ НЕЙРОННЫХ СЕТЕЙ 89
4.1. Предварительный подбор архитектуры сети . . . . . . . . . . . . . . . . . . . . . . . . . ‚ . . . 89

4.2. Подбор оптимальной архитектуры сети . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92

4.2. 1. Способность к обобщению . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92

4.2.2. Методы редукции сети с учетом чувствительности . . . . . . . . . . . . . . . . . 98

4.2.3. Методы редукции сети с использованием штрафной функции . . . . . . . . 103

4.3. Методы наращивания сети . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105

4.4. Подбор обучающих выборок . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105

4.5. Добавление шума в обучающие вьтборки . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

4.6. Прнмеры использования персептроиной сети . . . . . . . . . . . . . ‚ . . . . . . . . . . . . . 1 10

4.6.1. Распознавание и классификация образов . . . . . . . . . . . . . . . . . . . . . . . . . 1 10

4.6.2. Нейронная сеть для сжатия данных . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 16

4.6.3. Идентификация динамических объектов . . ‚ . . . . . . . . . . . . . . . . . . . . . . . 121

4.6.4. Прогнозирование нагрузок энергетической системы . . . . . . . . . . . . . . . . 124
5. РАДИАЛЬНЫЕ нвйгонньтв стати 129
5.1. Математические основы . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
5.2. Радиальная нейронная сеть . . . . . . . . . . . . . . . . . ‚ . . . . . . . . . . . . . . . . . . . . . . . . . 132
5.3. Методы обучения радиальных нейронных сетей . . . . . . . . . . . . . . . . . . . . . . . ‚ . . 137
5.3.1. Применение процесса самоорганизации для уточнения параметров
радиальных функций . . . . . . . . . . . . . . . . ‚ . . . . . . . . . . . . . . . . . . . ‚ . . . . . 139
5.3.2. Вероятностиый алгоритм подбора параметров радиальных
функций . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ‚ . . . . . . . . . . . . ‚ . . . 142
5.3.3. Гибридньтй алгоритм обучения радиальных сетей . . . . . . . . . . . . . . . . . 144
5.3.4. Алгоритмы обучения, основанные иа обратном распространении
ошибки . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146

5.4. Пример использования радиальной сети . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149

5.5. Методы подбора количества базисных функций . . . . . . . . . . . . . . . . . . . . . . . . . 151

5.5.1. Эврнстические методы . . . ‚ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151

5.5.2. Метод ортогонализации Г рэма-Шмидта . . . . . . . . . . . . . . . . . . . . . . . . . . 152

5.6. Сравнение радиальных и сигмоидальных сетей . . . . . . . . . . . . . . . . . . . . . . . . . . 157
6. СПЕЦИАЛИЗИРОВАННЫЕ СТРУКТУРЫ НЕЙРОННЫХ СЕТЕЙ 159
6. 1. Сеть каскадной корреляции Фальмана . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
6.2. Сеть Вольтерри . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
6.2.1. Структура и особенности обучения сети . . . . . . . . . . . . . . . . . . . . . . . . . 166
6.2.2. Примеры использования сети Вольтерри . . . . . . . . . . . . . . . . . . . . . . . . . 169

7. РЕКУРРЕНТНЫЕ СЕТИ КАК АССОЦИАТИВНЫЕ ЗАПОМИНАЮЩИЕ
УСТРОЙСТВА 176
7.1. Введение . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176

7.2. Автоассоциативная сеть Хопфилда . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178

7.2.1. Основные зависимости . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178

7.2.2. Режим обучения сети Хопфилда . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180

7.2.3. Режим распознавания сети Хопфилда . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182

7.3. СетьХемьтит-ца . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184

7.4. Сеть типа ВАМ . . . . . . . . . . . . . . . . . . . . ‚ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189

7.4.1. Описание процесса функционирования сети . . . . . . . . . . . . . . . . . . . . . . 189

7.4.2. Модифицированный алгоритм обучения сети ВАМ ‚ . . . . . . . . . . . . . . . 191

7.4.3. Модифицированная структура сети ВАМ . . . . . . . . . . . . . . . . . . . . . . . . . 192

Содержание 7

 

8. РЕКУРРЕНТНЫЕ СЕТИ НА БАЗЕ ПЕРСЕПТРОНА 200
8.1. Введение . . . . . . . . . . . . . . . . . . . . . . . ‚ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200

8.2. Персетгтронная сеть с обратной связью . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200

8.2.1. Структура сети КМЬР . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200

8.2.2. Ашоритм обучения сети КМЬР . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202

8.2.3. Подбор коэффициента обучения . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204

8.2.4. Коэффициент усиления сигнала . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204

8.2.5. Результаты компьютерного моделирования . . . . . . . . . . . . . . . . . . . . . . . 205

8.3. Рекуррентная сеть Эльмана . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210

8.3.1. Структура сети . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 210

8.3.2. Алгоритм обучения сети Эльмана . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212

8.3.3. Обучение с учетом момента . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214

8.3.4. Прнмер компьютерного моделирования сети Эльмана . . . . . . . . . ‚ . . . . 215

8.4. Сеть КТКЫ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219

8.4.1. Структура сети и алгоритм обучения . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219

8.4.2. Результаты вычислительных экспериментов . . . . . . . . . . . . . . . . . . . . . . 221

9. СЕТИ С САМООРГАНИЗАЦИЕЙ НА ОСНОВЕ КОНКУРЕНЦИИ 226
9.1. Отличительные особенности сетей с самоорганизацией на основе

конкуренции . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227

9.1.1. Меры расстояния между векторами . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228

9.1.2. Нормализация векторов . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229

9.1.3. Проблема мертвых нейронов . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230

9.2. _ Алгоритмы обучения сетей с самоорганизацией . . . . . . . . . . . . . . . . . . . . . . . . . 231

9.2.1. Алгоритм Кохонена . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233

9.2.2. Алгоритм нейронного газа . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233

9.2.3. Сравнение алгоритмов самоорганизации . . . . . . . . . . . . . . . . . . . . . . . . . 235

9.3. Сеть восстановления одно- и двумерных данных . . . . . . . . . . . . . . . . . . . . . . . . 238

9.4. Восстановление Сэммона . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241

9.5. Применение сетей с самоорганизацией . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242

9.5.1. Компрессия данных . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243

9.5.2. Диагностирование неисправностей оборудования . . . . . . . . . . . . . . . . . . 246

9.5.3. Краткосрочное прогнозирование нагрузок энергетической снстемы . . . . . . . .249

9.6. Г нбридная сеть . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
10. СЕТИ С САМООРГАНИЗАЦИЕЙ КОРРЕЛЯЦИОННОГО ТИПА 257
10.1. Энергетическая функция корреляцнонных сетей . . . . . . . . . . . . . . . . . . . . . . . . . 257

10.2. Нейронные сети РСА . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ‚ ‚ . . . . . . . 259

10.2.1. Математическое введение . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259

10.2.2. Определение первого главного компонента . . . . . . . . . . . . . . . . . . . . . . . 264

10.2.3. Алгоритмы определения множества главных компонентов _ . . . . . . . . . 265

10.3. Нейронные ЮА-сеш Херольта-Джуттена . . . . . . . . . . . . . . . . . ‚ . . . . . . . . . . . . 267

10.3.1. Предварительные пояснения . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267

10.3.2. Статистическая независимость сигналов . . . . . . . . . . . . . . . . . . . . . . . . . 268

10.3.3. Рекуррентная структура разделяющей сети . . . . . . . . . . . . . . . . . . . . . . . 269

10.3.4. Алгоритм Херольта-Джутгена для рекуррентной сети . . . . . . . . . . . . . . 270

10.3.5. Обобщенный алгоритм обучения рекуррентной сети . . . . . . . . . . . . . . . 272

10.3.6. Однонаправленная сеть для разделения сигналов . . . . . . . . . . . . . . . . . . 274

Содержание

 

11. МАТЕМАТИЧЕСКИЕ ОСНОВЫ НЕЧЕТКИХ СИСТЕМ

1 1. 1 . Операции на нечепшх множествах
1 1.2. Меры нечеткости нечепсих множеств . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11.3. Нечеткость и вероятность . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ._ . . . . . . . . . .

11.4. Нечеткие правила вывода . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 1.5. Системы нече’гкого вывода Мамдани-Заде . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 1.5.1. Фуззификатор . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11.5.2. Дефуззификатор . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11.5.3. Модель Мамдани-Заде как универсальный аппроксиматор . . . . . . . . . .

11.6. Модель вывода Такаги-Сугено—Канга . .` . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12. НЕЧЕТКИЕ НЕЙРОННЫЕ СЕТИ

12.1. Структура нечеткой сети ТЗК . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12.2. Структура сети Ванга-Менделя . . . . . . . . . . ‚ . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12.3. Г ибридный алгоритм обучения нечетких сетей . . . . . . . . . . . . . . . . . . . . . . . . . .
12.4. Применение алгоритма самоорганизации для обучения нечеткой сети
12.4. 1. Алгоритм нечеткой самоорганизации С-теапз . . . . . . . . . . . . . . . . . . . . .
12.4.2. Алгоритм пикового группирования . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12.4.3. Алгоритм разностного группирования . . . . . . . . . . . . . . . . . . . . . . . . . . .
12.4.4. Алгоритм нечеткой самоорганизации Г устафсона-Кесселя
12.4.5. Сеть с нечеткой самоорганизацией в гибридной структуре . . . . . . . . . .
12.4.6. Примеры реализации нечепшх сетей . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12.5. Адаптивный алгоритм самоорганизации нечеткой сети

Литература . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Предметный указатель . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

279

281
283
284
286
287
290
293
294
295

299

299
303
304
308
308
310
312
313
318
321
327

330
340

К читателю

м
›

Основные тенденции развития кибернетики в начале третьего тысячелетия можно
выразить двумя словами: биологизация и гибридизация. Под биологизацией чаще
всего понимается построение и исследование моделей поведения сложных
объектов и способов управления ими на основе имитации механизмов,
реализованных Природой в живых существах. Такой подход обусловлен тем
фактом, что многие так называемые “классические” методы обработки
информации воспринимаются в настоящее время как простейшие реализации
универсальных способов функционирования биологических объектов. В качестве
примеров можно привести последовательные алгоритмы фон Неймана
(вырожденный случай параллельной обработки информации), а также двоичную
логику (частный случай нечеткой логики). С другой стороны, стремительное
увеличение вычислительных мощностей и развитие математического аппарата
позволили подступиться к решению таких задач, размерность которых еще 5 - 10
лет назад была непреодолимым барьером для исследователя.

Гибридизация, в свою очередь, состоит в совместном применении различных
методов и/йлй моделей для обработки информации об одном и том же объекте
Парадигма такого подхода основана на согласии с тем, что любая сколь угодно
сложная искусственная модель реального объекта всегда будет примитивнее и
проще оригинала, и только многоаспектное его изучение с последующей
интеграцией получаемых результатов позволит обрести необходимые знания или
приблизиться к оптимальному решению. Гибридный подход давно и эффективно
используется в научных исследованиях (вспомним понятия корпускулярно-
волнового дуализма, микро- и макроэкономические исследования одних и тех же
хозяйственных систем и т.п.).

Предлагаемая вниманию уважаемого читателя книга видного польского
ученого С. Осовского удачно иллюстрирует названные тенденции в одной из
наиболее динамично развивающихся областей современной теории интел-
лектуальных вычислений (англ.: сотршапопа! 1те1113епсе), связанной с
построением и применением искусственных нейронных сетей. Сформированные
в рамках этого направления многослойные сетевые модели, в качестве прототипа
которых используются структуры и механизмы функционирования биоло-
гических нервных систем, все более серьезно рассматриваются в качестве
методологического базиса для создания сверхскоростных технических устройств
параллельной обработки информации.

10 К читателю
 

Представленный в книге материал можно рассматривать с трех точек
зрения. Во-первых, это своего рода справочник по наиболее важным
моделям нейронных сетей, написанный очень точным и корректным с
математической точки зрения языком. Обширная библиография дополни-
тельно обогащает семантику книги, превращая ее в своего рода путево-
дитель по первоисточникам. Во-вторых, это конспект лекций, стиль и
характер которого свидетельствуют о богатом педагогическом опыте и
мастерстве автора — профессора Варшавского политехнического университета.
Большое количество примеров практической реализации сетей и их детальный
анализ делают настоящее издание незаменимым учебным пособием для всех
изучающих, преподающих и применяющих теорию искусственных нейронных
сетей. В-третьих, книга содержит результаты собственной научной деятельности
автора, который в силу личной скромности умалчивает о том, что многие
описываемые в ней методы, структуры и алгоритмы (в частности, методы
генерации традиента в многослойной сети на основе потоковых и сопряженных
графов, метод обучения персептронной сети по алгоритму переменной мет-
рики ВРОЗ с направленной минимизацией, гибридный алгоритм обучения
радиальных сетей, алгоритм обучения многослойного персептрона с обратной
связью КМЬР, гибридная сеть с самоорганизующейся и МЬР-компонентой,
структура и гибридный алгоритм обучения нечеткой сети ТЗК с
самоорганизацией нейронов, а также многие другие) известны мировой
научной общественности по имени их создателя С. Осовского.

В разделе 1 обсуждаются биологические основы функционирова-
ния нейрона, базовая модель нейрона МакКаллока-Питса, а также виды
межнейронных взаимодействий, позволяющие строить искусственную
нейронную сеть.

В разделе 2 представлены наиболее широко применяемые в настоящее время
модели нейронов, в том числе модель персептрона, модель ситмоидального
нейрона, адалайн, модель Хебба, инстар и оутстар, а также модель ШТА.
Рассматриваются важнейшие алгоритмы обучения, основанные как на обучении
с учителем, так и на самоорганизации.

Раздел 3 посвящен однонаправленным сигмоидальным сетям, чаще
всего применяющимся на практике. Обсуждаются градиентные алгоритмы
обучения, реализующие метод обратного распространения ошибки для ее
минимизации при генерации вектора градиента. Представлены элементы
глобальной оптимизации методами имитации огжига и генетических алго-
ритмов. ’

В разделе 4 рассматриваются проблемы практического использования
неоднородных сетей, в том числе выбора оптимальной архитектуры сети,
принципов формирования обучающих выборок и методов повышения
эффективности обобщения. Представлены примеры использования таких сетей
для задач распознавания и классификации образов, сжатия сигналов, иден-
тификации динамических объектов и прогнозирования временных рядов.

К 11

читателю

Раздел 5 посвящен сетям с радиальными базисными функциями
(КВР). Рассматриваются типовые сетевые структуры и ашоритмы обучения,
основанные на обучении с учителем и на самоорганизации конкурирующих
нейронов.

В разделе 6 описываются специализированные сети, структура которых
проектируется исходя из необходимости достижения конкретных целей. К ним
относятся сеть каскадной корреляции Фальмана и сеть Вольтерри. Особенно
интересна неоднородная структура сети Вольтерри, предназначенной для
адаптивной обработки сигналов в реальном времени.

В разделе 7 содержатся сведения о рекуррентных сетях, исполь-
зуемых в качестве ассоциативных запоминающих устройств. Представлено
описание структур и методов обучения сетей Хопфилда, Хемминга и
сети типа ВАМ. Их функционирование иллюстрируется на численных
примерах.

Раздел 8 посвящен рекуррентным сетям, построенным на неод-
нородных персептронах, в частности рассматриваются сеть КМЬР, сеть
Эльмана и сеть КТЮЧ Вильямса—Зиспера. Теоретические рассуждения под-
крепляются многочисленными примерами компьютерного моделирования
этих сетей.

В разделе 9 обсуждаются сети с самоорганизацией на основе
конкуренции нейронов. Приводятся описания алгоритмов обучения таких
сетей и принципы их применения для решения задач распознавания и
классификации образов, сжатия сигналов и прогнозирования временных
рядов.

В разделе 10 рассматриваются вопросы корреляционного обучения
(по Хеббу). Представлены два вида нейронных сетей, в которых реализовано
обобщенное правило Хебба: сети РСА, осуществляющие анализ главных компо-
нентов, и сети 1СА Херольта-Джугтена для слепого разделения сигналов.
Обсуждаются важнейшие алгоритмы обучения этих сетей и принципы их
практического использования.

Разделы П и 12 посвящены новейшим достижениям в теории нейронных
сетей, связанным с применением нечеткой логики. В одиннадцатом разделе
представлены математические основы нечетких систем, необходимые для
понимания деятельности таких сетей. В двенадцатом разделе рассматриваются
базовые структуры и принципы функционирования нечетких сетей,
использующих для адаптации параметров методы обучения как с учителем, так и
на основе самоорганизации.

Несколько слов о применяемой терминологии. Причины лингвисти-
ческой неоднозначности, которой грешат многие русскоязычные публикации,
кроются в разрозненности отечественных научных центров, занимающихся
исследованием и применением искусственных нейронных сетей, а также в
отсутствии русскоязычного периодического издания национального масштаба,
целиком посвященного этой проблематике и способного формировать

12 ц К читателю
 

“терминологическую политику”. При переводе монографии С. Осовского мы
старались соблюдать принцип стилистического единства текста (особенно в
плане использования профессиональных англицизмов), а также максимально
корректно применять правила англо-русской транскрипции и транслитерации.
В необходимых случаях наряду с используемыми в книге переводными
терминами приводятся их наиболее распространенные русифицированные
аналоги.

Издание рассчитано на читателя, обладающего определенной математической
подютовкой. Предполагается, что он знаком с основными понятиями линейной
алгебры, дифференциального исчисления, теории оптимизации, теории вероят-
ности и теории множеств. п

Хочется верить, что публикация книги С. Осовского на русском языке
станет еще одним стимулом для повышения эффективности как проводимых,
так и планируемых в России исследований в области нейронных сетей.

И Рудинский,
кандидат технических наук

Предисловие к русскому изданию

‚ч‘;

Нейронные сети — это раздел искусственного интеллекта, в котором для
обработки сигналов используются явления, аналогичные происходящим в
нейронах живых существ. Важнейшая особенность сети, свидегельствующая о ее
широких возможностях и огромном потенциале, состоит в параллельной
обработке информации всеми звеньями. При громадном количестве
межнейронных связей это позволяет значительно ускорить процесс обработки
информации. Во многих случаях становится возможным преобразование
сигналов в реальном времени. Кроме того, при большом числе межнейронных
соединений сеть приобретает устойчивость к ошибкам, возникающим на
некоторых линиях. Функции поврежденных связей берут на себя исправные
линии, в результате чего деятельность сети не претерпевает существенных
возмушений.

Другое не менее важное свойство — способность к обучению и обобщению
накопленных знаний. Нейронная сеть обладает чертами искусственного
интеллекта. Натренированная на ограниченном множестве данных сеть способна
обобщать полученную информацию и показывать хорошие результаты на данных,
не использовавшихся в процессе обучения.

Характерная особенность сети состоит также в возможности ее реализации с
применением технологии сверхбольшой степени интеграции. Различие элементов
сети невелико, а их повторяемость огромна. Это открывает перспективу создания
универсального процессора с однородной структурой, способного перера-
батывагть разнообразную информацию.

Использование перечисленных свойств на фоне развития устройств со
сверхбольшой степенью интеграции (УЬЫ) и повсеместного применения
вычислительной техники вызвало в последние годы огромный рост интереса к
нейронным сетям и существенный прогресс в их исследовании. Создана база для
выработки новых технологических решений, касающихся восприятия,
искусственного распознавания и обобщения видеоинформации, управления
сложными системами, обработки речевых сигналов и т.п. Искусственные
нейронные сети в практических приложениях, как правило, используются в
качестве подсистемы управления или выработки решений, передающей
исполнительный сигнал другим подсистемам, имеющим иную методологическую
основу. Функции, выполняемые сетями, подразделяются на несколько групп:

14 Предисловие к русскому изданию

аппроксимация; классификация и распознавание образов; прогнозирование;
идентификация и оценивание; ассоциативное управление.

Аппроксимирующая сеть играет роль универсального аппроксиматора
функции нескольких переменных, который реализует нелинейную функцию вида
у = ](х), где х — входной вектор, а у — реализованная функция нескольких
переменных. Множество задач моделирования, идентификации, обработки
сигналов удается сформулировать в аппроксимационной постановке.

Для классификации и распознавания образов сеть накапливает в процессе
обучения знания об основных свойствах этих образов, таких, как геомегрическое
отображение структуры образа, распределение главных компонентов (РСА), или
о других характеристиках. При обобщении акцентируются отличия образов друг
от друга, которые и составляют основу для выработки классификационных
решений.

В области прогнозирования задача сети формулируется как предсказание
будущего поведения системы по имеющейся последовательности ее предыдущих
состояний. По информации о значениях переменной х в моменты времени,
предшествующие прогнозированию, сеть вырабатывает решение о том, чему
должно быть равно оцениваемое значение исследуемой последовательности в
текущий момент времени.

В задачах управления динамическими процессами нейронная сеть выполняет,
как правило, несколько функций. Во-первых, она представляет собой нелинейную
модель этого процесса и идентифицирует его основные параметры, необходимые
для выработки соответствующего управляющего сигнала. Во-вторых, сеть
выполняет функции следящей системы, отслеживает изменяющиеся условия
окружающей среды и адаптируется к ним. Она также может играть роль
нейрорегулятора, заменяющего собой традиционные устройства. Важное
значение, особенно при управлении роботами, имеют классификация текущего
состояния и выработка решений о дальнейшем развитии процесса.

В задачах ассоциации нейронная сеть выступает в роли ассоциативного
запоминающего устройства. Здесь можно выделить память автоассоциативного
типа, в которой взаимозависимости охватывают только конкретные компоненты
входного вектора, и память гетероассоциативного типа, с помощью которой сеть
определяет взаимосвязи различных векторов. Даже если на вход сети подается
вектор, искаженный шумом либо лишенный отдельных фрагментов данных, то
сеть способна восстановить полный и очищенный от шумов исходный вектор
путем генерации соответствующего ему выходного вектора.

Различные способы объединения нейронов между собой и организации их
взаимодействия привели к созданию сетей разных типов. Каждый тип сети, в
свою очередь, тесно связан с соответствующим методом подбора весов
межнейронных связей (т.е. обучения). Среди множества существующих видов
сетей в качестве важнейших можно выделить многослойный персептрон,
радиальные сети КВР, сети с самоорганизацией в результате конкуренции
нейронов, сети с самоорганизацией корреляционного типа, а также рекуррентные

Я исловтже к юскаи изданию 15

сети, в которых имеются сигналы обратной связи. Особую разновидность
составляют нечеткие нейронные сети, функционирование которых основано на
принципах нечеткой логики.

Интересным представляется объединение различных видов нейронных сетей
между собой, особенно сетей с самоорганизацией и обучаемых с учителем. Такие
комбинации получили название “гибридные сети”. Первый компонент — это сеть
с самоорганизацией на основе конкуренции, функционирующая на множестве
входных сигналов и группирующая их в кластеры по признакам совпадения
свойств. Она играет роль препроцессора данных. Второй компонент — в виде сети,
обучаемой с учителем (например, персептронной), сопоставляет входным
сигналам, отнесенным к конкретным кластерам, соответствующие им заданные
значения (постпроцессинг). Подобная сетевая структура позволяет разделить
фазу обучения на две части: вначале тренируется компонент с самоорганизацией,
а потом — сеть с учителем. Дополнительное достоинство такого подхода
заключается в снижении вычислительной сложности процесса обучения, а также
в лучшей интерпретации получаемых результатов.

В предлагаемой вниманию русскоязычного читателя книге уделяется
внимание важнейшим перечисленным выше типам искусственных нейронных
сетей, методам их обучения и практического использования при решении
конкретных задач обработки информации. По сравнению с польским изданием
она дополнена описанием ряда новейших алгоритмов, в частности, в разделе о
нечетких нейронных сетях.

Автор выражает благодарность издательству “Финансы и статистика” за
издание книги в России, И.Д. Рудинскому за перевод ее на русский язык, а также
издательству Варшавского политехнического университета “Ойсупа шуоашпйси”
за предоставленные иллюстративные материалы. Хотелось бы выразить надежду,
что изложенные в книге материалы будут полезными для лучшего понимания
проблематики искусственных нейронных сетей и их применения для обработки
информации.

С Осовский
Варшава,
июль, 200111

Предисловие

Книга “Нейронные сети для обработки информации” — это оригинальное
изложение новейших достижений в области искусственных нейронных сетей и их
практических приложений. Оно представляет собой расширенную и в
значительной степени модифицированную версию более ранних изданий
“Нейронные сети” (“Зйесй пеигопоше” Ойсупа Щуоауупйсга Р“, 1994) и
“Алгоритмическое описание нейронных сетей” (“Зйесй пеигопоше ш Щесйи а13о-
гугтйсгпуш” ЩЫТ, Шагзгаша, 1996). Нейронные сети получили широкую
популярность в научной среде благодаря способности относительно легко
адаптироваться к разтшчным отраслям знаний. Они обладают свойствами,
необходимыми для различных практических приложений: предоставляют
универсальный механизм аппроксимации, адекватный многомерным массивам
данных, способны обучаться и адаптироваться к изменяющимся условиям
окружающей среды, могут обобщать полученные знания и на этой основе
считаются системами искусственного интеллекта. Базис функционирования
таких сетей составляют алгоритмы обучения, позволяющие оптимизировать
весовые коэффициенты.

В книге представлены важнейшие разделы теории искусственных нейронных
сетей. Основное внимание уделяется алгоритмам обучения и их применению для
обработки измерительной информации. Приводятся детальный обзор и описание
важнейших методов обучения сетей различной структуры, иллюстрируемый
численными экспериментами с практически подтвержденными результатами.

Книга предназначена для студентов старших курсов, аспирантов и научных
работников, интересующихся методами теории искусственного интеллекта. С
учетом междисциплинарного характера обсуждаемой тематики она может
оказаться полезной как для специалистов в области информатики, статистики,
физики и технических дисциплин, так и для биомедицинских отраслей знаний.
Благодаря обсуждению и базовых и производных понятий искусственных
нейронных сетей, книга будет одинаково полезной как для начинающих, так
и для профессионалов в этой предметной области.

Автор выражает признательность Издательству ЩЫТ за разрешение
использовать фрагменты книги “Зйесй пеитопоше ‘д’ щесйп ащогуттйсгпут” при
подготовке настоящей монографии.

Автор

Раздел 1

ВЁЕДЕНИЕ

1.1. Биологические основьт функционирования
нейрона

Тематика искусственных нейронных сетей относится к междисциплинарной
сфере знаний, связанных с биокибернетикой, электроникой, прикладной матема-
тикой, статистикой, автоматикой и даже с медициной [16, 46, 51, 77, 113, 152, 182].
Искусственные нейронные сети возникли на основе знаний о функционировании
нервной системы живых существ. Они представляют собой попытку использова-
ния процессов, происходящих в нервных системах, для выработки новых техно-
логических решений. ’

Нервная клетка, сокращенно называемая нейроном, является основным эле-
ментом нервной системы. Изучение механизмов функционирования отдельных
нейронов и их взаимодействия принципиально важно для познания
протекающих в нервной системе процессов поиска, передачи и обработки
информации. С этой точки зрения представляется необходимым построить и
изучить модель биологического нейрона.

Как и у любой другой клетки, у нейрона имеется тело со стандартным
набором органелл, называемое самой, внутри которого располагается ядро [152].
Из сомы нейрона выходят многочисленные отростки, играющие ключевую
роль в его взаимодействии с другими нервными клетками. Можно выделить два
типа отростков: многочисленные тонкие, густо ветвящиеся дендриты и более
толстый, расщепляющийся на конце аксон (рис. 1.1).

Входные сигналы поступают в клетку через синапсы, тогда как выходной
сигнал отводится аксоном через его многочисленные нервные окончания, назы-
ваемые колатералами. Колатералы контактируют с сомой и дендритами других
нейронов, образуя очередные синапсы. Очевидно, что синапсы, подключающие к
клетке выходы других нейронов, могут находиться как иа дендритах, так и
непосредственно на теле клетки.

Передача сигналов внутри нервной системы - это очень сложный электрохи-

мический процесс. С большим упрощением можно считать, что передача нерв-
ного импульса между двумя клетками основана на выделении особых химических
субстанций, называемых нейромедиаторами, которые формируются под

2-2162

18 1. Введение
 

влиянием поступающих от синапсов раздражителей. Эти субстанции
воздействуют на клеточную мембрану, вызывая изменение ее энергетического
потенциала, причем величина этого изменения пропорциональна количеству
нейромедиатора, попадающего на мембрану.

Аксон друаоао нейрона

\

  
  

Дендриты

  

\

Синапс

   

‹- Аксон другого нейрона ‚

Концевые
колатералы

Рис. 1.1. Упрощенная структура биологической нервной клетки

Синапсы отличаются друг от друга размерами и возможностями концен-
трации нейромедиатора вблизи своей оболочки. По этой причине импульсы
одинаковой величины, поступающие на входы нервной клетки через различные
синапсы, могут возбуждать ее в разной степени. Мерой возбуждения клетки
считается уровень поляризации ее мембраны, зависящий от суммарного
количества нейромедиатора, выделенного на всех синапсах.

Из сказанного следует, что каждому входу клетки можно сопоставить
численные коэффициенты (веса), пропорциональные количеству нейромедиатора,
однократно выделяемого на соответствующем синапсе. В математической модели
нейрона входные сигналы должны умножаться на эти коэффициенты для того,
чтобы корректно учитывать влияние каждого сигнала на состояние нервной
клетки. Синапсические веса должны быть натуральными числами, принимаю-
щими как положительные, так и отрицательные значения. В первом случае синапс
оказывает возбуждающее, а во втором - тормозящее действие, препятствуюшее
возбуждению клетки другими сигналами. Таким образом, действие возбуждаю-
щего синапса может моделироваться положительным значением синапсического
веса, а действие тормозящего синапса — отрицательным значением.

В результате поступления входных импульсов на конкретные синапсы и
высвобождения соответствующих количеств нейромедиатора происходит опреде-
ленное электрическое возбуждение нервной клетки. Если отклонение от

1.1. Биологические основы функционирования нейрона 19

состояния электрического равновесия невелико либо если баланс возбуждений и
торможений является отрицательным, клетка самостоятельно возвращается в
исходное состояние, и на ее выходе какие-либо изменения не регистрируются. В
этом случае считается, что уровень возбуждения клетки был ниже порога ее
срабатывания. Если же сумма возбуждений и торможений превысила порог
активации клетки, значение выходного сигнала начинает лавинообразно
нарастать, принимая характерный вид нервного импульса (рис. 1.2), пересылае-
мого аксоном на другие нейроны, подключенные к данной клетке. Величина
этого сигнала не зависит от степени превышения порога. Клетка действует по

Щту]

 

Рис. 1.2. Типичная форма нервного импульса

принципу “все или ничего”. После выполнения своей функции нейромедиатор
удаляется. Механизм удаления заключается либо во всасывании этой субстанции
клеткой, либо в ее разложении, либо в удалении за пределы синапса.
Одновременно с генерацией нервного импульса в клетке запускается процесс
рефракции. Он проявляется как стремительное возрастание порога активации
клетки до значения “плюс бесконечность”, в результате чего сразу после
генерации импульса нейрон теряет способность вырабатывать очередной сигнал
даже при сильном возбуждении. Такое состояние сохраняется в течение времени
41„ называемого периодом абсолютной рефракции. По окончании этого срока
наступает период относительной рефракции Ащ, за который порог срабатывания
возвращается к первоначальному значению. В это время клетку можно
активировать, но только с приложением более сильных возбуждений. В
естественных процессах, как правило, выполняется отношение Ад,» 41,.
Количество взаимодействующих друг с другом нервных клеток чрезвычайно
велико. Считается, что человеческий мозг содержит около 10" нейронов [152],

каждый из которых выполняет относительно примитивные функции суммирова-

ния весовых коэффициентов входных сигналов и сравнения полученной суммы С
пороговым значением. Каждый нейрон имеет свои веса и свое пороговое значе-
ние. Они определяются местонахождением нейрона и решаемой им задачей и
2‘

20 1. Введение
могут интерпретироваться аналогично содержимому локальной памяти
процессора.

Громадное количество нейронов и межнейронных связей (до 1000 входов в
каждый нейрон) приводит к тому, что ошибка в срабатывании отдельного нейрона
остается незаметной в общей массе взаимодействующих клеток. Нейронная сеть
проявляет высокую устойчивость к помехам — это “стабильная” сеть, в которой
отдельные сбои не оказывают существенного влияния на результаты ее
функционирования. Таково главное отличие нейронных систем от обычных
электронных систем, созданных человеком. Следует подчеркнуть, что ни одна
современная технология не позволяет построить искусственную нейронную сеть,
близкую по масштабам к нейронной сети мозга. Однако изучение и копирование
биологических нервных систем позволяют надеяться на создание нового
поколения электронных устройств, имеющих аналогичные характеристики.

Другая важная особенность нервных систем — высокая скорость их
функционирования, несмотря на относительно длительный цикл срабатывания
каждой отдельной клетки, измеряемый в миллисекундах и показанный на рис. 1.2.
Она достигается благодаря параллельной обработке информации в мозге
огромным количеством нейронов, соединенных многочисленными межней-
ронными связями. Такие операции, как распознавание образов и звуков либо
принятие решений, выполняются человеческим мозгом за промежутки времени,
измеряемые миллисекундами. Достижение такого результата при использовании
полупроводниковой технологии УЬЗ! все еще выходит за границы современных
технических возможностей, хотя цш‹л срабатывания отдельных исполнительных
элементов СБИС является достаточно коротким и имеет порядок 10'8 с. Если
удастся, взяв за образец нервную систему создать устройство с высокой степенью
параллельности выполнения независимых операций, то скорость его функцио-
нирования может быть существенно увеличена и приближена к уровню,
наблюдаемому в процессах обработки информации биологическими объектами.

1.2. Первые модели нейронной сети

Из приведенных выше рассуждений следует, что каждый нейрон можно считать
своеобразным процессором: он суммирует с соответствующими весами сигналы,
приходящие от других нейронов, выполняет нелинейную (например, пороговую)
решающую функцию и передает результирующее значение связанным с ним
нейронам. В соответствии с действующим правилом “все или ничего” в
простейших моделях нейронов выходной сигнал принимает двоичные значения:
0 или 1. Значение 1 соответствует превышению порога возбуждения нейрона, а
значение 0 - возбуждению ниже порогового уровня.

В одной из первых моделей нейрона, называемой моделью МакКаллока-
Питса (предложенной в 1943 г), нейрон считается бинарным элементом [98, 135].
Структурная схема этой модели представлена на рис. 1.3. Входные сигналы

1.2. ‚Паевые модели нейеонной сети 21

х] ([ = 1, 2, ..., М) суммируются с учетом соответствующих весов шд (сигнал
поступает в направлении от узла 1 к узлу 1) в сумматоре, после чего результат
сравнивается с пороговым значением шю. Выходной сигнал нейрона у;
определяется при этом зависимостью

У: = Ёшд>‹‚(1)+ш‚о1. а (1-1)

1=1

П
Аргументом функции выступает суммарный сигнал и, = 21шдх‚(1)+ шю.
.‚ 1:
Функция ](и;) называется функциеи активации. В модели МакКаллока-Питса это

пороговая функция вида
1 для и > О

Ли) = (1.2)

0 дляи$0 ’

Коэффициенты шг, присутствующие в формуле (1.1), представляют веса
синаптических связей. Положительное значение шд соответствует возбуждающим
синапсам, отрицательное значение шд -
тормозящим синапсам, тогда как шд = О
свидетельствует об отсутствии связи
между Я-м и ]—м нейронами. Модель
МакКаллока-Питса - это дискретная
модель, в которой состояние нейрона в
момент (г + 1) рассчитывается по значе-
ниям его входных сигналов в предыду-
щий момент г. Построение дискретной
модели обосновывается проявлением Хм
рефракции у биологических нейронов,
приводящей к тому, что нейрон может
изменять свое состояние с конечной
частотой, причем длительность периодов бездействия зависит от частоты его
срабатывания.

Через несколько лет Д. Хебб в процессе исследования ассоциативной памяти
предложил теорию обучения (подбора весов шд) нейронов. При этом он исполь-
зовал наблюдение, что веса межнейронных соединений при активации нейронов
могут возрастать. В модели Хебба приращение веса Ашд в процессе обучения
пропорционально произведению выходных сигналов у; и И неиронов, связанных
весом шд:

 

Рис. 1.3. Модель нервной клетки по
МакКаллоку-Питсу

т‘ + 1) = “МЮ + Пугадиа‘) ‚ (1.3)
где 1с означает номер цикла, а п - это коэффициент обучения.

В начале 60-х годов Б. Видроу [167] предложил теоретическое обоснование и

сформулировал принципы "практической реализации ЯДЗПТИВНЫХ устройств
обработки сигналов, что стало существенным вкладом в развитие нейронных
сетей, функционирующих в режимах “онлайн” и “оффлайн”.

22 1. Введение

 

В 1962 п была опубликована книга Ф. Розенблатта [135], в которой
представлена теория динамических нейронных систем для моделирования
мозговой деятельности, основанная на персептронной модели нервной клетки. В
этой теории использовалось представление нейрона моделью МакКаллока-Питса,
в которой функция активации принимала двоичные значения О и 1.

Ограниченные возможности одиночного персептрона и составляемых из
таких элементов одноуровневых сетей подверглись критике в книге М. Минского
и С. Пейперта [101], что вызвало резкое снижение финансирования этой сферы
научных исследований и привело в результате к замедлению развития
искусственных нейронных сетей. Только отдельные научные группы,
сконцентрированные вокруг таких ученых, как Гроссберт; Видроу фон дер
Мальсбурц Амари, Фукушима и Кохонен, продолжали работу в этой области. И
только бурное развитие в 80-х годах технологии производства полупровод-
никовых устройств сверхвысокой степени интеграции (УЬЗ!) привело к резкому
возрастанию интереса к средствам параллельной обработки информации,
которыми считаются и искусственные нейронные сети. Начиная с опубли-
кованных в 1982 п работ Дж. Хопфилда [53], теория нейронных сетей развивается
в стремительном темпе, а количество научных центров, занимающихся этой
междисциплинарной сферой знаний, непрерывно увеличивается. Доработка или,
точнее, повторное открытие принципа обратного распространения [51] в
применении к обучению многослойных сетей сняли те ограничения, которые
стали главным объектом критики в книге М. Минского и С. Пейперта.
Масштабное увеличение финансирования этой научной отрасли предопределило
существенный прогресс как в теории, так и в практических приложениях. С
учетом взрывного развития вычислительных систем это создало базу для
реализации новых технологических решений в сфере технического распоз-
навания образов, восприятия и объяснения, в управлении сложными системами,
для обработки речевых сообщений и т.п. В настоящее время искусственные
нейронные сети представляют собой высокоразвитую (особенно в теоретическом
аспекте) отрасль знаний.

1.3. Прикладные возможности нейронных сетей

Любая нейронная сеть используется в качестве самостоятельной системы
представления знаний, которая в практических приложениях выступает, как
правило, в качестве одного из компонентов системы управления либо модуля
принятия решений, передающих результирующий сигнал на другие элементы, не
связанные непосредственно с искусственной нейронной сетью. Выполняемые
сетью функции можно распределить на несколько основных групп:

ЗППРОКСИМЗЦИИ И ИНТСРПОЛЯЦИИ; РЗСПОЗНЗВЩХИЯ И КЛЗССИФИКЗЦИИ ОбРЭЗОВ; СЖЗТИЯ
данных; прогнозирования; идентификации; управления; ассоциации.

В каждом из названных приложений нейронная сеть играет роль
универсального аппроксиматора функции от нескольких переменных [1, 56],

1.3. Прикладные возможности нейронных сетей 23

реализуя нелинейную функцию
у =](х) , (1 .4)

где х - это входной вектор, а у — реализация векторной функции нескольких
переменных. Постановки значительного количества задач моделирования,
идентификации и обработки сигналов могут быть сведены именно к
аппроксимационному представлению.

Для классификации и распознавания образов сеть обучается важнейшим их
признакам, таким, как геометрическое отображение точечной структуры
изображения, относительное расположение важнейших элементов образа,
компоненты преобразования Фурье и другие подобные факторы. В процессе
обучения выделяются признаки, отличающие образы друг от друга, которые и
составляют базу для принятия решений об отнесении образов к соответствующим
классам.

При решении задач прогнозирования роль нейронной сети состоит в
предсказании будущей реакции системы по ее предшествующему поведению.
Обладая информацией о значениях переменной х в моменты, предшествующие
прогнозированию х(1с—1), х(1с—2), ..., х(1с-1\/), сеть вырабатывает решение, каким
будет наиболее вероятное значение последовательности Ёс(1с) в текущий момент
дг. Для адаптации весовых коэффициентов сети используются фактическая
погрешность прогнозирования г=х(1‹) -—$(1с) и значения этой погрешности в
предшествующие моменты времени.

При решении задач идентификации и управления динамическими процессами
нейросеть, как правило, выполняет несколько функций. Она представляет собой
нелинейную модель этого процесса, обеспечивающую выработку соответст-
вующего управляющего воздействия. Сеть также выступает в роли следящей
системы, адаптирующейся к изменяющимся условиям окружающей среды. Очень
большое значение, особенно при управлении роботами, имеет функция
классификации, реализуемая при выработке решения о дальнейшем развитии
процесса.

В задачах ассоциации нейронная сеть играет роль ассоциативного
запоминающего устройства (ЗУ). Можно выделить ЗУ автоассоциативного типа, с
помощью которых определяется корреляция между отдельными компонентами
одного и того же входного вектора, и ЗУ тетероассоциативного типа, средствами
которых устанавливается корреляция между двумя различными векторами. Если
на вход сети подается неструктурированный вектор (например, содержащий
искаженные шумом компоненты или вообще не содержащий отдельные
компоненты), нейронная сеть сможет восстановить оригинальный и очищенный
от шумов вектор и сгенерировать при этом полную версию ассоциированного с

ним вектора.
Важнейшее свойство нейронных сетей, свидетелъствуюшее об их огромном

потенциале и широких прикладных возможностях, состоит в параллельной

обработке информации одновременно всеми нейронами. Благодаря этой
способности при большом количестве межнейронных связей достигается

24 1. Введение

 

значительное ускорение процесса обработки информации. Во многих ситуациях
становится возможной обработка сигналов в реальном масштабе времени.

Очень большое количество межнейронных’ соединений приводит к тому, что
сеть становится нечувствительной к ошибкам, возникающим в отдельных
контактах. Функции поврежденных соединений принимают на себя другие
элементы, в результате в деятельности сети не наблюдаются заметные нарушения.
Это свойство используется, в частности, при поиске оптимальной архитектуры
нейронной сети путем разрыва отдельных связей. Алгоритм такого поиска,
названный “Оргйта! Вгайп Ватаге” [84], является прекрасной иллюстрацией
этого свойства нейронной сети.

Другое не менее важное свойство нейронной сети состоит в способности к
обучению и к обобщению полученных знаний. Сеть обладает чертами так
называемого искусственного интеллекта. Натренированная на ограниченном
множестве обучающих выборок, она обобщает накопленную информацию и
вырабатывает ожидаемую реакцию применительно к данным, не обрабатывав-
шимся в процессе обучения. Несмотря на значительное количество уже
известных практических приложений искусственных нейронных сетей,
возможности их дальнейшего использования для обработки сигналов не изучены
окончательно, и можно высказать предположение, что нейронные сети еще в
течение многих лет будут средством развития информационной техники.

.›

Раздел 2   

МОДЕЛИ НЕЙРОНОВ И МЕТОДЫ ИХ ОБУЧЕНИЯ —

„з;

З соответствии с принципами функционирования биологических иейронов
:озданы различные математические модели, которыми в большей или меньшей
гтепени реализуются свойства природной нервной клетки. Обобщенная схема,
:оставляющая основу большинства таких моделей, восходит к представленной на
рис. 1.3 модели МакКаллока-Питса, содержащей сумматор взвешенных входных
:игналов и нелинейный блок выработки выходного сигнала нейрона, функцио-
аально зависящего от выходного сигнала сумматора. Свойства нелинейной
функции, особенно ее непрерывность, оказывают определяющее влияние на
выбор способа обучения нейрона (подбор весовых коэффициентов). Другим
важным фактором становится выбор стратегии обучения. Можно выделить два
подхода: обучение с учителем‘ (англ.: зирегчйзес! 1еатЕп3) и обучение без учителя
‹англ.: ипзиретйвед 1еатЕп3).

При обучении с учителем предполагается, что, помимо входных сигналов,
составляющих вектор х, известны также и ожидаемые выходные сигналы нейрона
ф, составляющие вектор с! (от англ. дезгйпагйоп). В подобной ситуации подбор
весовых коэффициентов должен быть организован так, чтобы фактические
выходные сигналы нейрона у; принимали бы значения, как можно более близкие
к ожидаемым значениям ф. Ключевым элементом процесса обучения с учителем
является знание ожидаемых значений а’; выходного сигнала нейрона.

Если такой подход невозможен, остается выбрать стратегию обучения без
учителя. Подбор весовых коэффициентов в этом случае проводится на основании
либо конкуренции нейронов между собой (стратегии “РУЕппег Та1сез АН — РУТ ”
(Победитель получает все) или “РУЕппег Та1сез Мозг — РУТМ’ (Победитель получает
больше), либо с учетом корреляции обучающих и выходных сигналов (обучение
по Хеббу). При обучении без учителя на этапе адаптации нейрона мы не можем
прогнозировать его выходные сигналы, тогда как при обучении с учителем
результат обучения предопределен заранее благодаря априори заданным
обучающим выборкам. В этом разделе книги обсуждаются наиболее
репрезентативные модели, реализующие каждый из указанных подходов.

 

1 Обучение с учителем также называют обучением под надзором.

26 2. Модели нейронов и методы их обучения

2.1. Персептрон

Простой персептрон — это обычная модель МакКаллока-Питса с соответст-
вующей стратегией обучения [51]. Структурная схема и обозначения элементов
Я-го персептрона представлены на рис. 1.3. Весовые коэффициенты входов
сумматора, на которые поступают входные сигналы 19, обозначаются шд, а
пороговое значение, поступающее с так называемого поляризатора, - и’;‹;.
Нелинейная функция активации персептрона представляет собой дискретную
функцию ступенчатого типа, вследствие чего выходной сигнал нейрона
может принимать только два значения — О или 1 в соответствии с правилом

( ) 1 для и 2 О
У: “г = ‚ 2-1
О для и < О ( )
где и; обозначен выходной сигнал сумматора
' и
и; = Е шдху. (2.2)

В приведенной формуле подразумевается, что имеющий длину А! вектор
х дополнен нулевым членом хо = 1, формирующим сигнал поляризации,
х = [х‹;, х;, ..., хд]. Обучение персептрона требует наличия учителя и состоит в
таком подборе весов шд, чтобы выходной сигнал у; был наиболее близок к
заданному значению ф. Это обучение тетероассоциативного типа, при котором
каждой обучающей выборке, представляемой вектором х, априори поставлено в
соответствие ожидаемое значение ф на выходе й-го нейрона.

Наиболее популярный метод обучения персептрона состоит в применении
правила персептрона [1, 51, 114, 135], в соответствии с которым подбор весов
осуществляется по следующему алгоритму:

’ При первоначально выбранных (как правило, случайным образом) значениях
весов шд на вход нейрона подается обучающий вектор х и рассчитывается
значение выходного сигнала у;. По результатам сравнения фактически
полученного значения у; с заданным значением ф уточняются значения весов.

’ Если значение у; совпадает с ожидаемым значением ф, то весовые коэф-
фициенты шд не изменяются.

О Если у; = О, а соответствующее заданное значение ф = 1, то значения весов
уточняются в соответствии с формулой шд(г + 1) = шд-(г) + 19, где 1 обозначает
номер предыдущего цикла, а (1 + 1) —- номер текущего цикла.

’ Если у; = 1, а соответствующее заданное значение ф = О, то значения весов
уточняются в соответствии с формулой шдд + 1) = шд(г) -— 29, ше 1 обозначает
номер предыдущего цикла, а (г + 1) — номер текущего цикла.

По завершении уточнения весовых коэффициентов представляются очеред-
ной обучающий вектор х и связанное с ним ожидаемое значение ф, и значения
весов уточняются заново. Этот процесс многократно повторяется на всех
обучающих выборках, пока не будут минимизированы различия между всеми‘

3.2. Сигмоидальный нейеон 27
значениями у; и соответствующими им ожидаемыми значениями ф.

Следует отметить, что правило персептрона представляет собой частный
случай предложенного гораздо позже правила Видроу-Хоффа [114‚ 166]. В
соответствии с этим правилом подбор весовых коэффициентов нейрона
«необязательно персептронного типа) проводится по формулам:

шд(г+1) = мы!) +Ашд , (2.3)
 =  —  . 

Аналогичные соотношения используются при подборе веса поляризатора шт,
для которого входной сигнал всегда равен 1, в связи с чем

МЮ = (д: " Уж) - (2-5)

Легко заметить, что если сигналы у, и а’; принимают только двоичные
значения О и 1, то правило Видроу-Хоффа превращается в правило персептрона.
Характерная особенность как правила персептрона, так и обобщенного
правила Видроу-Хоффа состоит в использовании для обучения информации
только о текущем и ожидаемом значениях выходного сигнала. В связи с
разрывностью нелинейной функции активации персептрона невозможно
учитывать информацию об изменении значения у, (т.е. ее производную).
Минимизация различий между фактическими реакциями нейрона у, и
ожидаемыми значениями а’, может быть представлена как минимизация
конкретной функции погрешности (целевой функции) Е, чаще всего
определяемой как
Е =Ё‚(УЁ"’ #19)’ ‚ (2.в)
где р означает количество предъявляемых обучающих выборок. Такая
минимизация при использовании правила персептрона проводится по методу
безградиентной оптимизации [51]. Эффективность метода при большом
количестве обучающих выборок относительно невелика, а количество циклов
обучения и его длительность возрастают очень быстро, причем без всякой
гарантии достижения минимума целевой функции. Устранить эти недостатки
можно только в случае применения непрерывной функции активации, при
которой целевая функция Е также становится непрерывной, что дает возможность
использовать в процессе обучения информацию о величине градиента.

2.2. Сигмоидальный нейрон

Нейрон сигмоидального типа (рис. 2.1) имеет структуру подобную модели
МакКаллока-Питса, с той разницей, что функция активации является непрерыв-
ной и может быть выражена в виде сигмоидальной униполярной или биполярной
функции [46, 114]. Униполярная функция, как правило, представляется формулой

‚дат, ‚ у (21)

28 2. Модели ней онов и методы их об чения

 

тогда как биполярная функшхя задается в виде

1Ш=тЩШ) ’ 9%

В этих формулах параметр [З подбирается пользователем. Его значение влия-
ет на форму функции активации. На
рис. 2.2 представлены графики сигмои-
дальной функции от переменной х для
различных значений В, причем на рис.
2.2а показана униполярная, а на рис.
2.26 — биполярная функция. Графики
обеих функций сильно зависят от
значения В. При малых величинах В
график функции достаточно пологий,
но по мере роста значения [З крутизна
графика увеличивается. При В —› ‹><›
сигмоидальная функция превращается
в функцию ступенчатого типа, иден-
тичную функции активации персепт-
рона. На практике чаще всего для упрощения используется значение В = 1.

Важным свойством сигмоидальной функции является ее дифферен-
цируемость. Для униполярной функции имеем

 

Рис. 2.1. Модель сигмоидального нейрона

аж‘) = В/(х)(1—(х)) ‚ ‚ ‹2.9)
тогда как для биполярной функции
аж‘) = 130-1200) . (210)

И в первом, и во втором случае график изменения производной относи-
тельно переменной х имеет колоколообразную форму; а его максимум соответст-
вует значению х = О (рис. 2.3).

Сигмоидальный нейрон, как правило, обучается с учителем по принципу
минимизации целевой функции, которая для единичного обучающего кор-
тежа <х, ‹1> Е-го нейрона определяется в виде 

=%‹у‚—‹‘‚›’‚ (211)
где _ 
„ ‚‚
и =/(и‚) =/[}3ш„х‚). (2.12)
Функция [(щ) является сигмоидальной, х — это входной вектор,

х = [х‹;, х1‚ ...‚ х„]Т со значением хо = 1 при наличии поляризации и хо = О
при ОС ОТ СУТСТВИИ, а  — СООТВЁГСТВУЮЩЁС СМ)’ ОЖИДЗФМШ? ЗНЗЧФНИС на ВЫХОД‘?

1-го нейрона. Применение непрерывной функции активации позволяет

ИСПОЛЬЗОВЗТЬ при ОбУЧСНИИ градиентные МЕТОДЫ. Проще ВССГО РВЗЛИЗОВЗТЬ

2.2. Сигмоидальный нейвон 29
д) 1

0,9
9.8
0,7
0,8
0,5
0,4
0,3
0.2
0.1
0

Г (Х)

 

б) 1
0.6
0,4
0,2

0
0.2
0,4
0,8 — _ _ _
1

Г(х)

   

1-в—в

Рис. 2.2. График ситмоидапьной функции:
а) униполярной; б) биполярной при различных значениях коэффициента В

метод наискорейшего спуска, в соответствии с которым уточнение вектора
весов и’ = [и’;‹;, ищ, .. ., шдддт проводится в направлении отрицательного градиента
целевой функции. Если эта функция определена выражением (2.11), ]-я
составляющая градиента имеет вид: '

7115 = Е=ещ

"Е ЁЁ-Ё , (213)
ди-

пе е; = (у, - ф) означает разницу между фактическим и ожидаемым значе-

нием выходного сигнала нейрона. Если ввести обозначение й та?! то

к
можно получить выражение, определяющее 1-10 СОСТЗВШШЮЩУЮ ГВЗДИЕНТЗ В ВИДЕ

У]Е = бдх] . . ъ 

30 2. Модели нейронов и методы их обучения

0,25

0,2

9
ч
СИ

(1/Д 0Г(Х)МХ
9

0,05

 

0
—10 -8 -6 -4 -2 0 2 4 6 8 10

Рис. 2.3. График производной от сигмоидальной функции при различных значениях
коэффициента В

Значения весовых коэффициентов также могут уточняться дискретным способом:
шд(г+1)= шд(г)-пб‚х‚ , (2.15)

где п - это коэффициент обучения, значение которого, как правило, выбирают
либо эмпирически из интервала (0,1), либо решением разностного уравнения

дш.

-д%=-дб‚х] , (2.1б)
в котором константа д выступает в роли, аналогичной значению п в уравнении
(2.15). Два последних уравнения определяют алгоритм обучения нейрона. На
эффективность обучения оказывает сильное влияние подбор коэффициента
обучения. В существующих приложениях его величина может задаваться
константой либо быть переменной величиной, значение которой изменяется в
процессе обучения адаптивным способом либо подбирается на каждом шаге по
принципу направленной минимизации. Наиболее эффективным, но одновременно
и наиболее трудоемким считается метод направленной минимизации, по
которому коэффициент обучения подбирается на каждом шаге путем
минимизации целевой функции от одной переменной в направлении
наискорейшего уменьшения значений этой целевой функции.

Необходимо подчеркнуть, что применение градиентного метода для обучения
нейрона гарантирует достижение только локального минимума. В случае
полимодальной целевой функции найденный локальный минимум может быть
достаточно далек от глобального минимума. Выход из окрестности локального

минимума при ИСПОЛЬЗОВЗНИИ ПрОСТОГО ЗЛГОРИТМЗ наискорейшего СПУСКЗ

невозможен. Результативным может оказаться обучение с моментом или
разбросом [51, 114]. В этом методе процесс уточнения весов определяется не

2.2. Сигмоидатьный нейеан 31

только информацией о градиенте функции, но также и фактическим трендом
изменений весов. Подобный способ обучения может быть задан следующим
математическим выражением, определяющим приращение значений весов:

Аш„(:+1)=—цд‚х‚ +аАшд(1‘) , (2.17)

в котором первый член соответствует обычному методу наискорейшего
спуска, тогда как второй член, называемый моментом, отражает последнее
изменение весов и не зависит от фактического значения градиента. Значение
коэффициента момента а, как правило, выбирается из интервала О<а <1.
Следует обратить внимание, что влияние момента на подбор весов увеличивается
с ростом значения а. Такое влияние существенным образом усиливается
при непосредственной близости локального минимума, где значение
градиента стремится к нулю. В этом случае возможны такие изменения весов,
которые приводят к возрастанию значения целевой функции и выходу за пределы
области локального минимума. Такая ситуация применительно к аппрок-
симирующей сети (выполняющей аппроксимацию входных данных) иллюст-
рируется на рис. 2.4. Отмеченные на графике точки соответствуют значениям
целевой функции, получаемым на каждом шаге обучения. Локальный минимум
Рд был покинут благодаря действию момента. Это позволило найти в точке Р;
новый минимум с меньшим значением целевой функции, который оказался
более подходящим ’ с позиций приближения фактического значения у; к
ожидаемому значению ‹1-.

Следует отметить, что показатель момента не должен доминировать в
процессе обучения, так как это приведет к нестабильности (расходимости)
алгоритма. Как правило, в процессе обучения отслеживается значение
погрешности е; с тем, чтобы не допустить его возрастания сверх некото-
рого допустимого предела, например 5%. В подобном случае, если

Целевая функция

    

2 э г а а э э в г
-1 -0‚8 -0,6’-0,4 -0‚2 0 0,2 0,4 0,6 0,8 1
и/

 

Рис. 2.4. Идшюстрация влияния момента на процесс обучения нейронной сети

32 2. Модели нейвонов и методы их обучения

е;(г+1) < 1,05 е;(1)‚ очередной шаг считается целесообразным, и уточнение весов
проводится. Если же е; (1+1) = 1‚05е;(1), изменения игнорируются, при-
нимается Ашд(г)=0, и в выражении (2.17) градиентная составляющая оказы-
вается доминирующей над составляющей момента.

2.3. Нейрон типа “адалайн”  ‹‚

Модель нейрона типа “адалайн” (англ.: АВАрйуе Ыпеаг А/Еигоп — адаптивный
линейный нейрон) была предложена Б. Видроу [167]. Ее структурная схема,
демонстрирующая адаптивный способ подбора весовых коэффициентов,
изображена на рис. 2.5. По методу весового суммирования сигналов нейрон типа
“адалайн” аналогичен представленным ранее моделям нейронов. Функция
активации имеет тип зйдпцт, т.е.

у‚(“‚) = ‘ ‚ (2.18)

 

Рис. 2.5. Структурная схема нейрона типа “адалайн”

Адаптивный подбор весовых коэффициентов осуществляется в процессе
минимизации квадратичной ошибки, определяемой как

2
 Е(и‘)=-%ег =12-[а1,—(% шдх‚  — (2-191

!=0
Следует обратить внимание, что, несм0’тря на нелинейный характер модели, т

целевой функции присутствуют только линейные члены, представляющие собой

СУММУ ВЗВСШСННЫХ ВХОДРШХ СИГНШЮВ. В СВЯЗИ С выполнением УСЛОВШ
непрерывности целевой функции стало возможным применение алгоритм:
градиентного обучения. Как и в ситуации с сигмоидальным нейроном, 1

2.3. Нейрон типа "адалайн " 33

алгоритме Видроу для минимизации целевой функции применяется метод
наискорейшего спуска. Значения весовых коэффициентов могут уточняться либо
дискретным способом

 щ‚(г+1)=ш„‹:)+це‚х‚, р’ "А (2.2о)
либо аналоговым способом - путем решения разностных уравнений вида

„ д“?
——‘#-=де‚х] ‚ 

в которых в соответствии с зависимостью (2.19) е; = ((1,- Ё‘) шдх  Несмотря на
то, что адалайн имеет на выходе нелинейный блок тигта зйдпцт, он все же
считается линейным элементом, поскольку в определении целевой функции
нелинейности отсутствуют, а подбор весов происходит так, как будто никакой
нелинейности не существует.

Нейрон типа “адалайн” имеет относительно простую практическую
реализацию [15, 113, 167] как в случае аналогового подхода на основе уравне-
ния (2.21), так и в дискретном варианте на базе выражения (2.20). Основные
компоненты модели в первом случае - это вычислительные элементы (интегра-
торы и сумматоры), тогда как во втором случае - это элементы задержки,
описываемые оператором запаздывания 24, и также интеграторы и сумматоры.
Обе адалайн-модели могут служить базой для компьютерного моделирования
нейрона этого типа.

Подчеркнем, что в практических приложениях нейроны типа “адалайн”
всегда используются группами, образуя слои, называемые мадалайн (англ.: Мапу
адаИпе - много адалайн). Каждый входящий в слой нейрон обучается по пра-
вилу адалайн. Выходные сигналы отдельных нейронов такого слоя могут
формироваться различными способами. Б. Видроу [167] предложил три базовых
типа межнейронньтх соединений: ОК, АЪП) и мажоритарное. На рис. 2.6 а, б и в

 

Рис. 2.6. Сетъ мадалайн с выходами типа: а) ОК; б) АЫО; в) мажоригарный
3—2‘е2

34 2. Модели нейеанов и методы их обучения

показаны схемы таких соединений. Конкретные сигналы у; суммируются с учетом
порогового значения, устанавливаемого раздельно для каждого типа связи.
Для схемы ОК порог имеет значение (п—1 ), для схемы АЪП) - значение (1-п), а
для мажоритарной схемы - нулевое значение. Благодаря применению функции
активации типа зйдпшп выходной сигнал у принимает значение +1, когда хотя
бы один из входных сигналов имеет значение +1 (ОК), когда все входные сиг-
налы у; имеют значения +1(А1‘ПЭ) либо когда большинство сигналов у; имеет
значение +1 (мажоритарное соединение).

2.4. Инстар и оутстар Гроссберга

Нейроны типа инстар и оутстар — это взаимодополняющие элементы. Инстар
адаптирует веса сигналов, поступающих на сумматор нейрона, к своим вход-
ным сигналам, а оутстар согласовывает веса выходящих из нейрона связей с
узлами, в которых формируются значения выходных сигналов. Нейрон типа
инстар был определен С. Гроссбергом. На рис. 2.7 представлена структурная
схема инстара.

31 _ Веса
‚1 инстара

 

Рис. 2.7. Структурная схема инстара

Сигналы х], подаваемые с весовыми коэффициентами шд на вход й-го
инстара, суммируются в соответствии с выражением

и
и, = Епшдт . (2.22)
‚=

В соответствии с функцией активации на выходе нейрона вырабатывается
выходной сигнал у; = /(щ). Часто в инстаре применяется линейная форма
функции активации, и тогда у;= щ. Обучение инстара (подбор весов шд)
производится по правилу Г россберга, в соответствии с которым

„(но = ш„(:)+цу‚[х‚ —ш„(:)1 _ ‚ (2.2з)

2. 4. Инстае и ошстав Г еоссбеега 35

где п — это коэффициент обучения, значение которого, как правило, выби-
рается из интервала (0,1). Входные данные, представляемые в виде вектора х,
выражены чаще всего в нормализованной форме, в которой ||х||= 1. Норма-
‚тизация компонентов вектора х выполняется по формуле

х.

’‹‚‹— 2 2‘ 2 . (214)
“х, +х2 +...+х„

Результаты обучения по методу Гроссберга в значительной степени зависят от
коэффициента обучения п. При выборе п = 1 веса шд становятся равными
значениям 19 уже после первой итерации. Ввод очередного входного вектора х
вызовет адаптацию весов к новому вектору и абсолютное “забывание”
предыдущих значений. Выбор п < 1 приводит к тому, что в результате обучения
весовые коэффициенты шд принимают усредненные значения обучающих
векторов х.

Допустим, что 1-й инстар был обучен на некотором нормали-

 

режиме классификации при вводе очередного входного вектора х; инстар
вырабатывает сигнал и; вида

1’:="’Тх2 ч?» = ||х1|| ||х2||с°5ф12- (225)
ВСЛСДСТВИС нормализации амплитуд ВХОДНЫХ ВСКТОРОВ ПОЛУЧЗСМЗ
и, =со$ф12 . (2.26)

При выполнении условия х; =х1 реакция инстара будет равна ид= 1. В слу-
чае, когда входные векторы отличаются друг от друга, реакция инстара будет
пропорциональна косинусу угла между этими векторами. Для ортогональных
векторов и; = О.

В итоге натренированный инстар функционирует как векторный класси-
фикатор, сопоставляющий очередной поданный на его вход вектор с вектором,
сформированным в процессе обучения. В случае максимального совпа-
дения этих векторов реакция инстара будет максимальной (наиболее
близкой к единице). Если инстар обучался на группе достаточно похожих
векторов с коэффициентом обучения п < 1, то его весовые коэффициенты
примут значения, усредненные по этим векторам, и в режиме классифи-

Необходимо подчеркнуть, что инстар может обучаться как с учителем, так и
без него. Во втором случае в правиле Г россберга в качестве значения у;
принимается фактическое значение выходного сигнала инстара. При обучении с
учителем значение у; заменяется ожидаемым значением ф, т.е. у; = ф.

з!

36 2. Модели нейеонов и методы их обучения

Для примера рассмотрим обучение четырехвходового инстара с одно-
ступенчатой функцией активации. Инстар тренируется с учителем, а обучающие
векторы х и значения ‹1 имеют вид:

01630 05800
03482 0‚1000

х‘: , Х2= , д1=ь (12=0.
0,5000 0,7400
0,7481 03256

Значение весового коэффициента поляризации принято равным — О, 95. Это
означает, что выходной сигнал нейрона будет равен 1 при и; = 0,95, т.е. при
значении щ, достаточно близком к единице. При нулевых начальных значениях
весов и коэффициенте обучения п = 0,4 при обучении с у‘штелем стабилизация
значений весов была достигнута уже после десяти циклов обучения. Численные
результаты обучения имеют вид

О,2б14 "
О,З4б1
ш =
О,497О
О‚7436

достаточно близкий к реализации первого входного вектора х1. При выборе
коэффициента обучения п = 0,75 нейрон оказался натренированным уже после
четырех циклов обучения. Второй вектор х; в процессе обучения с учителем не
оказывал никакого влияния на результаты обучения вследствие того, что д; = О.

В процессе функционирования при подаче на вход вектора х; выраба-
тывается значение щ = 0,9940, при котором нейрон формирует выходной сиг-
нал, равный 1. При подаче на вход вектора х; вырабатывается значение
и; = 0,79б1 < 0,95, при котором нейрон формирует нулевой выходной сигнал.

  
   

Веса

оутстара у‚

У2

Ум

Рис. 2.8. Структурная схема оутстара

2.5.Нейеаны типа РУТА 37

Нейрон типа оутстар Гроссберга представляет собой комплементарное
дополнение инстара. Если инстар обучается с целью распознавать вектор,
подаваемый на его вход, то оутстар должен генерировать вектор, необходимый
связанным с ним нейронам. Структурная схема оутстара представлена на рис. 2.8.
Я-й нейрон-источник высылает свой выходной сигнал у; взаимодействующим с
ним нейронам, выходные сигналы которых обозначены ИО = 1, 2, ..., М).
Оутстар, как правило, является линейным нейроном. Обучение состоит в таком
подборе его весов шд, чтобы выходные сигналы оутстара были равны ожидаемым
значениям и взаимодействующих с ним нейронов. Обучение оутстара согласно
правилу Гроссберга проводится в соответствии с выражением

Ш;:(Ё+1)="’;:(Ё)+ПУ:(У;"и’л(’))› (2-27)

в котором п - это коэффициент обучения, а у; — выходной сигнал й-го нейрона,
выступающего в роли источника. Зависимость (2.27) для оутстара аналогична
выражению (223), по которому обучается инстар. В режиме распознавания в
момент активизации нейрона-источника оутстар будет генерировать сигналы,
соответствующие ожидаемым значениям д.

Нейроны типа инстар и оутстар существенным образом отличаются от
нейронов трех типов, определенных ранее в этом разделе. Основу обучения
персептрона, сигмоидального нейрона и адалайна составляет пара обучающих
векторов (х, а’). Они могут обучаться только с учителем. При обучении инстара и
оутстара весовые коэффициенты подстраиваются под входные или выходные
векторы. Обучение может проводиться как с учителем, так и без него.

2.5. Нейроны типа \МТА

Нейроны ‘пша ШТА (англ.: типе’ ТаКез АН — Победитель получает все) [46, 73,
114] имеют входной модуль в виде стандартного сумматора, раосчитывающего
сумму входных сигналов с соответствующими весами шд. Выходной сигнал й-го
сумматора определяется согласно формуле

и
и, = 2 шдх‚ . (2.28)
;=о

Группа конкурирующих между собой нейронов (рис. 2.9) получает одни
и те же входные сигналы х]. В зависимости от фактических значений
весовых коэффициентов суммарные сигналы и; отдельных нейронов могут
различаться. По результатам сравнения этих сигналов победителем приз-
нается нейрон, значение и; у которого оказалось наибольшим. Нейрон-побе-
дитель вырабатывает на своем выходе состояние 1, а остальные (проитравшие)
нейроны переходят в состояние О.

Для обучения нейронов типа ЩТА не требуется у‘штель, оно протекает
аналогично обучению инстара, с использованием нормализованных входных
векторов х. На начальном этапе случайным образом выбираются весовые
коэффициенты каждого нейрона, нормализуемые относительно 1. После подачи

38 2. Модели ней онов и методы их об чения

 

первого входного вектора х определяется победитель этапа. Победивший
в этом соревновании нейрон переходит в состояние 1, что позволяет ему про-
вести уточнение весов его входных линий шу (по правилу Гроссберга).

МЭХЭНПЗМ

конкуренции
нейронов

 

Рис. 2.9. Схема соединения нейронов типа ШТА

Проигравшие нейроны формируют на своих выходах состояние О, что
блокирует процесс уточнения их весовых коэффициентов. Вследствие
бинарности значений выходных сигналов конкурирующих нейронов (О или 1)
правило Гроссберга может быть несколько упрощено:

И/у (!+1)=И/у (!)+Ц[)Ч—И1у  

На функционирование нейронов типа ЧЧТА оказывает существенное влия-
ние нормализация входных векторов и весовых коэффициентов. Выходной сиг-
нал и; й-го нейрона в соответствии с формулой (2.25) может быть описан
векторным отношением _
и; =шТх= ||и’|| ||х|| созфд. (2.3О)

Поскольку ||и’|| = ||х|| = 1, значение и; определяется углом между векторами
х и и’, и; = созф д. Поэтому победителем оказывается нейрон, вектор весов кото-
рого оказывается наиболее близким текущему обучающему вектору х. В
результате победы нейрона уточняются его весовые коэффициенты, значения
которых приближаются к значениям текущего обучающего вектора х. Если на
вход сети будет подаваться множество близких по значениям векторов, побеждать
будет один и тот же нейрон. Поэтому его веса станут равными усредненным
значениям тех входных векторов, благодаря которым данный нейрон оказался
победителем. Проигравшие нейроны не изменяют свои веса. Только победа при
очередном представлении входного вектора позволит им произвести уточнение
весовых коэффициентов и продолжить процесс обучения в случае еще одной
победы.

Следствием такой конкуренции становится самоорганизация процесса
обучения. Нейроны уточняют свои веса таким образом, что при предъявлении
труппы близких по значениям входных векторов победителем всегда оказывается
один и тот же нейрон. В процессе функционирования именно этот нейрон
благодаря соперничеству распознает свою категорию входных данных. Сис-
темы такого типа чаще всего применяются для классификации векторов.

1 ЁНей оны типа РУТА 39

 

 

Рис. 2.10. Нейронная сеть типа ЧУТА

Входные векторы тинии) и векторы весов (о)

 

-1 -0‚5 О 0,5 1
Щ: ‘Щ:

Рис. 2.11. Процесс обучения изображенной на рис. 2.10 нейронной сети типа Ч/ТА

В качестве примера рассмотрим нейронную сеть, состоящую из четырех
нейронов типа ШТА и предназначенную для классификации входных
двухкомпонентных векторов (рис. 2.10). Входные обучающие векторы х
представлены в нормализованной форме:

0,97 1,00 —- 0,72 — 0,67
хк: ›х2— ’хз= ›х4= ›
0,20 0,00 0,70 0,74

3

— 0,80 0,00 0,20 — 0,30
Х5 = , Хб = , х7 = ‚ Х8 = .
0,60 — 1,00 — 0,97 — 0,95

40 2. Модели нейронов и методы их общения

Процесс обучения сети представлен на рис. 2.11. Окружностями обозначены
позиции очередных векторов весов тех нейронов, которые побеждали в
соревновании. Можно отметить, что в процессе обучения побеждали только три
нейрона. Четвертый нейрон остался мертвым (он не победил ни разу) и не
настроился ни на одну категорию векторов.

При значении коэффициента обучения т; = 0,05 после 320 обучающих циклов
были получены следующие веса трех первых нейронов:

— 0,73 14 0,О276 О,9904

ш: ‚ш: ш:
‘ о‚в7зв 2

—0,9790’ 3 —0,0в5в `

Они отражают три категории входных векторов, на которые было
самостоятельно разделено множество исходных данных.

Серьезной проблемой при обучении ЧУТА остается проблема мертвых
нейронов, которые после инициализации ни одного раза не победили в
конкурентной борьбе и остались в состоянии, сформированном в начальный
момент времени. Каждый мертвый нейрон уменьшает эффективное коли-
чество элементов, прошедших обучение, и соответственно увеличивает
общую погрешность распознавания данных. Для разрешения этой проблемы
применяется модифицированное обучение, основанное на учете прошлых
побед каждого нейрона и штрафовании (временной дисквалификации)
тех из них, которые побеждали чаще всего. Дисквалификация слишком
активных нейронов может осуществляться либо назначением порогового
числа побед, по достижении которого наступает обязательная пауза, либо умень-
шением фактического значения и, при нарастании количества побед Е-го
нейрона.

2.6. Модель нейрона Хебба

Д. Хебб в процессе исследования нервных клеток [49, 51] заметил, что
связь между двумя клетками усиливается, если обе клетки пробуждаются
(становятся активными) в один и тот же момент времени. Если ]-я клетка с
выходным сигналом И связана с 1-й клеткой, имеющей выходной сигнал уд,
связью с весом шд, то на силу связи этих клеток влияют значения выходных
сигналов у; и И.

Д. Хебб предложил формальное правило, в котором отразились результаты его
наблюдений. В соответствии с правилом Хебба [49], вес шд нейрона изменяется
пропорционально произведению его входного и выходного сигналов’

Ашд = тщу; ‚ (231)

1 Известно также антихеббовское правило (англ.: апНИеЬЬЕап 1еагптг)‚ в соответствии
с которым Ашй = -11 у‚у;—

2, 6. Модель нейвона Хебба 41

где т; —- это коэффициент обучения, значение которого выбирается в интервале
(0,1). Правило Хебба может применяться для нейронных сетей различных типов
с разнообразными функциями активации моделей отдельных нейронов.

Структурная схема нейрона Хебба, представленная на рис. 2.12, соответствует
стандартной форме модели нейрона.
Связь с весом шд, способ подбора
значения которого задается отноше-
нием (2.31), соединяет входной сиг-
нал у; с сумматором Я-го нейрона, вы-
рабагывающего выходной сигнал у;.
Обучение нейрона по правилу Хебба
может проводиться как с учителем, так
и без него. Во втором случае в пра-
виле Хебба используется фактическое
значение у; выходного сигнала ней-
рона. При обучении с учителем вместо Рис- 1-12- СТРУКТУРЫ” схема НСЙРОН“
значения выходного сигнала у; ис- Хебба
пользуется ожидаемая от этого ней-
рона реакция д; В этом случае правило Хебба записывается в виде

 

Ашд =п И д; . (2.32)

Правило Хебба характеризуется тем, что в результате его применения веса
могут принимать произвольно большие значения, поскольку в каждом цикле обу-
чения происходит суммирование текущего значения веса и его приращения Ашд:

шд(!+1)=и’д(!) ‘РАИЩ. (233)

Один из способов стабилизации процесса обучения по правилу Хебба состоит
в учете д.гтя уточнения веса последнего значения и’;-, уменьшенного на коэф-
фициент забывания 1/[51]. При этом правило Хебба представляется в виде

шд(г+1)=шд(1)(1-7)+Ашд. (234)

Значение коэффициента забывания у выбирается, как правило, из интервала
(0, 1) и чаще всего составляет некоторый процент от коэффициента обучения т).
Применение больших значений у приводит к тому, что нейрон забывает зна-
чительную часть того, чему он обучился в проптлом. Рекомендуемые значения
коэффициента забывания -у< 0,1 , при которьтх нейрон сохраняет большую
часть информации, накопленной в процессе обучения, и получает возможность.
стабилизировать значения весов на определенном уровне.

В качестве примера рассмотрим обучение без учителя с забыванием сети,
состоящей из четырех нейронов с одноступенчатой нелинейностью, причем на
входы каждого нейрона подаются все четыре компонента вектора х (рис. 2.13).
Примем, что веса поляризации шт для Е = 1, 2, 3, 4 постоянны и равны —0,5.

м:

42 2. Модели ней онов и методы их об чения

 

 

Рис. 2.13. Структура сети Хебба

Обучающие выборки х представлены в следующем виде:

1 0 0

0 0 1
х‘: ‚ х2= ‚ хз:

0 1 1 0

0 0 1

Начальные значения весовых коэффициентов шд заданы единичной мат-
рицей и‘, в которой каждый 1-й столбец соответствует весам б-го нейрона:

1000
0100
=0010`
0001

И’

П
После нескольких циклов обучения при п = 0,1 и у = Ё матрица весов
приняла вид: 4 ‘

0,971 0 0 0
0 1,029 0 0,899
0 0 0,999 0
0 0 0 1,029

2.6. Модель нейрона Хебба 43

В результате обучения связи между четвертым нейроном и вторым входом, а
также между вторым нейроном и четвертым входом были усилены. После
проведенного тренинга оба нейрона (второй и
четвертый) одинаково реагируют на единич-
ный сигнал, поступающий как на второй, так
и на четвертый вход. Веса первого и третьего
нейронов подверглись минимальным измене-
ниям, соответствующим принятым коэффици-
ентам обучения т; и забывания у Сеть само-
стоятельно (обучение проводилось без учи-
теля) обрела способность распознавать опре-
деленные зависимости между вторым входом
и четвертым нейроном, а также между четвер-
тым входом и вторым нейроном. По этой Рис- 2-14- м°дедь Пинейнш“
причине обучение по Хеббу считается "ейрша Хебба
обучением ассоциативного типа.

При обучении линейного нейрона по правилу Хебба стабилизация не
происходит даже при вводе коэффициента забывания. Выходной сигнал нейрона,
структурная схема которого приведена на рис. 2.14, определяется выражением

 

у=2ш‚х‚ = штх=хтш . (235)
1

Если согласно правилу Хебба
Ан’ = пху (2.36)

подставить выражение (2.35) в формулу (2‚36) и выбрать для упрощения 1] = 1, то
получим приращение вектора весов Аи’ в виде

Аи’ = Си’ , (237)

где С=хх — это матрица корреляции, которая по определению является
симметричной и положительно полуопределенной и, следовательно, имеет
собственные натуральные и неотрицательные значения. При выполнении
операций, описываемых зависимостью (2.37) и повторяемых на положительно
полуопределенной матрице С, процесс становится расходящимся, а значения
компонентов вектора и’ стремятся к бесконечности.

Нестабильность правила Хебба в процессе обучения можно устранить
ограничением вектора весов за счет операции ренормализации, т.е. таким
подбором пропорционального коэффициента а на каждом шаге обучения,
чтобы и"=аи’ при ||и"||= 1. Этот метод достаточно сложен и требует дополни-
тельных трудозатрат на этапе обучения.

Е. Ойя [112] модифицировал правило Хебба таким образом, что и без
ренормализации процесса обучения вектор весов самостоятельно стремится
к || и’||= 1. В соответствии с правилом Ойи уточнение весов производится
согласно выражению

Т

АИ’ = душ —у“ч)— (238)

44 2. Модапи нейронов и методы их обучения

Это правило напоминает обратное распространение; поскольку сигнал х;
модифицируется обратным сигналом, связанным с выходным сигналом у
нейрона. Для каждого отдельно взятого нейрона правило Ойя может считаться
локальным, так как в процессе модификации х; принимается во внимание
только тот весовой коэффициент, значение которого подбирается в текущий
момент времени.

Доказательство ограниченности весов, уточняемых по правилу Ойя, можно
получить, заменяя скалярное выражение (238) векторной формой, которая с
учетом упрощения т; = 1 и в соответствии с (2.38) приобретает вид:

Аи’= Си’ — (‚Я Си’) и’ . (239)

Стабильность процесса обучения достигается, когда при достаточно
длительном обучении обеспечивается ||Аю|| = 0, т.е.

Си’ = (шт Си’) и’ . (2.40)

Если собственное значение корреляционной матрицы С обозначить А, а век-
тор и’ подбирать как связанный с ней собственный вектор, то по определению
собственного значения имеем Сш=Я и’. Подставляя это выражение в формулу
(2.39), получаем: ’

Л=шТСш=шТЛ ш=Я|ш|2. (2.41)

Из (2.41) следует, что применение для обучения модифицированного правила
Хебба приводит к ограничению модуля вектора и’ единицей ' |и’|= 1,
обеспечивающему ограниченность значений весовых коэффициентов.

2.7. Стохастическая модель нейрона

В отличие от всех дегерминированньхх моделей, определенных ранее в этом
разделе, в стохастической модели [51] выходное состояние нейрона зависит не
только от взвешенной суммы входных сигналов, но и от некоторой случайной
переменной, значения которой выбираются при каждой реализации из интервала
(0,1).

В стохастической модели нейрона выходной сигнал у; принимает значения 11
с вероятностью РгоЬ(уд=1 1) = 1/(1 + ехр _( 1 2[3ид)), где и; обозначена взве-
шенная сумма входных сигналов Я-го нейрона, а В — это положительная
константа, чаще всего равная 1. Процесс обучения нейрона в стохастической
модели состоит из следующих этапов:

и
’ Расчет взвешенной суммы и, = Е шдх] для каждого нейрона сети.
1=О

’ Расчет вероятности того, что у; принимает значение 11 в соответствии с

формулой 1

РГОЬ(УЁ=Ё1›= 1+ехр($2[3и‚) '

(2.42)

2. 7. Стохастическая модель нейрона 45

’ Генерация значения случайной переменной К ё (0,1) и формирование
выходного сигнала у; = 11, если К < РтоЬ (у; = 11) или у, = 451 , в противном
случае.

’ Определенный таким образом процесс осуществляется на случайно выб-
ранной труппе нейронов, вследствие чего их состояние модифицируется в
соответствии с предложенным правилом.

’ После фиксации состояния отобранных нейронов их весовые коэффициенты
модифицируются по применяемому правилу уточнения весов. Например, при
обучении с учителем по правилу Видроу-Хоффа адаптация весов проводится
по формуле

Ашд = П  ((1; -уд) . (243)

Доказано [51], что такой способ подбора весов приводит в результате
к минимизации целевой функции, определенной как среднеквадратичная
погрешность

И

в =% й >:«‹;’‹> —‚;’‹›)1‚

/с=|!=|

рассчитываемая по всем п нейронам и р обучаюшим выборкам.

Раздел 3

ОДНОНАПРАВЛЕННЫЕ МНОГОСЛОЙНЫЕ СЕТИ
СИГМОИДАЛЬНОГО ТИПА

Объединенные между собой нейроны образуют систему, которая в дальнейшем
будет называться искусственной нейронной сетью (сокращенно - ИНС). В
зависимости от способа объединения нейронов они могут быть сетями

однонаправленными либо регфррентньши (с обратной связью).

Среди различных известных видов ИНС наибольший интерес вызывает
однонаправленная многослойная сеть МЬР, состоящая из нейронов сигмои-
дального типа, наиболее корректно называемая многослойным персептроном
(МЬР — МиШЬауетРегсерцопУ [46, 135]. Передача сигналов в таких сетях
происходит только в одном направлении от входа к выходу Их математи-
ческое описание относительно просто и прозрачно, а результат может быть
выражен в виде точной функциональной зависимости алгебраического типа.
Методы обучения подобных сетей также достаточно просты и имеют
несложную практическую реализацию. Обучение многослойного персептрона
проводится, как правило, с учителем, а основная идея обучения состоит в
подборе кортежей <х,а!>, в которых х - входной вектор, а 11 — соответствую-
щий ему ожидаемый выходной вектор сети. Если векторы х и а! не равны
между собой, сеть называется гетероассоциативной. В случае, когда х = д,
сеть называется автоассоциативной. В сетях подобного типа используются
персептронные модели нейронов либо их обобщенная форма в виде
сигмоидальной модели.

В настоящем разделе представляются базовые математические зави-
симости, определяющие многослойные сигмоидальные сети. Мы обсудим
основные методы обучения подобных сетей, в том числе алгоритм обратного
распространения ошибок, методы минимизации целевой функции, а также
различные методы подбора начальных значений весовых коэффициентов сети,
ускоряющие процесс обучения и позволяющие избежать прекращения этого
процесса в точках локальных минимумов.

С исторической точки зрения первыми были созданы однослойные сети
и методы их обучения, и только через много лет (с конца семидесятых
годов двадцатого века) была предложена эффективная методика обучения
многослойной сети.

1 Также встречается название "слоистая сеть". - Примеч. перев.

3.1. Однослойная сеть 47

3.1. Однослойная сеть

Однослойную сеть образуют нейроны, расположенные в одной плоскости (рис.
3.1). Каждый 1-й нейрон имеет поляризацию (связь с весом шт, по которой
поступает единичный сигнал), а также множество связей с весами шд, по кото-
рым поступают входные сигналы 29. Значения весов подбираются в процессе
обучения сети, состоящем в приближении выходных сигналов у; к ожидаемым
значениям д; Мерой близости считается значение целевой функции, также
называемой стоимостной функцией. При использовании р обучающих векторов
<х,а!> для обучения сети, включающей М выходных нейронов, целевую функ-
цию можно определить эвклидовой метрикой вида

Е =1 Ён у“ -‹""’ н’=1 Ё Ёёо?” -‹‘:"’›’— (11)
2 1‹=1 2 к=н=1

Выходные сигналы нейрона у; являются функциями весов сети шд, значения
которых уточняются в процессе обучения по критерию минимизации целевой
функции. Ф

 

11 1‘: 1‘: т
Рис. 3.1. Структура однослойной сипиоидальной нейронной сети

Расположенные на одном уровне нейроны функционируют независимо друг
от друга, поэтому возможности такой сети ограничиваются свойствами
отдельных нейронов. Веса нейронов образуют определениое пространство
решений. Следует учитывать, что каждый нейрон реализует функциональ-

1‘!
ное отображение у; = ПЕ дху). Принимая во внимание, что сигмоидальная
1=0

функция ](=‘=) представляет собой непрерывный аналог одноступенчатой
пороговой функции, можно заметить, что выходной сигнал нейрона (значение 1

или 0) будет зависеть от знака выражения Ёьшт. Это уравнение линейно
‚=
относительно весов шд. Выходной сигнал у; при фиксированных значениях весов
зависит от расположения входного вектора х, который определяет гипер-
плоскость, разделяющую многомерное пространство на два подпространства.
Поэтому задача классификации (приписываъшя значения 0 или 1 выходному

сигналу нейрона) может быть решена с помощью единственного нейрона, если

48 3. Однонапеавленныг ‚многослойные сети сигмоидального типа

она относится к классу задач линейной сепарации (например, с применением

логических функций АЫВ или ОК).

Продемонстрируем ограниченность возможностей однослойных сетей на
примере реализации двухвходовой логической функции ХОК [101]. Для
упрощения будем использовать функцию активации в виде одноступенчатого
порога. Множество данных для обучения логической функции ХОК представлеио
в табл. 3.1.

Таблица 3.1

Множество данных
для обучения функции ХОВ

Легко показать, что в этом случае невозможно провести единственную лииию,
разделяющую пространство данных на два подпространства, из которых одно
соответствовало бы входному сигналу 1, а
другое — 0 (на рис. 3.2 заштрихованная об-
ласть относится к одному классу, а неза-
штрихованная — ко второму). Внутри заштри-
хованной области выходной сигнал нейроиа
должен быть равен 1, а за ее пределами — 0.
Такое условие не может быть выполнено при
использовании для разделения пространства
единственной прямой (одного нейрона)
независимо от значений параметров этой
прямой ( весов ищ), ищ, шд). Таким образом,
однослойный персептрон не в состоянии
реализовать даже такую несложную функцию,
Рис. 3.2. Иллюстрация иевозмож- как ХОК. Эту проблему легко разрешить
ности линейного разделения обу- путем расширения искусственной нейронной
чающих данных, соответствую- сети. С этой целью добавим в слой еще один

щих логической функции ХОК нейрон и подберем веса обоих нейронов

таким образом, чтобы они разделяли прост-

ранство на две части в зависимости от

входного вектора х = [х1, х;]т: щ=ищ х; +

+ м; х; + шю > О и щ = щ; х; + щ; х; + шю < О (первый нейрон) и и; = шд х; +

+ шд х; + то > О и и; = шд х; + т; х; + то < О (второй нейрон). Подбор весов

должен обеспечить разделение пространства, показанное на рис. 3.3. Общая часть

подмножеств, соответствующая условиям и1>О, и;>0, определила область, отде-
ленную от остального пространства, соответствующего условиям и; < О, и; < 0.

 

3.1. Однослойная сеть

49

 

Рис. 3.3. Решение проблемы нелинейного разделения путем применения двух линейных
разделителей

Добавлением на выходе сети еще одного слоя, состоящего из единственного
нейрона, можно реализовать функцию логического суммирования, выделяющую

общую часть подмножеств щ > 0,
и2>0. Окончательная структура ИНС,

вьшолняющей функцию ХОК, пред- _

ставлена на рис. 3.4. Следует отме-
тить, что добавление в сеть допол-
нительного слоя позволило разре-
шить проблему невозможности ли-
нейного разделения данных. Каждый
нейрон скрытого слоя осуществляет
дополнительное линейное разде-
ление плоскости, причем граница
такого раздела на области щ>О и
ид< 0 зависит от значений весов
нейрона. Выходной слой выполняет
соответствующую линейную ком-
бинацию (например, логическую
сумму) подобластей, на которые
множество. входных данных было
разделено нейронами скрытого слоя.

Несмотря на то, что однослойная

У

 

Рис. ЗА. Структура ИНС, выполняющей
’ функцию ХОК

ЕСТЬ ИМССТ НСООЛЬШОС ПРЗКТИЧВСКОВ ЗНЗЧЁНИВ, ее ПРОДОЛЖШОТ ИСПОЛЬЗОВЗТЬ там,
где ДЛЯ РЕШЕНИЯ ПОСТЗВЛСННОЙ задачи ДОСТЗТОЧНО И ОДНОГО СПОЯ нейронов.

‘-2152

50 3. Однонапвавленные многослойные сети сигмоидшьного типа

Выбор архитектуры такой сети весьма прост. Количество входных
нейронов определяется размерностью входного вектора х, а количество выходных
нейронов определяется размерностью вектора д. Обучение сети производится,
как правило, с учителем и является точной копией обучения одиночного
нейрона.



.‚ ,›'г

3.2. Многоспойный персептрон

3.2.1. Структура персептронной сети

;‚‘

Многослойная сеть состоит из нейронов, расположенных на разных уровнях,
причем, помимо входного и выходного слоев, имеется еще, как минимум, один
внутренний, т.е. скрытый, слой. Как уже отмечалось в литературе, посвященной
проблематике нейронных сетей, такая нейронная система называется
многослойным персептроном [46, 135, 136].

 

Рис. 3.5. Обобщенная структура двухслойной сигмоидальной нейронной сети (с одним
скрытым слоем)

На рис. 3.5 представлена сеть с одним скрытым слоем. Все последующие
рассуждения относятся к сетям именно такого типа. Обозначения сигналов и
весов также будут соответствовать этому рисунку. Веса нейронов скрытого слоя
пометим верхним индексом (1), а выходного слоя — верхним индексом (2).
Выходные сигналы нейронов скрытого слоя обозначим ‘у (/ = 1, 2, ..., К), а
выходного слоя -— И (/ = 1, 2, ..., М). Примем, что функция активации нейронов
задана в сигмоидальной униполярной или биполярной форме. Для упрощения
описания будем использовать расширенное обозначение входного вектора
сети в виде х = [х‹;, хд, ..., хит, где хо ё 1 соответствует единичному сигнал)
поляризации. С вектором х связаны два входных вектора сети: вектор

3 2 Многослойный певсептеан 51

фактических выходных сигналов у = [уд, уд, ..., уМ]Т и вектор ожидаемых
выходных сигналов е! = М), ф, ..., дМ]Т.

Цель обучения состоит в подборе таких значений весов шут и шут для всех
слоев сети, чтобы при заданном входном векторе х получить на выходе значения
сигналов у‚, которые с требуемой точностью будут совпадать с ожидаемыми
значениями д, для 1 = 1, 2, ..., М Если рассматривать единичный поляри-
зационный сигнал как один из компонентов входного вектора х, то веса
поляризации можно добавить в векторы весов соответствующих нейронов обоих
слоев. При таком подходе выходной сигнал 1-го нейрона скрытого слоя удается

описать функцией ‚

и

\д= у );„;"‚‹‚ ‚ (з.2)

1=0

в которой индекс 0 соответствует сигналу и весам поляризации, причем
щ; г 1, хо Е 1. В выходном слое К-й нейрон вырабатывает выходной сигнал,
определяемый как

К К А’
›»"(Ё”?и)="Ёш$ Еи#Ч‚ — (ар
х=0 1=0 1=0

Из формулы (33) следует, что на значение выходного сигнала влияют веса
обоих слоев, тогда как сигналы, вырабатываемые в скрытом слое, не зависят от
весов выходного слоя.

3.2.2. Алгоритм обратного распространения ошибки

Алгоритм обратного распространения ошибки определяет стратегию подбора
весов многослойной сети с применением градиентных методов оптимизации.
"Изобретенный заново” несколько раз [46], он в настоящее время считается одним
из наиболее эффективных алгоритмов обучения многослойной сети. Его основу
составляет целевая функция, формулируемая, как правило, в виде квадратичной
суммы разностей между фактическими и ожидаемыми значениями выходных
сигналов. В случае единичной обучающей выборки (х, к!) целевая функция
определяется в виде )`‹‚'

1 М 2
‚ ЕЙ") =Е 20% " ад) - ‹ (3-4)
ь=1
При большем количестве обучающих выборок 1 (1 = 1, 2, ..., р) целевая
функция превращается в сумму по всем выборкам
вшн1ЁЁоР—#Щ’— вы
1 ‚=и‹=1

Уточнение весов может проводиться после предъявления каждой обучающей
выборки (так называемый режим “0нлайн”) либо однократно после предъяв-

г

52 3. Однонапеавлгнныг многослойные сети сигмоидального типа

ления всех выборок, составляющих цикл обучения (режим “оффлайн”). В
последующем изложении используется целевая функция вида (3.4), которая
соответствует актуализации весов после предъявления каждой выборки.

Для упрощения можно считать, что цель обучения состоит в таком
определении значений весов нейронов каждого слоя сети, чтобы при
заданном входном векторе получить на выходе значения сигналов уд,
совпадающие с требуемой точностью с ожидаемыми значениями д; при
Ё = 1, 2, ..., М

Обучение сети с использованием алгоритма обратного распространения
ошибки проводится в несколько этапов. На первом из них предъявляется
обучающая выборка х и рассчитываются значения сигналов соответствующих
нейронов сети. При заданном векторе х определяются вначале значения
выходных сигналов щ скрытого слоя, а затем значения у; нейронов выходного
слоя. Для расчета применяются формулы (3.2) и (З.З). После получения значений
выходных сигналов у; становится возможным рассчитать фактическое значение
целевой функции Е(и’), заданной выражением (3.4). На втором этапе
минимизируется значение этой функции.

Если принять, что целевая функция непрерывна, то наиболее эффек-
тивными способами обучения оказываются градиентные методы оптими-
зации, согласно которым уточнение вектора весов (обучение) производится
по формуле

ш(/‹+1)=»›‹/‹)+А», (за)

Где г“
13"’: ПР("’)‚ (3-7)
Ё ‘ ’ -ч

п -— коэффициент обучения, а р(и’) — направление в многомерном прост-
ранстве и’.

Обучение многослойной сети с применением градиентных методов
требует определения вектора градиента относительно весов всех слоев
сети, что необходимо для правильного выбора направления р(и’). Эта
задача имеет очевидное решение только для весов выходного слоя. Для
других слоев создана специальная стратегия, которая в теории искус-
ственных нейронных сетей называется алгоритмом обратного распрост-
ранения ошибки (англ: еггог Ьас/сргорадайоп) [46, 51], отождествляемым, как
правило, с процедурой обучения сети. В соответствии с этим алгоритмом в
каждом цикле обучения выделяются следующие этапы [46]. "

1. Анализ нейронной сети в прямом направлении передачи инфор-
мации при генерации входных сигналов, составляющих очередной вектор х.
В результате такого анализа рассчитываются значения выходных сигналов
нейронов скрытых слоев и выходного слоя, а также соответствующие

5

3_2. Многослойный пгвсептвон 53

#04") 41114”) даёт’)
   ›..‚› 
слоя (т — количество слоев сети).
Создание сети обратного распространения ошибок путем изменения
направлений передачи сигналов, замена функций активации их
производными и подача на бывший выход (а в настоящий момент -
вход) сети возбуждения в виде разности между фактическим и ожидаемым
значением. Для определенной таким образом сети необходимо рассчитать
значения требуемых обратных разностей. 

Уточнение весов (обучение сети) производится по предложенным выше

формулам на основе результатов, полученных в п‚ 1 и 2, для оригинальной

сети и для сети обратного распространения ошибки.

4. Описанный в п. 1, 2 и 3 процесс следует повторить для всех обучающих
выборок, продолжая его вплоть до выполнения условия остановки
алгоритма. Действие алгоритма завершается в момент, когда норма
градиента упадет ниже априори заданного значения г, характеризующего
точность процесса обучения.

1

производные функций активации каждого

!)

Н)

Базовые формулы и их модификации для конкретных типов нейронных сетей
считаются классическими для теории нейронных сетей. По этой причине мы
рассмотрим только условия. относящиеся к сети с одним скрытым слоем.
Используемые обозначения представлены на рис. 3.5.

Как и ранее, количество входных узлов обозначим буквой Н, количество
нейронов в скрытом слое К, а количество нейронов в выходном слое М Будем
использовать сигмоидальную функцию активации этих нейронов. Основу
алгоритма составляет расчет значения целевой функции как квадратичной
суммы разностей между фактическими и ожидаемыми значениями выходных
сигналов сети. В случае единичной обучающей выборки (х, д) целевая
функция задается формулой (3.4)‚ а для множества обучающих выборок
‚т (1 = 1, 2, ..., р) - формулой (3.5). Для упрощения излагаемого материала будем
использовать целевую функцию вида (3 .4)‚ которая позволяет уточнять веса после
предъявления каждой обучающей выборки.

С учетом обозначений, введенных на рис. 3.5, эта функция определяется
выражением

ч.

Е=ЁМ[‘(Ё“Ё"‘)""‘] ‘ЁМ Ёшё?’ ЁЩМ —‹‘„‹ ‚ (18)

1‹=| 1-0 ]=О

Конкретные компоненты градиента рассчитываются дифференцированием
зависимости (З.8). В первую очередь подбираются веса нейронов выходного слоя.
Для выходных весов получаем:

(1)
=(У:—‹1ЛШУ;‚ (за)

(2) 2
дшд  )

 

54 3. Однонапеаштенньте ‚многослойные сети сигмоидапьного типа

2
д/(и! ’›
дИЁЁ)
|
ветствующий компонент градиента относительно весов нейронов выходного слоя

можно представить в виде

(2

к р ‚ .
где и, ’ = Еотиэди]. Если ввести обозначение ЕР’ =(у‚ -а'‚) ‚ то соот-

дЕ

(1)
дшд

=д}"»‚. (310)

1

Компоненты градиента относительно нейронов скрытого слоя определяются
по тому же принципу, однако они описываются другой, более сложной
зависимостью, следующей из существования функции, заданной в виде

дЕ = ЁЁЩ —д‚‹)—— . (зм)

ат?) ь=| Ф’, дшф т

  1

.г5 ›‘

ПОСЛЕ конкретизации ОТДВПЬНЫХ СОСТЗВЛЯЮЩИХ ЭТОГО выражения ПОЛУЧЗВМЗ

м а (1) а (1)
 ё 851% = Ебд —д‚д`1:;;:) Жду 21:23) ‚‹‚ .  (312)
. й _ ‚с ‚ .
Если ввести обозначение в ‘ ‘=  ч’ ‚
 к
д (2) д (п
дЕ1)=Ё[(у‚‘ _‹1‚‹)_ШШ‹Ё)ДШ ’ (313)

1ы_

дну’ дн!" ' 1 ‘

:‘ гЁЬ’ 1 ;\›Н‚ \: "
ТО ПОПУЧИМ выражение, ОПРЭДЭЛЯЮЩСЁ КОМПОНЭНТЫ градиента ОТНОСИТЭПЬНО
ВССОВ НСйрОНОВ СКрЫТОГО СЛОЯ В виде

ав 
= д}"х‚‚  (314)

 

В обоих случаях (формулы (310) и (314)) описание градиента имеет
аналогичную структуру и представляется произведением двух сигналов: первый
соответствует начальному узлу данной взвешенной связи, а второй — величине
погрешности, перенесенной на узел, с которым эта связь установлена.
Определение вектора градиента очень важно для последующего процесса
уточнения весов. В классическом алгоритме обратного распространения ошибки
фактор р(и’), учитываемый в выражении (3.6), задает направление отрицательного
градиента, поэтому

Аш=—п7Е(и’).  ‘ (315)

В следующем разделе представляются другие, более эффективные методы
выбора направления р(и’).

3.3 Потоковыег а ы и ихп имгнение для ггне а ииг адиента 55

3.3. Потоковые графы и их применение
для генерации градиента

Знакомство с формулами для расчета градиента показывает, что они
довольно сложны и неудобны для практического применения, особенно
если сеть содержит более одного скрытого слоя. Поэтому представляется
интересным, что на основе метода потоковых графов удается построить
очень простые правила формирования компонентов градиента, которые
имеют постоянную структуру, не зависящую от сложности сети. При этом базу
таких правил составляют соотношения, полученные в результате анализа
чувствительности сети методом сопряженньж элементов. В теории систем [114]
под полной чувствительностью объекта понимается производная любого
циркулирующего в нем сигнала относительно значеъшй весов, которая может
быть рассчитана на основании знаний о сигналах, распространяющихся по
обычному графу (обозначаемому С?) и сопряженному с ним графу (обоз-
начаемому д). Граф д определяется как исходный граф д, в котором
направленность всех дуг изменена на противоположную. Линейная дуга графа д
и соответствующая ей дуга сопряженного графа д имеют идентичные описания.
В случае нелинейной связи /(х‚ 1:), где х — входной сигнал, а 1с — параметр,
соответствующая ей дуга графа д линеарнзуется с коэффициентом

в = ЁДЁ , рассчитанным для фактического входного сигнала х графа д.
Эх

Как показано в работах [113, 114, 126], метод расчета чувствительности
нейронной сети с использованием потоковых графов основан на анализе
исходного графа д и сопряженного с ним графа д при возбуждении
последнего еднничным сигналом, подаваемым на вход д (соответствую-
щий выходу д). Чувствительность графа д относительно параметров дуг
этого графа к произвольному входному сигналу щ) можно выразить сле-
дующим образом:

’ для линейной дуги шу графа д

ц д

‹1\’‹,
Ё г’? 2 у
‘ дм’ 1

Ч

"‚ , (3.16)

где шу — это коэффициент усиления линейной дуги, направленной от
]-го узла к 1-му; хд обозначает сигнал 1-го узла графа д, а ‘Ё — сигнал
Е-го узла сопряженного графа д, для которого в качестве входного сигнала
задается значение 9д= 1;

’ для нелинейной дуги графа д, объединяющей 1-й и К-й узлы и описы-
ваемой функцией щ = [д 1(\’1, К), чувствительность относительно па-
раметра К определяется выражением ‚

‘до ^‚( ЭЙ: (ИК)

н Ж = ‚ ‚ (3-17)

дк ‹ ’

56 3. Однонапеавленные многослойные сети сигмоидального типа

д У К
где /Н( 1’ )
ЭК _
Обозначим и’ вектор оптимизированных параметров (весов щ) сис-

темы, представленной графом 6, и’= [и›1, ш;‚..., ш„ ]Т, а Е(и’) — Целе-
вую функцию. Тогда градиент УЕ (ш), сокращенно обозначаемый как
3(и’) = 7Е(и’), можно определить в виде

рассчитывается для сигнала щ 1-го узла графа С. ’

вы») вы») вы») Т

го"): д», ’ дм’,  ди’

(318)

И

(в этом выражении для обозначения элементов вектора и’ использован один
индекс 1= 1, 2,  п). Если представить целевую функцию в форме, учитывающей
только одну обучающую выборку

Е‹›‹»`=%Ёо‚ —‹‘‚›*‚ (119)

где ф обозначено ожидаемое значение й-го выходного нейрона, й= 1, 2, ..., М то
градиент целевой функции принимает вид:

го») = [г1("’)‚ м»)  ‚г„("’)1 ‘‚ 0.20)
в которой
«:‚‚‹›‹»=Ё‹у‚ «лёд 0.21)
1=1 и’),

Для задания вектора градиента также необходимы производные вы-
ходных сигналов у; графа относительно весов и’), (показатели их
чувствительности), умноженные на величину погрешности (уд-ф). Благодаря
использованию методов теории графов все эти операции (в том числе
и суммирование) можно выполнить за один шаг с помощью исходного
графа О и сопряженного с ним графа д при соблюдении соответст-
вующих условий возбуждения графа д. Как показано в [126], вследствие
линейности сопряженного графа все эти операции могут быть реализованы
автоматически в случае, когда в сопряженном графе вместо единичных
возбуждений генерируются сигналы в виде разностей между фактичес-
кими у; и ожидаемыми д; значениями выходных сигналов. Способ формирования
сопряженного графа д и методика его возбуждения для автоматичес-
кого расчета вектора градиента на основе анализа только двух графов 6 и д
представлены на рис. 3.6. При замене всех единичных возбуждений в
д на (уд- ф) любой компонент вектора градиента 31,0’) может быть
рассчитан по соответствующим сигналам исходного графа 6 и сопря-

женного с ним графа С точно так же, как и при определении обычной

3.3. Нотаковые графы и их применение для генееакии геедиента 57

‘ У1—д1

' Ум‘ дм

Рис. 3.6. Иллюстрация применения способа формирования и возбуждения сопряженного
графа: а) исходный граф С; б) сопряженный граф С

чувствительности. Для линейной дуги графа О, описываемой весом шд,
формула имеет вид: ‘
ЭЕ и’ ‚с — а
——Ц=\’]\’‚ . (3.22)
дшд

Для нелинейной дуги графа О, описываемой функцией шд; (щ,К)‚

получаем:

>

ЭЕЁ") _ ЭШЬЙУЬК)
ЭК ЭК ’
Представленные выражения применимы для любых систем (линейных,

нелинейных, рекуррентных и т.п.). Они практически применяются для анализа
однонаправленных многослойных нейронных сетей, описываемых потоковым

С

1, (323)

трафом прохождения сигналов.

Рассмотрим изображенную на рис. 3.7а типовую многослойную сеть
(состоящую из т слоев) с произвольной непрерывной функцией активации ней-
ронов. Количество нейронов в каждом слое будем обозначать  (1 = 1, 2, ...‚ т),
причем последний слой является выходным слоем сети, содержащим К‚„ = М
нейронов. Выходные сигналы нейронов в конкретных слоях обозначим 170‘),

причем для последнего слоя ‘уж’ = 39.

5

3. Однонап аапенные ‚многослойные сети сигмоидального типа

 

 
  
  

    

   
 

  

 “ х‘ „‚

‘э’ ‘г
й,

'\
А»

Рис. 3.7. Иллюстрация применения метода сопряженных графов для генерации
вектора градиента однонаправленной многослойной сети:
а) выходной граф сети; б) сопряженньпй граф

3.3. Потоковые г а ы и их и иенение для ггне а ии г адиента 59

Для определения компонентов градиента относительно весов конкретных
слоев сети будем применять формулировки, относящиеся к сопря-
женному графу. На рис 3.76 представлен сопряженный граф сети,
изображенной на рис. 3.7а, причем для уъшфикации описания все сигналы
в сопряженном графе обозначены символами с “крыжиком” (й). Сопряженный
граф возбуждается разностями между фактическими у; и ожидаемыми а’;
значениями выходных сигналов. Нелинейные дуги графа О заменяются в

сопряженном графе О производными ай”) , значения которых рассчитываются
Х
раздельно для каждого слоя в точках х = щ. Если, например, функция активации

нейронов имеет сигмоидальную униполярную форму 1’ (х) =   ,

фьёсх) = Дх)(1—](х)) рассчитывается непосредственно на основе известного зна-
чения сигмоидальной фушщии в точке х и не требует никаких дополнитель-
ных вычислений.

_ Опираясь на предложенный алгоритм определения градиента методами
теории графов, можно рассчитать конкретные компоненты вектора градиента
3(и’) для любого слоя нейронов:

ТО

9 ДЛЯ ВЫХОДНОГО СЛОЯ ’ ‚._— ‹ ‘

 

 7 д ф; ‚ г  = (т—1);‚`[(т);   (324)
0 для 1с-го скрытого слоя ‘ х   
   =\Э‹’‹—1)‚’;‚‹’‹);   (325)
’ для первого скрытого слоя
‘дуг’:   =убл1$щ д" ф   (326)
и

Из приведенных формул видно, что их структуры (при использо-
вании соответствующих обозначений сигналов) абсолютно идентичны
независимо от того, в каком слое нейронов находится учитываемый вес.
Сформулированное правило является чрезвычайно простым с прикладной
точки зрения, поскольку для расчета любого компонента градиента необ-
ходимо знать только два сигнала: от узла, из которого исходит взвешенная
дуга в оригинальном графе, и от узла, из которого исходит взвешенная
дуга в сопряженном графе. В этом смысле правило расчета может считаться
локальным.

Еще одним важным достоинством графического метода, помимо
значительного упрощения вычислительных процедур, считается возможность
учета равенства значений различных весов сети [114]. Если, например, вес со

6О 3. Однонапшвленные многослойные сети сигмоидального типа

значением и’ относится к дуге шд, соединяющей 1-й и 1-й узлы (в направ-
лении от ]-го к Е-му), и к дуге ш“, соединяющей 1с-й и 1-й узлы (в нап-
равлении от 1-го к 1с-му), то леп‹о заметить, что вес и’ будет присутствовать
в двух различных позициях выражения, определяющего целевую функцию.
Согласно правилу дифференцирования составной функции ее производная
представляется в виде суммы производных относительно шд и ицд. Следо-
вательно,

вы») _ дЕ + дЕ
дм’ дшд дшд,’
С учетом рассуждений относительно сопряженного графа при вводе

унифицированных обозначений сигналов для любых узлов в виде ъ’ (9) с
соответствующими индексами получаем окончательное выражение

(3.27)

ЁЁЁ = „он „ад.  (3.28)
ди’ ‘ ‚

Как следует из формулы (3.28), учет равенства отдельных весов (шд = шт)
не только не усложняет общую расчетную формулу, но, напротив, упро-
щает ее за счет уменьшения количества переменных. Необходимо отметить, что
совпадающие веса (англ.: зйагеа’ шейд/хгв) могут лежать как в одном и том
же, так и в совершенно разных слоях. Сущностъ формулы (3.28) при этом
совершенно не меняется. В этом заключается важнейшее отличне метода
генерации градиента, основанного на потоковых графах распространения
сигналов, от классического подхода, широко представленного в мировой
литературе [46, 51].

3.4. Г радиентные алгоритмы обучения сети

3.4.1. Основные положения

Задачу обучения нейронной сети будем рассматривать на данном этапе
как требование минимизировать априори определенную целевую
функцию Е(и’). При таком подходе можно применять для обучения алго-
ритмы, которые в теории оптимизации считаются наиболее эффек-
тивными. К ним, без сомнения, относятся градиентные методы, чью
основу составляет выявление градиента целевой функции. Они связаны с
разложением целевой функции Е(и›) в ряд Тейлора в ближайшей окрест-
ности точки имеющегося решения и’. В случае целевой функции от многих
переменных (и’= [ш1,ш2,..., и’„]Т) такое представление связывается с окрест-
ностью ранее определенной точки (в частности, при старте алгоритма
это исходная точка щ) в направлении р. Подобное разложение описы-

3.4. Г Еадиентные алгоритмы обучения сети 61

вается универсальной формулой вида [39‚ 170] к

Е("’+1’)=Е(“‘)+[:(“’)]Тр+%рТН(“’)1’+--—‚ 0.29)

ав ав ав Т
где 3(и’) = 7Е= 51? дщ  д — это вектор традиента, а симметричная

квадратная матрица

шп

3215 ат
‹ ’ ’ ди/‚дш, " дш‚дш„
Н (т) =   
315 да;
дш„дш‚ " ди’„дш„

является матрицей производных второго порядка, называемой гессианом.

В выражении (3.29) р играет роль направляющего вектора, зависящего
от фактических значений вектора и’. На практике чаще всего рассчитываются
три первых члена ряда (3.29), а последующие просто игнорируются. При этом
зависимость (329) может считаться квадратичным приближением целевой
функции Е (ш) в ближайшей окрестности найденной точки и’ с точностью,
равной локальной погрешности отсеченной части 0013), где И = || р ||‚ Для
упрощения описания значения переменных, полученные в 1с-м цикле, будем
записывать с нижним индексом К. Точкой решения ш=шд будем счнтать
точку в которой достигается минимум целевой функции Е(ш) и д(щ) = О, а
гессиан Н(и’д) является положительно определенным [39, 42]. При выпол-
нении эгтих условий функция в любой точке, лежащей в окрестности щ,
имеет большее значение, чем в точке щ, поэтому точка щ является
решением, соответствующим критерию минимизации целевой функции.

В процессе поиска минимального значения целевой функции направ-
ление поиска р и шаг 11 подбираются таким образом, чтобы для каждой
очередной точки и’;‚+1 = щ + пдрд выполнялось условие Е(ю;‚+1) < Е(ш;‚). Поиск
минимума продолжается, пока норма градиента не упадет ниже априори
заданного значения допустимой погрешности либо пока не будет превышено
максимальное время вычислений (количество итераций).

Универсальный оптимизационный алгоритм обучения нейронной сети можно
представить в следующем виде (будем считать, что начальное значение
оптимизируемого вектора известно и составляет щ = шд):

1. Проверка сходимости и оптимальности текущего решения щ. Если
точка щ отвечает градиентным условиям остановки процесса - завершение
вычислений. В противном случае перейти к п.2.

2. Определение вектора направления оптимизации рд для точки щ.

З. Выбор величины шага щ в направлении рд, при котором выполняется
условие Е (щ + т, рд) < Е(ш;‹).

62 3. Однонапвавленные многослойные сети сигмоидального типа

4. Определение нового решения ты = щ + пдрд, а также соответствую-
щих ему значений Е (щ) и 3001,), а если требуется - то и Н(шд), и возврат
к п.1.

3.4.2. Алгоритм наискорейшего спуска

Если при разложении целевой функции Е(и›) в ряд Тейлора ограничиться ее
линейным приближением, то мы получим алгоритм наискорейшего спуска. Для
выполнения соотношения Е(и’‚„1) < Е (щ) достаточно подобрать д(шд)тр < 0.
Условию уменьшения значения целевой функции отвечает выбор вектора
направления

‘ ‘ и =—а6"‚‚). (330)

Именно выражением (3.3О) определяется вектор направления р в методе
наискорейшего спуска. _

Ограничение слагаемым первого порядка при разложении функции
в ряд Тейлора не позволяет использовать информацию о ее кривизне. Это
обусловливает медленную сходимость метода (она остается линейной).
Указанный недостаток, а также резкое замедление минимизации в ближайшей
окрестности точки оптимального решения, когда градиент принимает очень
малые значения, делают алгоритм наискорейшего спуска низкоэффекгивным. Тем
не менее с учетом его простоты, невысоких требований к объему памяти и
относительно небольшой вычислительной сложности именно этот метод в
течение многих лет бьш и остается в настоящее время основным способом
обучения многослойных сетей. Повысить его эффективность удается путем
модификации (как правило, эвристической) выражения, определяющего
направление. Хорошие результаты приносит применение метода обучения
с так называемым моментом. При этом подходе уточнение весов сети
(ш;‹+1=ш;‚+Ашд) производится с учетом модифицированной формулы опре-
деления значения Ащ

2‘‹н -;:\

Ащ= три + ‹1'(И’к—“ч‹—1)‚ *‘ (3-31)

где а - это коэффициент момента, принимающий значения в интервале
[0‚ 1]. Первое слагаемое этого выражения соответствует обычному обучению
по методу наискорейшего спуска, тогда как второе учитывает последнее
изменение весов и не зависит от фактического значения градиента. Чем боль-
ше значение коэффициента а, тем большее значение оказывает показатель
момента на подбор весов. Это влияние существенно возрастает на плоских
участках целевой функции, а также вблизи локального минимума, где значе-
ние градиента близко к нулю.

На плоских участках целевой функции приращение весов (при постоянном
значении коэффициента обучения щ = п) остается приблизительно одним и

1

 3 \

3.4. Г Еадиентные алгоритмы обичения сети 63

тем же. Это означает, что Ан’), = црд + (ХАшд, поэтому эффективное приращение
значений весов можно описать отношением

А„›„= ‘7 р,„.  (332)
 1-(1  . —‘  

При значении а = 0,9 это соответствует 1О-кратному увеличению
эффективного значения коэффициента обучения и, следовательно, также 1О-крат-
ному ускорению процесса обучения.

Вблизи локального минимума показатель момента, не связанный с
градиентом, может вызвать слишком большое изменение весов, приводящее к
увеличению значения целевой функции и к выходу из “зоны притяжения”
этого минимума. При малых значениях градиента показатель момента
начинает доминировать в выражении (3.31), что приводит к такому
приращению весов Ащ, которое соответствует увеличению значения
целевой функции, позволяющему выйти из зоны локального минимума.
Однако показатель момента не должен полностью доминировать на
протяжении всего процесса обучения, поскольку это привело бы к
нестабильности алгоритма. Для предотвращения такого избыточного
доминирования значение целевой функции Е контролируется так, чтобы
допускать его увеличение только в ограниченных пределах, например
не более 4%. При таком подходе, если на очередных (1с-м и (/‹+1)-м)
шагах итерации выполняется условие Е(1с+1)<1‚О4Е(1‹), то изменения
игнорируюгтся и считается, что (щ — ш“) = О. При этом показатель градиента
начинает доминировать над показателем момента и процесс развивается в
направлении минимизации, заданном вектором градиента. Следует подчеркнуть,
что подбор величины коэффициента момента является непростым делом и
требует проведения большого количества экспериментов, имеющих целью
выбрать такое значение, которое наилучшим образом отражало бы специфику
решаемой проблемы.

: ‹ имей. . ‚ ‚„

3.4.3. Алгоритм переменной метрики

В методе переменной метрики используется квадратичное приближение
функции Е(и’) в окрестности полученного решения щ. Если в формуле (3.29)
ограничиться тремя первыми слагаемыми, то получим: 

‚_‚!‘‹':г'‹д —.
.‚‚‚‚ _. ‚1 в“,

+1р{н(ш,‚)р‚‚ +0(и3).

2 (3.33)

Щщ т) э Е‹›‹›‚‚›+г‹›‹›‚‹›‘р‚‚

Длядостижения минимума функции (3.33) требуется, чтобы ——7—— = .
Рь
При выполнении соответствующего дифференцирования можно получить

УСПОВИС ОПТИМВЛЬНОСТИ В ВИДЕ

8("’1‹)+ Н("’1‹)Р1‹ = О -

д}

64 3. Однонапеавленные многослойные сети сиамоидальнога типа

Элементарное преобразование этого выражения дает очевидное решение:

1›‚‚ =—[Н("’‚‹)Гв(»щ‹)‚ 0.34)

Формула (3.34) однозначно указывает направление рд, которое гарантирует
достижение минимального для данного шага значения целевой функции. Из него
следует, что для определения этого направления необходимо в каждом цикле
вычислять значение градиента 3 и гессиана Н в точке известного (последнего)
решения щ.

Формула (3.34), представляющая собой основу ньютоновского алгоритма
оптимизации, является чисто теоретическим выражением, поскольку ее приме-
нение требует положительной определенности гессиана на каждом шаге, что в
общем случае практически неосуществимо. По этой причине в имеющихся
реализациях алгоритма, как правило, вместо точно определенного гессиана
Н(и’‚‚) используется его приближение С(и’д). Одним из наиболее популярных
считается метод переменной метрики [39, 170]. В соответствии с этим методом на
каждом шаге гессиан или обратная ему величина, полученная на предыдущем
шаге, модифицируется на величину некоторой поправки. Если прирост вектора и’),
и градиента 3 на двух последовательных шагах итерации обозначить
соответственно в), и ц, т.е. вд = и’), — ты и п, = д(ш;‚) — 300“), а матрицу,
обратную приближению гессиана Уд = [С(ш;‚)]—1, Ум = [С(шд_1)]—1‚ обозначить У,
то в соответствии с очень эффективной формулой Бройдена-Флетчера-
Гольдфарба—Шенно (англ.: Вгоудеп-Ртгсйег-6о1а]агЬ—$Иаппо — ВРСЗ) процесс
уточнения значения матрицы У можно описать рекуррентной зависимостью [39]:

т т т т
’1‹ Уь-Пк $1‹$1‹ _ 5Нь Ук-Шдь

Т Т Т . (335)
$к 4 $1‹ ’1‹ $1‹ И

УТ =\/,‚_‚ + 1+

В другом известном алгоритме Девидона-Флетчера-Пауэлла (англ.: Пауйдоп-
Р1е1с11ег-Роше11 - ВРР) значение гессиана уточняется согласно выражению [39]

т т
51‹51‹ У1‹—1"1‹"1‹ Ук-т

УК =У1‹-—1 + Т — Т — 
5к "к "к Ук-НЪ

В качестве начального значения обычно принимается Уд = 1, а первая
итерация проводится в соответствии с алгоритмом наискорейшего спуска. Как
показано в [39‚ 170], при начальном значении Уд — 1 и при использовании
направленной минимизации на каждом шаге оптимизации можно обеспечить
положительную определенность аппроксимированной матрицы гессиана.
Направленная минимизация необходима при реализации как стратегии ВРОБ, так
и ВРР, причем в соответствии с проведенными тестами метод ВРСЗЗ менее
чувствителен к различным погрешностям вычислительного процесса. По этой
причине, несмотря ‚та несколько большую вычислительную сложность, мегод
ВРСЗЗ применяется чаще, чем ВРР.

3.4. Геадиентные алгоритмы обучения сети 65

Метод переменной метрики характеризуется более быстрой сходимостью,
чем метод наискорейшего спуска. Кроме того, факт положительной
определенности гессиана на каждом шаге итерации придает уверенность в том,
что выполнение условия д(ш;‚) = О действительно гарантирует решение
проблемы оптимизации. Именно этот метод считается в настоящее время
одним из наиболее эффективных способов оптимизации функции нескольких
переменных. Его недостаток состоит в относительно большой вычислительной
сложности (связанной с необходимостью расчета в каждом цикле п2 элементов
гессиана), а также в использовании значительных объемов памяти для хранения
элементов гессиана, что в случае оптимизации функции с большим количеством
переменных может стать серьезной проблемой. По этой причине метод
переменной метрики применяется для не очень больших сетей. В частности, с
использованием персонального компьютера была доказана его эффективность для
сети, содержащей не более тысячи взвешенных связей.

3.4.4. Алгоритм Левенберга-Марквардта

Другим приложением ньютоновской стратегии оптимизации является
алгоритм Левенберга-Марквардта [39]. При его использовании точное значение
гессиана Н(и’) в формуле (3.34) заменяется аппроксимированным значением
6(и’), которое рассчитывается на основе содержащейся в градиенте информации
с учетом некоторого регуляризационного фактора.

Для описания этого метода представим целевую функцию в виде, отвечающем
существованию единственной обучающей выборки, ‘ у

1 м 2 .
Еоо=5;Ьоо1‚ р ода
где е; = [уд (ш) - ф]. При использовании обозначений
За 21 да
е‘ („д дм’, дм’,  ди’„
„(щ ЁЁ. ЁЗ.  дег
е("’) = ‚ -1(“’)= дш, дщ ди’„ ‚ (3-38)
ем ("д де; дед,  дем
дм’, дшг  ди’„

вектор градиента и аппроксимированная матрица гессиана, соответствующие
целевой функции (3.37), определяются в виде

ни=ЫшЖам‚ от)
с‹„›) =[.т‹‚‹›)1’.1‹„›)+в‹„›) , (зло)

где В(и’) обозначены компоненты гессиана Н(и’), содержащие высшие

5-2162

66 3. Однонапеавленные многослойные сети сигмоидального типа

производные относительно и’. Сущность подхода Левенберга-Марквардта
состоит в аппроксимации В(и’) с помощью регуляризационного фактора и], в
котором переменная ъ’, называемая параметром Левенберга-Марквардта, является
скалярной величиной, изменяющейся в процессе оптимизации. Таким образом,
аппроксимированная матрица гессиана на Аг-м шаге алгоритма приобретает вид:

90%) =[5‹"’1‹)1Т1(“’;‹)+\’ь1 - (3-41)

В начале процесса обучения, когда фактическое значение щ еще далеко
от искомого решения (велико значение вектора погрешности е), исполь-
зуется значение параметра щ, намного превышающее собственное значение
матрицы [З (щ) 173 (шд). В таком случае гессиан фактически подменяется
регуляризационным фактором:

с("’1‹)5 Ул 1‚ (3-42)
а направление минимизации выбирается по методу наискорейшего спуска:
ат )
и =———4‘—. (143)
Щ

По мере уменьшения погрешности и приближения к искомому решению
величина параметра щ понижается и первое слагаемое в формуле (3.40)
начинает играть все более важную роль.

На эффективность алгоритма влияет грамотный подбор величины щ.
Слишком большое начальное значение щ по мере прогресса оптимизации должно
уменьшаться вплоть до нуля при достижении фактического решения, близкого к
искомому. Известны различные способы подбора этого значения, но мы
ограничимся описанием только одной оригинальной методики, предложенной
Д. Марквардтом [95]. Пусть значения целевой функции на 1с-м и (1с—1)-м шагах
итерации обозначаются соответственно Ед и Е „д, а значения параметра и на этих
же шагах - щ и 14.1. Коэффициент уменьшения значения 1’ обозначим г, при-
чем г>1. В соответствии с классическим алгоритмом Левенберга-Марквардта

ЗНЭЧСНИС У ИЗМСНЯСТСЯ ПО СЛСДУЮЩЁЙ СХСМСЁ

—1
о если Е (у? ) 5 Ед, то принять щ‹= у’; ;

’ если Е ("М )>Е;‹ и Е (щ‹_1) <Ед, то принять щ, = щ‚_1 ;
Г’

’ если Е(""—' )> Ед и Е (ид_1)>Е;‹, то увеличить последовательно т раз
Г‘

значение ъ’ до достижения Е (щ‚_1 г“) 5 Ед, одновременно принимая щ‹= мы г“.

Такая процедура изменения значения и выполняется до момента, в котором
так называемый коэффициент верности отображения о, рассчитываемый по

формуле
Ёь — Ёь-1

‹;= —Ё——————————Т—— , (144)
[АИ] гл + О‚5 [АИ] ЩАЩ ’ ‹

3.4. Г Еадшгнтные алгоритмы обучения сети 67

достигнет значения, близкого к едиъшце. При этом квадратичная аппроксимация
целевой функции имеет высокую степень совпадения с истинными значениями,
что свидетельствует о близости оптимального решения. В такой ситуации
регуляризационный фактор щ‹1 в формуле (3.41) может быть опущен (щ, = 0),
процесс определения гессиана сводится к непосредственной аппроксимации
первого порядка, а алгоритм Левенберга-Марквардта превращается в алгоритм
Гаусса-Ньютона, характеризующийся квадратичной сходимостью к опти-
мальному решению.

3.4.5. Алгоритм сопряженных градиентов

В этом методе при выборе направления минимизации не используется
информация о гессиане. Направление поиска р], выбирается таким образом,
чтобы оно было ортогональным и сопряженным ко всем предыдущим
направлениям ро, рд, ..., р;‹_1. Множество векторов рд, 1 = 0, 1, ..., К, будет
ВЗЗИМНО СОПРЯЖСННЫМ ОТНОСИТЁЛЬНО матрицы С, ЕСЛИ

дар, =о‚ [т] _ (145)

Как показано в [39, 167], вектор рд, удовлетворяющий заданным выше
условиям, имеет вид:

Рк =—81‹ + дыры ‚ (3.46)

где 31, = 3(ш;‹) обозначает фактическое значение вектора градиента.

Из формулы (3.46) следует, что новое направление минимизации зависит
только от значения традиента в точке решения щ и от предыдущего направления
поиска р“, умноженного на коэффициент сопряжения Вы. Этот коэффициент
играет очень важную роль, аккумулируя в себе информацию о предыдущих
направлениях поиска. Существуют различные правила расчета его значения.
Наиболее известны среди них [39, 170]

в’(в —в _)
д‚(_1=_ь4__ц

Т (3 .47)
Ек-п Еь-п

д“ = 21 (ш —г‚‹—1)‚
—Р1‹—1Е1‹—1

Ввиду накопления погрешностей окрутления в последовательных циклах
вычислений практическое применение метода сопряженных градиентов связано с
постепенной утратой свойства ортогональности между векторами направлений
минимизации. По этой причине после вьшолнения п итераций (значение п
рассчитывается как функция от количества переменных, подлежащих
оптимизации) производится рестарт процедуры, на первом шаге которой
направление минимизации из точки полученного решения выбирается по
алгоритму иаискорейшего спуска. Метод сопряженных градиентов имеет

51

(3.48)

‘б

68 3. Однонаправленные многослойные сети сиамоидального типа

сходимость, близкую к линейной, и он менее эффективен, чем метод переменной
метрики‚ однако заметно быстрее метода наискорейшего спуска. Он широко
применяется как единственно эффективный алгоритм оптимизации при весьма
значительном количестве переменных, которое может достигать нескольких
десятков тысяч. Благодаря невысоким требованиям к памяти и относительно
низкой вычислительной сложности метод сопряженных градиентов позволяет
успешно решать очень серьезные оптимизационные задачи.

3.5. Подбор коэффициента обучения

Алгоритмы, представленные в предыдущем подразделе, позволяют определить
только направление, в котором уменьшается целевая функция, но не говорят
ничего о величине шага, при котором эта функция может получить минимальное
значение. После выбора правильного направления р; следует определить на нем
новую точку решения шт, в которой будет выполняться условие Е(ш;‹+1) < Е(шд).
Необходимо подобрать такое значение 111„ чтобы новое решение шт = щ + цд рд
лежало как можно ближе к минимуму функции Е(и’) в направлении рд. Грамот-
ный подбор коэффициента п; оказывает огромное влияние на сходимость
алгоритма оптимизации к минимуму целевой функции. Чем сильнее велтшна
т отличается от значения, при котором Е(и’) достигает минимума в выбранном
направлении рд, тем большее количество итераций потребуется для поиска
оптимального решения. Слишком малое значение п не позволяет минимизировать
целевую функцию за один шаг и вызывает необходимость повторно двигаться в
том же направлении. Слишком большой шаг приводит к “перепрыгиванию” через
минимум функции и фактически заставляет возвращаться к нему.

Существуют различные способы подбора значения п, называемого в теории
нейронных сетей коэффициентом обучения. Простейший из них (относительно
редко применяемый в настоящее время, главным образом для обучения в режиме
“онлайн”) основан на фиксации постоянного значения т) на весь период
оптимизации. Этот способ практически используется только совместно с методом
наискорейшего спуска. Он имеет низкую эффективность, поскольку значение
коэффициента обучения никак не зависит от вектора фактического градиента и,
следовательно, от направления р на данной итерации. Величина п подбирается,
как правило, раздельно для каждого слоя сети с использованием различных
эмпирических зависимостей. Один из подходов состоит в определении
минимального значения коэффициента п для каждого слоя по формуле [72]

. 1
пЗппп —- ‚ (3_49)

п: а‘! 1

где п; обозначает количество входов д-го нейрона в слое.
Другой более эффективный метод основан на адаптивном подборе коэф-
фициента п с учетом фактической динамики величины целевой функции в

результате ОбуЧСНИЯ. В СООТВСТСТВИИ С ЭТИМ МСТОДОМ стратегия ИЗМЕНЕНИЯ

3.5. Подбо коз и иента об чения 69

значения п определяется путем сравнения суммарной погрешности г на Е-й
итерации с ее предыдущим значением, причем г рассчитывается по формуле

‘ › (3.50)

 

т"

Для ускорения процесса обучения следует стремиться к непрерывному
увеличению п при одновременном контроле прироста погрешности г по
сравнению с ее значением на предыдущем шаге. Незначительный рост этой
погрешности считается допустимым.

Если погрешности на (1——1) и й-й итерациях обозначить соответственно вы и г;,
а коэффициенты обучения на этих же итерациях — п“ и 11„ то в случае
а > 1с„‚е‚_1 (1с„ - коэффициент допустимого прироста погрешности) значение 11
должно уменьшаться в соответствии с формулой

ты =7ТгРа , (3.51)

где р,‘ - коэффициент уменьшения п. В противном случае, когда г; 5 /‹„г;.1,
принимается

пнт = тт, ` (352)

где р; - коэффициент увеличения п. Несмотря на некоторое возрастание обгьема
вычислений (необходимых для дополнительного расчета значений г), возможно
существенное ускорение процесса обучения. Например, реализация представ-
ленной стратегии в программе МАТЬАВ [27] со значениями 1с„‚ = 1,41, рд = 0,7,
р;= 1,05 позволила в несколько раз ускорить обучение при решении проблемы
аппроксимации нелинейных функций.

Интересно проследнть характер изменения коэффициента 11 в процессе
обучения. Как правило, на начальных этапах доминирует тенденция к его
увеличению, однако при достижении некоторого квазистационарного состояния
величина п постепенно уменьшается, но не монотонно, а циклически возрастая
и понижаясь в следующих друг за другом циклах.

Однако необходимо подчеркнуть, что адаптивный метод подбора п сильно
зависит от вида целевой функции и значений коэффициентов 1с„, рд и рд.
Значения, оптимальные для функции одного вида, могут замедлять процесс
обучения при использовании другой функции. Поэтому при практической
реализации этого метода следует обращать внимание на механизмы контроля и
управления значениями коэффициентов, подбирая их в соответствии со
спецификой решаемой задачи.

Наиболее эффективный, хотя и наиболее сложный, метод подбора коэф-
фициента обучения связан с направленной минимизацией целевой функции в
выбранном заранее направлении рд. Необходимо так подобрать скалярное
значение т, чтобы новое решение ил,“ = щ +п;‚р;‚ СООТВЕГСТВОВЗЛО минимуму

целевой функции в данном направлении рд. В действительности получаемое
решение ш/‚Н только с определенным приближением может считаться настоящим

70 3. Однонапшвленные многослойные сети сиамоидального типа

минимумом. Это результат компромисса между объемом вычислений и влиянием
величины т на сходимость алгоритма.

Среди наиболее популярных способов направленной минимизации можно
выделить безградиентные и градиентные методы. В безградиентньхх методах
используется только информация о значениях целевой функции, а ее минимум
достигается в процессе последовательного уменьшения диапазона значений
вектора и’. Примерами могут служить методы деления пополам, золотого
сечения либо метод Фибоначчи [39,170]‚ различающиеся способом декомпо-
зиции получаемых поддиапазонов.

Заслуживает внимания метод аппроксимации целевой функции Е(и’) в
предварительно выбранном направлении р; с последующим расчетом минимума,
получаемого таким образом, функции одной переменной п. Выберем для
аппроксимации многочлен второго порядка вида

Е(и’) —› Р, (п) = «2112 + а111+а0 ‚ (353)

где а;‚ ад и ад обозначены коэффициенты, определяемые в каждом цикле
оптимизации. Выражение (3.53) — это многочлен Р; одной скалярной
переменной п. Если для расчета входящих в Р; коэффициентов исполь-
зуются три произвольные точки щ, и’; и юд, лежащие в направлении рд,
те. и’; = и’ + 171 рд, и’; = и’ + 11; рд, и’; = и’ + 113 рд (в этом выражении и’
обозначено предыдущее решение), а соответствующие этим точкам
значения целевой функции Е(и’) обозначены Е1 = Е(и’;), Е; = Е(и’;), Е; = Е(ш3),
то

Р;‹П1)=Е1‚Р;(П;)=Е;‚Р;(П;)=Е; — (3-54)

Коэффициенты а;‚ ад и ао многочлена Р; рассчитываются в соответствии

с системой линейных уравнений, описываемых в (3.54). Для определения
а)’,

‘111
нулю, что позволяет получить значение т] в виде птд, =

МИНИМУМН ЭТОГО МНОГОЧЛСНЗ ЕГО производная = 20211 +01 ПРИРВВНИВЗСТСЯ К

2а2
выражений для Е1,Е; и Е; в формулу расчета п,“ получаем:

. После подстановки

_1(712 "711)2(Е2 "Ез)`т2 —71з)2‹Е2 —Е1) _ (355)
2 (П; —'771)‹Е2 —Е;)—(П2 ЧЬХЕ; “Е”

Однако лучшим решением считается применение градиентньхх методов, в
которых, кроме значения функции, учитывается также и ее производная вдоль
направляющего вектора рд. Они позволяют значительно ускорить достижение
минимума, поскольку используют информацию о направлении уменьшения
величины целевой функции. В такой ситуации применяется, как правило,
аппроксимирующий многочлен третьего порядка

ппйп = "2

Рз (П) = аЗЦЗ + а2112 + ат + ао . (356)

Значения четырех коэффициентов а; этого многочлена можно получить
исходя из информации о величине функции и ее производной всего лишь в двух

3.6. Эв истические методы об чения сети 71

 

точках. Если приравнять к нулю производную многочлена относительно п, то
можно получить формулу для расчета птдп в виде

Е.‘ \м‚ (357)

птйп = за: ‚

Более подробное описание этого подхода можно найти в первоисточниках,
посвященных теории оптимизации [39,170].

Алгоритм обучения многослойного персептрона реализован в Институте
теоретической электротехники и электроизмерений Варшавского политех-
нического университета на языке С++ в виде программы Непеасй [144]. Для
выбора направления минимизации в нем применяется метод переменной метрики
или классический метод сопряженных градиентов, а для расчета оптимального
значения коэффициента обучения — аппроксимация многочленом третьего
порядка. Программа позволяет работать с произвольным количеством слоев,
причем функция активации нейронов каждого слоя задается индивидуально. На
выбор предлагаются функции: сигмоидальная униполярная (Зддт ), сигмо-
идальная биполярная (Вф), а также линейная (Цп). Градиент рассчитывается с
применением метода потоковых графов.

3.6. Эвристические методы обучения сети

Помимо алгоритмов обучения, реализующих апробированные методы
оптимизации нелинейной целевой функции (такие, как методы переменной
метрики, Левенберга-Марквардта либо сопряженных градиентов), создано
огромное количество алгоритмов эвристического тшта, представляющих собой в
основном модификацию методов наискорейшего спуска или сопряженных
градиентов. Подобные модификации широко известных алгоритмов связаны с
внесением в них некоторых изменений, ускоряющих (по мнению авторов)
процесс обучения. Как правило, такие методы не имеют серьезного
теоретического обоснования, особенно это относится к процедуре подбора
управляющих параметров. Однако в таких алгоритмах реализуется личный опыт
работы авторов с нейронными сетями. К наиболее известным эвристическим
алгоритмам относится Ёиёсйргор С. Фальмана [33] (использованный среди
прочих и в программе Сазсог [34]), а также КРКОР М. Ридмиллера и Х. Брауна
[133], реализованный в программе ЗНМЗ’ [178].

3.6.1. Алгоритм Оибскргор

Оийскртор содержит элементы, предотвращающие зацикливание в точке
неглубокого локального минимума, возникающего в результате работы нейрона
на фазе насыщения сигмоидальной кривой, где из-за близости к нулю
производной функции активации процесс обучения практически прекращается.

72 _ 3. Однонапеавленные многослойные сети сигмоидального типа

Вес шд на 1с-м шаге алгоритма изменяется согласно правилу

дЕ(‚‹›(1‹))

Ашд(1‹)= —П1‹ 

+щ(1‹) +а;“Аш„(1‹—1). (3.58)

ЭЕ
дшд ц
шего спуска, последнее слагаемое, - фактору момента, а среднии член ушд

предназначен для минимизации абсолютных значений весов. Коэффициент 1;
имеющий обычно малую величину (типовое значение у = 10-4), — это фактор,
приводящий к уменьшению весов вплоть до возможного разрыва соот-
ветствующих взвешенных связей. Константа п), - это коэффициент обучения,
который в данном алгоритме может иметь ненулевое значение т) (как правило,
0,015 по 5 0,6) на старте процесса обучения, когда Ашд (/с— 1)=0 либо когда
[дЕ(“’(/‹)) +

Эшд

Важную роль в алгоритме Фийскргор играет фактор момента, который
адаптируется к текущим результатам процесса обучения. В соответствии с
алгоритмом Фальмана коэффициент момента ад подбирается индивидуально для
каждого веса по правилу

Первое слагаемое соответствует оригинальному алгоритму наискорей-

ушдОсЛАшд > 0, или нулевое значение — в противном случае.

дай)
ПрИЧСМ
$„(1‹)=Ё%:ЁЁ+Ж„(1‹)‚ (3.60)
й
_ ` В)“ = М") (вы)

$„(1‹—1)—$„(1‹)'

Константа вещах — это максимальное значение коэффициента момента, которая
по предложению Фальмана принимается равной ест, = 1,75.

Также известна упрощенная версия алгоритма Оийскргор, в которой значения
весов изменяются в соответствии с правилом

а„(/‹)А„„(1‹—1) для Аш„(1‹—1)=ьо

мы‘) = „о 5511 - (з.в2)

й

$д(1‹)

ад(1‹)=т1п —————————$й(‚с_1)_8й(‚‹),а‚„„х ‚

(3.63)

где Зд (1с)=   . В нем уменьшено количество управляющих парамет-
и).
ров и упрощена” сама формула уточнения значений весов. Согласно пред-

ставленным в [159] результатам эффективность модифицированного алгоритма
сравнима с оригинальным алгоритмом Фальмана. ’

3.1 Сравнение эффективности алгоритмов обучения 73

3.6.2. Алгоритм КРКОР

‘д

Другой простой эвристический алгоритм, демонстрирующий высокую
эффективность обучения, — это алгоритм М. Ридмиллера и Х. Брауна, назы-
ваемый КРКОР (англ: Кезййепг Ьас/с РКОРадайоп) [133, 178]. В этом алгоритме
при уточнении весов учитывается только знак градиентной составляющей, а ее
значение игнорируется:

дБ (“(10)
3%

Коэффициент обучения подбирается индивидуально для каждого веса шу с
учетом изменения значения градиента:

т111(‹111д(/‹—1)‚ Птах) для $900 $д‘(/‹—1) > 9
тах(1›пд(/‹—1)‚ пты для Зуд‘) $д(‘‹—1) < о ‚ ‹з.в5)
пд (/‹—1) в остальных случаях

Аш„(/‹)=—п„(/‹)$еп (з.в4)

где $д(/‹)= ЁЁЁЁЁ, а и Ь - константы: а=1,2; Ь=0,5. Минимальное и макси-

мальное значейия коэффициента обучения обозначены соответственно
птдп и птах; для алгоритма КРКОР они составляют Птап = 10`6 и
птах = 50 [178]. Функция з3п( ) принимает значение, равное знаку градиента.

Алгоритм КРКОР, в котором игнорируется информация о значении градиента,
позволяет значительно ускорить процесс обучения в тех случаях, когда угол
наклона целевой функции невелик. В соответствии со стратегией подбора весов,
если на двух последовательных шагах знак градиента не изменяется,
предусматривается увеличение коэффициента обучения. Если же знак градиента
изменяется, то коэффициент обучения уменьшается.

3.7. Сравнение эффективности
алгоритмов обучения

Эффективность алгоритмов обучения проверяется на определенных тестах,
соответствующих принятым мировым стандартам. Такими стандартными
тестами, в частности, считаются задача логистики, задача парности, кодирование
и декодирование двоичных данных, аппроксимация определенного вида
нелинейной функции, задача двух спиралей и многие другие [155]. Различные
алгоритмы сравниваются по количеству циклов обучения, количеству расчетов
значения целевой функции, количеству знакопеременных произведений,
чувствительности к локальным минимумам и т.п.

Например, решение задачи логистики состоит в предсказании очередного
значения х„+1 случайной цифровой последовательности по предыдущему
значению х„. Этап обучения сети, имеющей, к примеру структуру 1-5-1 (1

74 3. Однонапвавленные многослойные сети сигмоидального типа

входной узел, 5 скрытых нейронов, 1 выходной нейрон), имеет целью
сформировать такие значения весов, чтобы реализовать логистическое
отображение

х„+1=гх„(1 —хп)

для 05х„$1, которое при значении г=4 будет демонстрировать свойства слу-
чайной последовательности.

В свою очередь, тестовая задача кодирования двоичных векторов
заключается в таком подборе весов сети, чтобы при размерности А!
входного вектора закодировать его с помощью о нейронов скрытого слоя,
с последующим декодированием в выходном слое к исходному виду. Обу-
чающие векторы состоят из одной единицы и (Н- 1) нулей. Каждому
сформированному таким образом входному вектору сопоставляется
идентичный выходной вектор.

По результатам многих имитационных экспериментов можно утверждать,
что наименее эффективным является алгоритм наискорейшего спуска,
особенно при постоянном шаге обучения. Стратегия выбора этого шага
имеет ключевое значение для эффективности алгоритма. Чем ближе
минимальное значение целевой функции в направлении р, тем лучше
результаты обучения на отдельных итерациях и тем выше конечный
результат. С этой точки зрения наибольший эффект обеспечивает метод
направленной минимизации, применяемый в каждом оптимизационном
цикле для выбора оптимального размера шага. Однако при сравнении
эффективности различных методов следует принимать во внимание объем
дополнительных вычислений, требуемых для расчета оптимальной
величины п.

Эффективность различных алгоритмов сравнивается либо путем измере-
ния среднего времени, требуемого для решения конкретной задачи, либо по
количеству циклов обучения, либо по количеству знакопеременных операций
(по вычислительной сложности алгоритма). Эти характеристики могут
существенно отличаться в зависимости от характера тестовой задачи,
объема обучающих данных, размерности нейронной сети, используемого
вычислительного оборудования, а также деталей реализации отдельных этапов
алгоритма. Поэтому невозможно дать однозначный ответ на вопрос: какой
алгоритм считается абсолютно лучшим?

В табл. 3.2 представлены результаты, полученные на компьютере;
Масйптовп Роч/егЬоок 1400 при использовании прикладного пакета “Ыеига! Е
Ыеш/огкз” программы МаНаЬ [27], позволяющие сравнить длительность,
количество циклов обучения и вычислительную сложность различных
алгоритмов. В ходе экспериментов обучался многослойный персептрон со \
структурой 1-10-1, предназначенный для аппроксимации 41 пары обучающих
одномерных данных. Все алгоритмы были реализованы в инструментальной
среде одной и той же программы Ма11аЬ‚ что создало основу для получения
объективных оценок. Ч

5 5. Зтементь: глобальной оптимизации 75

 

Таблица 3.2
Сравнение эффективности алгоритмов обучения

Время, Количество Количество
(с) циклов операций, х106
5 7’ 7 1

$111
п

Получены усредненные результаты по 20 процессам обучения. На
чалой сети, использованной в ходе тестирования, наибольшую эффек-
тивность продемонстрировал алгоритм Левенберга-Марквардта (наименьшее
время обучения, наименьшее количество циклов обучения, наименьшая
вычислительная сложность). Следующими по количеству циклов и времени
обучения идут алгоритмы переменной метрики ВРСЭЗ и сопряженных градиентов.
Самую низкую эффективность в ходе тестирования показал алгоритм
наискорейшего спуска (все показатели имеют наихудшие значения).
Эвристический алгоритм КРКОР в этом соревновании выглядел сов-
сем неплохо — он занял второе место по вычислительной сложности.

По результатам многочисленных и различных тестов сделан общий
вывод, что ньютоновские алгоритмы, в том числе методы переменной
метрики и Левенберга-Марквардта, по эффективности доминируют как над
четодами наискорейшего спуска, так и над методом сопряженных
градиентов. Однако это очевидное превосходство исчезает при значительном
увеличении размеров сети. Уже при 1000 взвешенных связей наиболее
эффективным становится, как правило, метод сопряженных градиентов.

 
 
 

  
   

Наискорейшего спуска
с адаптируемым шагом

  
  
  

  
  
    
 

С опряженных градиентов

переменной метрики ВРОЗ

  
 

Левенберга-Марквардта
КРКОР

  

3.8. Элементы глобальной оптимизации

При обучении нейронных сигмоидальных сетей, основанном на минимизации
значения целевой функции, даже при решении относительно простых
технических задач необходимо учитывать возможность появления большого
количества локальных минимумов. Проблемы обучения таких сетей хорошо
иллюстрирует следующий пример. Рассмотрим сеть, состоящую из одного
нейрона, связанного с входным узлом дугой с весом и’; и с единичным
поляризатором дугой с весом щ). Нейрон выполняет функцию классификатора
данных, относящихся к двум классам. Имеются обучающие данные в виде
(—4, 1), (-3, 1), (—-2, 1), (-1, 1), (1, —1),(3, —1), (4, -1). При использовании линейной
функции активации нейрона график зависимости целевой функции от весов щ)

76 3. Однонапеавягенные многослойные сети сигмоидального типа

и и»; принимает вид выпуклой кривой (рис. 3.8 а), единственный минимум
которой можно легко рассчитать при любых начальных условиях обучения.
Переход к сигмоидальной функции активации принципиально меняет форму
целевой функции. Эта ситуация демонстрируется на рис. 3.8 б, причем
сигмоидальная функция активации задана в виде гиперболического
тангенса. На графике видны многочисленные плоские участки и множество
локальных минимумов, которые осложняют процесс обучения и пред-
ставляют собой ловушки на пути к глобальному минимуму, в котором целевая
функция принимает наименьшее значение.

Хотя графики целевой функции, представленные на рис. 3.8, относятся к
простейшей однонейронной сети, они хорошо иллюстрируют проблемы,
создаваемые нелинейностью функции активации. Увеличение размеров сети
создает еще большие сложности, поскольку количество локальных минимумов
также возрастает.

Все представленные ранее методы обучения нейронных сетей являются
локальными. Они ведут к одному из локальных минимумов целевой функции,
лежащему в окрестности точки начала обучения. Только в ситуации, когда
значение глобального минимума известно, удается оценить, находится ли
найденный локальный минимум в достаточной близости от искомого
решения. Если локальное решение признается неудовлетворительным.
следует повторить процесс обучения при других начальных значениях весов и с
другими управляющими параметрами. Можно либо проигнорировать
полученное решение и начать обучение “с чистого листа” при новых (как
правило, случайных) значениях весов, либо изменить случайным образом
найденное локальное решение и продолжить обучение сети. Последняя методика.
имеющая английское название ‘По; о] шеддйгв” (встряхивание весов).
представляется вполне разумной, поскольку ее применение позволяет
использовать полученные ранее результаты обучения [72]‚

Случайное приращение весов соответствует переходу из точки
локального минимума в иную точку пространства целевой функции.
Вследствие случайного характера таких приращений переход в новую
точку связан с определенной вероятностью того, что возобновление процесса
обучения выведет поиск из ‘7сферы притяжения” локального минимума
Случайный выбор значений весов, применяемый как в начале обучения.
так и для вывода решения из зоны локального минимума, играет роль
стохастического алгоритма, взаимрдействуюшего с детерминированнын
алгоритмом обучения сети. Однако возмущение весов, вызванное добав-
лением случайных поправок к ранее найденному решению, не вызывает
длительной потери предыдущих ‘результатов обучения. Сеть проявляет
интересную способность “запоминания” наилучших результатов и после
кратковременной амнезии быстро восстанавливается, а затем и (чаще
всего) улучшает предыдущие показатели.

8 Элементы глобальной оптимизации 77

 

‘Ё
ь‘‚’/
„. до; _\_‚
" / М‘ ›" ’ м‘ ‘
-‚ › / ‘
“‚ил,‹\\‹:‚‘‹‚’г‚\‘\‘‚’ "д д‘
‚ ‚‹к‚\‚_‚‚‚:‚\\:„ д,’ д“ ‚ ‚ \
‚о; "д

‚
ь\\’
д

‚ ‘и,
/

‘„:“.ы’‚д‚ Ш

‚„ ш щ

\\- ш щ

. \\\\\\ Щ
ш н‘ ’^
._ ш \‚ _

’!‚

‚ Н!’ › 1  ‚

‚ . ‘‚‚г‚‚‘;//‚:ё:‚‚‚/‚‚Д"М; ‚ ‚

. 1 ‚Щи ‚ ‚ ‚::{/‚‚::_/‚„%/‚
’. ч, ‚ 1

Рис. 3.8. Пример графика целевой функции нейронной сети:

а) линейная функция активации; б) СИГМОИДШЬННЯ ФУНКЦИЯ ЗКТИВЯЦИИ

78 3. Однонапвавленньте многослойные сети сигмоидального типа

При решении реальных как технических, так и экономических задач
в общем случае даже приблизительная оценка глобального минимума
оказывается неизвестной. По этой причине возникает необходимость
применения методов глобальной оптимизации. Из множества разработан-
ных в этой области подходов выберем и подробно рассмотрим два: метод
имитации отжига‘ и генетические алгоритмы [41, 149].

3.8.1. Алгоритм имитации отжига  к

Метод имитации отжига основан на идее, заимствованной из статической
механики. Он отражает поведение материального тела при отвердевании с
применением процедуры отжига (управляемого охлаждения. — Примеч. ред.) при
температуре, последовательно понижаемой до нуля. Как показали исследования,
при отвердевании расплавленного материала его температура должна
уменьшаться постепенно, вплоть до момента полной кристаллизации. Если
процесс остывания протекает слишком быстро, образуются значительные
нерегулярности структуры материала, которые вызывают внутренние
напряжения. В результате общее энергетическое состояние тела, зависящее
от его внутренней напряженности, остается на гораздо более высоком
уровне, чем при медленном охлаждении. Быстрая фиксация энергетического
состояния тела на уровне выше нормального аналогична сходимости
оптимизационного алгоритма к точке локального штнимума. Энергия состояния
тела соответствует целевой функции, а абсолютный минимум этой
энергии — глобальному минимуму. В процессе медленного управляемого
охлаждения, называемого отжигом, кристаллизация тела сопровождается
глобальным уменьшением его энергии, однако допускаются ситуации, в
которых она может на какое-то время возрастать (в частности, при подогреве
тела для предотвращения слишком быстрого его остывания — Примеч. ред.).
Благодаря допустимости кратковременного повышения энергетического уровня
возможен выход из ловушек локальных минимумов, которые возникают
при реализации процесса. Только понижение температуры тела до абсолютного
нуля делает невозможным какое-либо самостоятельное повышение его
энергетического уровня. В этом случае любые внутренние изменения ведут
только к уменьшению общей энергии тела.

В реальных процессах кристаллизации твердых тел температура пони-
жается ступенчатым образом. На каждом уровне она какое-то время
поддерживается постоянной, что необходимо для обеспечения терми-
ческого равновесия. На протяжении всего периода, когда температура оста-
ется выше абсолютного нуля, она может как ПОНИЖаТЬСЯ, ТЗК И ПОВЫШЗТЬСЯ. за

счет удержания трмпературьт процесса ПОбЛИЗОСТИ ОТ ЗНЯЧСНИЯ,
соответствующего непрерывно снижающемуся уровню термического рав-

 

1 о . ‚
Оригинальное англииское название вттишед аппеаипд.

3. 8. Элементы глобальной оптимизации 79

новесия, удается обходить ловушки локальных минимумов, что при достижении
нулевой температуры позволяет получить и минимальный энергетический
уровень.

Метод имитации отжига представляет собой алгоритмический аналог
физического процесса управляемого охлаждения. Предложенный Н. Метро-
полисом в 1953 г. [61, 71] и доработанный многочисленными после-
дователями, он в настоящее время считается одним из немногих алгоритмов,
позволяющих практически находить глобальный минимум функции нескольких
переменных.

Классический алгоритм имитации отжига можно описать следующим
образом [61].

1. Запустить процесс из начальной точки и‘ при заданной начальной температуре

Т = Т „ш.

2. Пока Т > О, повторить Ь раз следующие действия:

’ выбрать новое решение ю’ из окрестности и’;

’ рассчитать изменение целевой функции А = Е (и”) — Е (ю);

’ если А 5 О, принять и’ = ш’; в противном случае (при А > 0) принять,
что и’ = ю’ с вероятностью ехр(-А! Т) путем генерации случайного
числа К из интервала (0, 1) с последующим сравнением его со зна-
чением ехр( -А/ Т); если ехр(-А! Т) > К, принять новое решение
и’ = ю’; в противном случае проигнорировать его.

3. Уменьшить температуру ( Т ‹-— гТ ) с использованием коэффициента

уменьшения г, выбираемого из интервала (О , 1), и вернуться к п. 2.

4. После снижения температуры до нулевого значения провести обучение сети
любым из представленных выше детерминированных методов, вплоть до
достижения минимума целевой функции.

В описании алгоритма в качестве названия параметра, влияющего на
вероятность увеличения значения целевой функции, используется выбран-
ный его автором Н. Метрополисом термин “температура”, хотя с формальной
точки зрения приведенная модель оптимизации является только математической
аналогией процесса отжига. Алгоритм имитации отжига выглядит кон-
цептуально несложным и логически обоснованным. В действительности
приходится решать много фундаментальных проблем, которые влияют на его
практическую применимость. Первой следует назвать проблему длительности
имитации. Для повышения вероятности достижения глобального минимума
длительность отжига (представляемая количеством циклов Ь, повторяемых
при одном и том же значении температуры) должна бьпъ достаточно

большой, а коэффициент уменьшения температуры г’ -— низким. Это УВЕЛИ-
ЧиваеТ ПРОДОПЖИТЁПЬНОСТЬ процесса МОДЁПИРОВаНЁ/ПЁ, ЧТО МОЖЁТ ДИСКРЁДИ‘

тироватъ его с позиций практической целесообразности.

Возникает также и проблема конкурентоспособности метода по сравнению,
например, с методами локальной оптимизации в связи с возможностью
многократного возобновления процесса из различных точек в пространстве

1

30 3. Однонапвааленные многослойные сети сигмоидального типа

параметров. При таком подходе грамотная статистическая обработка позволяет с
высокой вероятностью и достаточно быстро локализовать зону глобального
минимума и достичь его с применением технологии детерминированной
оптимизации.

Огромное влияние на эффективность метода имитации отжига оказывает
выбор таких параметров, как начальная температура Т „т, коэффициент
уменьшения температуры г и количество циклов Ь, выполняемых на каждом
температурном уровне.

Максимальная температура подбирается по результатам многочисленных
предварительных имитационных экспериментов. На их основе строится
распределение вероятности стохастических изменений текущего решения при
конкретных значениях температуры (зависимость А = [(Т)). В последующем,
задаваясь процентиым значением допустимости изменений в качестве порогового
уровня, из сформированного распределения можно найти искомую начальную
температуру. Главной проблемой остается определение порогового уровня,
оптимального для каждой реализации процесса имитации отжига. Для отдельных
практических задач этот уровень может иметь различные значения, однако общий
диапазон остается неизменным. Как правило, начальная температура подбирается
так, чтобы обеспечить реализацию порядка 50% последующих случайных
изменений решения. Поэтому знание предварительного распределения
вероятностей таких изменений позволяет получить приблизительную оценку
начальной температуры.

Методики выбора как максимального количества циклов Ь для кон-
кретных температурных уровней, так и определение значения коэффи-
циента уменьшения температуры г не столь однозначны. При подборе этих
параметров приходится учитывать динамику изменения величины целевой
функции в зависимости от количества выполненных циклов обучения.

Большая часть вычислительных ресурсов расходуется на начальной
стадии процесса, когда средняя скорость изменения целевой функции неве-
лика и прогресс оптимизации минимален. Это “высокотемпературная”
стадия имитационного процесса. Быстрее всего величина целевой функции
уменьшается на средней стадии процесса при относительно небольшом
количестве приходящихся на нее итераций. Завершающая стадия процесса
имеет стабилизационный характер. На ней независимо от количества
итераций прогресс оптимизации становится практически незаметным. Такое
наблюдение позволяет существенно редуцировать начальную стадию
отжига без снижения качества конечного результата. Модификации обычно
подвергается количество циклов, выполняемых при высоких температурах, -
оно сокращается в случае, когда оказался выполненным весь запланированный

объем изменений текущего решения. Такой подход позволяет сэкономить до
20% времени. .‚ ‚

Исключение последней, плоской части характеристической кривой целевой
функции также возможно. В соответствии с обычным критерием остановки

З. 8. Элементы глобальной оптимизации 31

алгоритма, ЕСЛИ при НВСКОЛЬКИХ ПОСЛСДОВЗТЁЛЬНЫХ СНИЖСНИЯХ ТСМПСРЭТУрЫ

(типовое значение 5) не регистрируется уменьшение ВВЛИЧИНЫ ЦВЛСВОЙ ФУНКЦИИ,
то процесс останавливается, а наилучшее достигнутое решение считается
глобальным минимумом. Дальнейшее уменьшение критерия остановки не
рекомендуется, поскольку оно ведет к снижению вероятности достижения
глобального минимума. В то же время заметное влияние на конечную стадию
процесса оказывают коэффициент понижения температуры г и количество
циклов 1,. Ее длительность удается сократить более частым изменением
температуры при уменьшении количества циклов, но при сохранении
неизменным общего объема итераций.

Еще одна проблема связана с определением длительности моделирования
процесса отжига, пропорциональной суммарному количеству итераций.
Поскольку отводимое для оптимизации время всегда ограничено, все его можно
потратить либо на одну реализацию процесса с соответствующим удлинением
циклов, либо сократить длительность всех циклов, а за счет этого выполнить
несколько реализаций и принять в качестве результата наилучшее решение. В
ходе различных компьютерных экспериментов установлено, что при малом
лимите времени лучшие результаты дает единичная реализация. Если же
моделирование может быть более длительным, статистически лучшие результаты
достигаются при многократной реализации процесса имитации отжига, при
больших (близких к 1) значениях коэффициента г.

Однако наибольшее ускорение процесса имитации отжига можно достичь
путем замены случайных начальных значений весов и’ тщательно подобранными
значениями с использованием любых доступных способов предварительной
семантической обработки исходных данных. В такой ситуации в зависимости от
количества оптимизируемых весов и степени оптимальности начальных значений
удается добиться даже многократного сокращения времени моделирования.

Таким образом, метод имитации отжига оказывается особенно удачным для
полимодальных комбинаторных проблем с весьма большим количеством
возможных решений, например, для машины Больцмана, в которой каждое
состояние системы считается допустимым. При решении наиболее распрост-
зраненных задач обучения многослойных нейронных сетей наилучшие
результаты в общем случае достигаются применением стохастически
управляемого метода повторных рестартов совместно с детерминированными
алгоритмами, приведенными в предыдущем подразделе.

3.8.2. Генетические алгоритмы

Идея генетических алгоритмов была предложена Дж. Холландом в 70-х годах
ХХ в. [41], а их интенсивное развитие и практическая реализация для численных

оптимизационных расчетов были инициированы Д. Гольдбергом [41]. Эти
алгоритмы имитируют процессы наследования свойств живыми организмами и

Г енерируют ПОСЛСДОВЗТСЛЬНОСТИ НОВЫХ ВСКТОРОВ И’, содержащие ОПТИМИЗИ-

6-2152

82 3. Однонаправленньяе многослойные сети сигмоидального типа

рованные переменные: и’ = [щ, ш2,...,ш„]Т. При этом выполняются операции
трех видов: селекция, скрещивание и мутация.

Отдельные компоненты вектора и’ могут кодироваться в двоичной системе
либо натуральными числами [41]. При двоичном кодировании применяется
обычный код, или код Грея. После соответствующего масштабирования
отдельные биты представляют конкретные значения параметров, подлежащих
оптимизации. Каждому вектору и’ сопоставляется определенное значение
целевой функции. Генетические операции (селекция, скрещивание и мутация)
выполняются для подбора таких значений переменных и’; вектора и’,
при которых максимизируется величина так называемой функции приспо-
собленности (англ.: Лтезв [ипс110п). Функция приспособленности Ни’)
определяется через целевую фунщию Е(и’) путем ее инвертирования (целевая
функция минимизируется, а функция приспособленности максимизируется).
Например, она может иметь вид: Р(и’) = -Е(и’).

На начальной стадии выполнения генетического алгоритма инициали-
зируется определенная популяция хромосом (векторов и’). Она формируется
случайным образом, хотя применяются также и самонаводящиеся спо-
собы (если их можно определить заранее). Размер популяции, как правило,
пропорционален количеству оптимизируемых параметров. Слишком малая
популяция хромосом приводит к замыканию в неглубоких локальных
минимумах. Слишком большое их количество чрезмерно удлиняет
вычислительную процедуру и также может не привести к точке глобального
минимума. При случайном выборе векторов и’, составляющих исходную
популяцию хромосом, они статистически независимы и представляют собой
начальное погружение в пространство параметров. Одна часть этих хро-
мосом лучше “приспособлена к существованию” (у них большие значения
функции соответствия и меньшие — целевой функции), а другая часть хуже.
Упорядочение хромосом в популяции, как правило, производится в
направлении от лучших к худшим. Хромосомы отбираются (подвергаются
селекции) для формирования очередного поколения по значениям функции
соответствия.

Селекция хромосом для спаривания (необходимого для создания нового
поколения) может основываться на различных принципах. Одним из наиболее
распространенных считается принцип элитарности, в соответствии с которым
наиболее приспособленные хромосомы сохраняются, а наихудшие
отбраковываются и заменяются вновь созданным потомством, полученным в
результате скрещивания пар родителей. На этапе скрещивания подбираются такие
пары хромосом, потомство которых может быть включено в популяцию путем
селекции. Существует огромное количество методов спаривания, от полностью

случайного (как правило, среди наиболее приспособленных хромосом), через
взвешенно-случайное спаривание и вплоть до так называемой турнирной

системы. В последнем случае случайным образом отбирается несколько
хромосом, среди которых определяются наиболее приспособленные (с

3.8. Элементы глобальной оптимизаиии 83

наименьшим значением целевой функции). Из победителей последовательно
проведенных турниров формируются пары для скрешивания.

При взвешенно-случайной системе в процессе ‘отбора учитывается
информация о текущем значении функции приспособленности. Отбор может
происходить по принципу “рулетки”, при этом площадь сегмента колеса рулетки,
сопоставленного конкретной хромосоме, пропорциональна величине ее
относительной функции приспособленности. Ситуация, типичная для такого
отбора, иллюстрируется на рис. 3.9. Полная площадь круга соответствует сумме

‘ РШЧ)

 

Указатель

Рис. 3.9. Схема “рулетки”, используемая при выборе родителей для будущего поколения.
Площадь отдельных сегментов пропорциональна значениям соответствующих функций
приспособленности

значений функций приспособленности всех хромосом данной популяции.
Каждый выделенный сегмент отвечает конкретной хромосоме. Наиболее
приспособленным особям отводятся большие сегменты колеса рулетки,
увеличивающие их шансы попадания в переходную популяцию.

Хромосома 1 Хромосома 3

=>

Хромосома 2 Хромосома 4

И

Рис. 3.10. Иллюстрация операции скрещивания, применяемой в генетическом алгоритме

Процесс скрещивания основан на рассечении пары хромосом на две части
1 рис. 3.10) с последующим обменом этих частей в хромосомах родителей’. Место
рассечения также выбирается случайным образом. В ситуации, показанной на

1 Также МОЖЕТ ПрИМСНЯТЬСЯ РЗЗДСЛСНИЕ РОДИТЕЛЕЙ на НЕСКОЛЬКО ОДИНЗКОВЫХ ЧЗСТСЙ
2 ПОСЛЕДУЮЩИМ ОбМСНОМ КОМПЛСМСНТЗРНЬПМИ КОМПОНЕНТЗМИ.

б‘

84 3. Однонапеавленные многослойные сети сигмоидального типа

рис. 3.10, после скрещивания хромосомы 1 (фрагменты Ь; и 122) с хромосомой 2
(фрагменты Ь; и Ь4) образовалась пара новых хромосом: хромосома 3 (фрагменты
Ь; и Ь4) и хромосома 4 (фрагменты 123 и 122). Количество новых потомков равно
количеству отбракованных в результате селекции. После их добавления к
оставшимся хромосомам размер популяции остается неизменным. Как правило,
признается допустимым перенос в очередное поколение некоторых случайно
выбранных хромосом вообще без скрешивания. Это соответствует ситуации,
когда скрещивание достигает успеха с определенной вероятностью, обычно на
уровне 0,6 — 1.

Последняя генетическая операция — это мутация, состоящая в замене
значений отдельных битов (при двоичном кодировании) на противоположные.
При кодировании натуральными десятичными цифрами мутация заключается в
замене значения какого-либо элемента вектора другим, случайно выбранным
допустимым значением. Мутация обеспечивает защиту как от слишком раннего
завершения алгоритма (в случае выравниваншт значений всех хромосом и целевой
функции), так и от представления в какой-либо конкретной позиции всех
хромосом одного и того же значения. Однако необходимо иметь в виду, что
случайные мутации приводят к повреждению уже частично приспособленных
векторов. Обычно мутации подвергается не более 1—5% бит всей популяции
хромосом. Как и при выполнении большинства генетических операций, элемент,
подвергаемый мутации, отбирается случайным образом.

На рис. 3.11 представлены схема формирования переходной популяции и
ПрОВОДИМЫС ПОСПС него операции скрещивания И МУТЗЦИИ, ПрИВОДЯЩИС К
образованию популяции потомков. Отметим, что в этих операциях не обязательно
участвуют все хромосомы, входяшие в переходную популяцию.

Исследованиями доказано [41], что каждое последующее поколение,
сформированное после выполнения селекции, скрещивания и мутации, имеет
статистически лучшие средние показатели приспособленности (меньшие
значения целевой функции). Типичная динамика изменения среднего по
популяции и минимального (т.е. соответствующего наиболее приспособленной
хромосоме) значения целевой функции для последовательных поколений
генетического процесса представлена на рис. 3.12.

В качестве окончательного решения принимается наиболее приспособленная
хромосома, имеющая минимальное значение целевой функции. Г енетический
процесс завершается либо в момент генерации удовлетворяющего нас решения,
либо при выполнении максимально допустимого количества итераций. При
реализации генетического процесса отслеживается, как правило, не только
минимальное значение целевой функции, но и среднее значение по всей
популяции хромосом, а также их вариации. Решение об остановке алгоритма
может приниматься и в случае отсутствия прогресса минимизации, опреде-
ляемого по изменениям названных характеристик.

Хорошие результаты обучения приносит объединение алгоритмов глобальной
оптимизации с детерминированными методами. На первом этапе обучения сети

85

3.8. Зчементы ггюбальной оптимизации

Едымнъ: = Ёшыщъёоыыо ‚ыыпмопоо Ёпмшопо ЁЭЁЁЭЬЗЕЕ ‚м-‚ЁЕЁЁ оьоиоогёьшоь ЫЕФКФ ымшшоНоцР» .=.м 6.:-

ь

«Е. ц ЗЁоЕос казкчъсо: ьтц кззкчЁос кмхгоЕЁозоцс

а ц ыазЁЁос кмхсохо:

‘2
Ё

000

1'."'|"""'1"

| ооо

Н 

кЁЁЭЕ шзхмёчзшцмо „Зёбчшо

86 3. Однонапвавленные ‚многослойные сети сигчаидатьнаго типа

Е (ш)

10

 

Поколение

Рис. 3.12. Типичная динамика среднего (Е‚) и минимального (Етш) значения целевой
функции в последовательных поколениях генетического алгоритма

применяется выбранный алгоритм глобальной оптимизации, а после дости-
жения целевой функцией определенного уровня включается детермини-
рованная оптимизация с использованием какого-либо локального алгоритма
(наискорейшего спуска, переменной метрики, Левенберга—Марквардта или
сопряженных градиентов).

3.9. Методы инициализации весов

Обучение нейронных сетей, даже при использовании самых эффективных
алгоритмов, представляет собой трудоемкий процесс, далеко не всегда дающий
ожидаемые результаты. Проблемы возникают из-за нелинейных функций
активации, образующих многочисленные локальные минимумы, к которым может
сводиться процесс обучения. Конечно, применение продуманной стратегии
поведения (например, имитации отжига, метода мультистара, генетических
алгоритмов) уменьшает вероятность остановки процесса в точке локального
минимума, однако платой за это становится резкое увеличение трудоемкости и
длительности обучения. Кроме того, для применения названных методов
необходим большой опыт в области решения сложных проблем глобальной
оптимизации, особенно для правильного подбора управляющих параметров.

На результаты обучения огромное влияние оказывает подбор начальных
значений весов сети. Идеальными считаются начальные значения, достаточно
бтшзкие к оптимальным. При этом удается не только устранить задержки в точках
локальных минимумов, но и значительно ускорить процесс обучения. К
сожалению, не существует универсального метода подбора весов, который бы

1.9. Методы инициализации весов 87

гарантировал нахождение наилучшей начальной точки для любой решаемой
задачи. По этой причине в большинстве практических реализаций чаще всего
применяется случайный подбор весов с равномерным распределением значений в

заданном интервале.
Неправильный выбор диапазона случайных значений весов может вызвать

дишком раннее насыщение нейронов, в результате которого, несмотря на
продолжающееся обучение, среднеквадратичная погрешность будет оставаться
практически постоянной. Явление этого типа не означает попадания в точку
локального минимума, а свидетельствует о достижении седловой зоны целевой
функции вследствие слишком больших начальных значений весов. При
определенных обучающих сигналах в узлах суммирующих нейронов

генерируются сигналы и, ={и’дх] со значениями, соответствующими глу-

‚ 1 .‚

‘эокому насыщению сигмоидальнои функции активации. При этом поляри-
зация насыщения обратна ожидаемой (выходной сигнал нейрона равен
’| при ожидаемой величине -1 и обратно). Значение возвратного сигнала,

гвнерируемое в методе обратного распространения, пропорционально величине

_‚ д
ИЗВОДНОИ ОТ нКЦИИ аКТИВаЦии 1’, В ТОЧКе НаСЬПЦенИЯ близко Н ПЮ. ПОЭТС)’
Эх у

ку изменения значений весов, выводящие нейрон из состояния насыщения,
происходят очень медленно. Процесс обучения надолго застревает в седловой
юне. Следует обратить внимание, что в состоянии насыщения может находиться
дана часть нейронов, тогда как другая часть остается в линейном диапазоне,
1 для них обратный обучающий сигнал принимает нормальный вид. Это
означает, что связанные с такими нейронами веса уточняются нормальным
збразом, и процесс их обучения ведет к быстрому уменьшению погрешности.
Как следствие, нейрон, остаюшийся в состоянии насыщения, не участвует в
зтображении данных, сокращая таким образом эффективное количество
нейронов в сети. В итоге процесс обучения чрезвычайно замедляется, поэтому
:остояние насыщения отдельных нейронов может длиться практически
непрерывно вплоть до исчерпания лимита итераций.

Случайная инициализация, считающаяся единственным универсальным
способом приписывания начальных значений весам сети, должна обеспечить
такую стартовую точку активации нейронов, которая лежала бы достаточно
далеко от зоны насыщения. Это достигается путем ограничения диапазона
допустимых разыгрываемых значений. Оценки нижней и верхней границ такого
диапазона, предлагаемые различными исследователями на основании
многочисленных компьютерных экспериментов, отличаются в деталях, однако
практически все лежат в пределах (0 , 1).

В работе [155] предложено равномерное распределение весов, норма-

_‚ 2
ЩЗОВЗННОС ДЛЯ КВЖДОГО НСИ она ПО ампли де т, ГДС Пдд ОЗНЗЧЗСТ КОЛИ-
пйп

чество входов нейрона. Значения весов поляризации для нейронов скрытых слоев

должны принимать случайные значения из интервала [_ ‘то ‘то 1, а для вы-
ходных нейронов — нулевые значения. 2 2

88 3. Однонаправленные ‚многослойные сети сигмоидального типа

Д. Нгуен и Б. Видроу в своих рассуждениях на тему оптимальных значений
начальных весов используют кусочно-линейную аппроксимацию сигмоидальной
функции активации. На этой основе они определили оптимальную длину
случайного вектора весов нейронов скрьпъхх слоев равной "д, где М, означает
количество нейронов в скрытом слое, а п;„ — количество входов данного нейрона.
Оптимальный диапазон весов поляризации для нейронов скрытого слоя
определен в пределах [дл/‚АТШД Начальные веса выходных нейронов, по
мнению упомянутых авторов, не должны зависеть от топологии области
допустимых значений и могут выбираться случайным образом из интервала
[— 0,5 , 0,5].

Решение представленных проблем случайной инициализации весов сети
опирается либо на интуицию исследователя, либо на результаты большого
количества численных экспериментов. Более детальный анализ событий,
происходящих в процессе обучения, позволит точнее выявить причины
замедления обучения персептронной сети, задержек в седловых зонах, а также
слишком раннего завершения обучения в точках локальных минимумов, далеких
от оптимального решения. Результатом такого анализа должны стать меры
предупреждения этих нежелательных явлений за счет применения
соответствующих процедур предварительной обработки обучающих данных для
необходимой инициации как структуры сети, так и значений весов. Эти
процедуры базируются либо на анализе данных с использованием конкуренции
[28], подобно тому, как это происходит в сетях, самоорганизуюцшхся на основе
конкуренции, либо на использовании информации о корреляционных зависи-
мостях обучающих данных [65].

 

у
а’
«

Раздел 4

ПРОБЛЕМЫ ПРАКТИЧЁСКОГО ИСПОШЭЗОВАНИЯ
ИСКУССТВЕННЫХ НЕИРОННЫХ СЕТЕИ

4.1. Предварительный подбор архитектуры сети

Для решения какой-либо задачи с применением искусственной нейронной сети
шедует прежде всего спроектировать структуру сети, адекватную поставленной
задаче. Это предполагает выбор количества слоев сети и нейронов в каждом слое,
1 также определение необходимых связей между слоями.

Подбор количества нейронов во входном слое обусловлен размерностью
входного вектора х. Подобная ситуация и с выходным слоем, в котором
толичество нейронов принимается равным размерности ожидаемого вектора «1.
Серьезной проблемой остается подбор количества скрытых (внутренних) слоев и
числа нейронов в каждом из них. Теоретическое решение этой задачи в смысле
3СЛОВИЯ достаточности было предложено математиками, занимающимися
ышроксимацией функции нескольких переменных. Следует отметить, что ИНС
выступает в роли универсального аппроксиматора обучающих данных (х, д)
[46, 56]. В процессе обучения подбираются его функциональные коэффициенты
‘векторы весов отдельных нейронов). На этапе функционирования при
зафиксированных значениях весов производится простой расчет значения
алпроксимирующей функции при заданном входном векторе.

Определение минимального количества скрытых слоев сети основано на
использовании свойств аппроксимирующих функций. Каждая заданная функция
может быть выражена линейной комбинацией локальных импульсов, которые
имеют ненулевое значение только в ближайшей окрестности текущего значения х.
Ципульсная функция определенной структуры может быть сформирована как
суперпозишая двух функций, сдвинутых относительно друг друга [38, 113]. На
эис. 4.1 демонстрируется способ формирования импульса для одномерной сети

имеющей единственный вход). Две сдвинутые относительно друг друга
идентичные ситмоиды уд и у; создают в результате вычитания импульс с

длительностью, пропорциональной рЗЗНОСТИ СМВЩСНИЙ ЭТИХ СИГМОИДШХЬНЬХХ

функций. Соответствующим подбором функциональных параметров можно
добиться формирования такого импульса, который будет возникать в

необходимом для нас месте, будет иметь требуемую ширину и крутизну

нарастания.

90 4. Пеобчемы пшктического использования искгсственньлх нейронных сетей

 

У1
0
1
0
1
У1—У2
0
-4 0 4

Рис. 4.1. Иллюстрация способа формирования локального одномерного импульса
из двух сигмоидальных функций

В случае двухмерной сети можно аналогичным способом сформировать
импульс на плоскости [38]. Разность двух определенных на плоскости и
сдвинуть1х относительно друг друга сигмоидальных функций образует гребень
бесконечной длины, показанный на рис. 4.2 а. Добавляя следующую пару сдвину-
тых относительно друг друга сигмоидальных функций и вычисляя их
разность, можно получить второй гребень бесконечной длины. При подборе
параметров обеих сигмоидальных пар таким образом, чтобы их гребни
располагались под определенным углом (например, 900), можно получить в
результате суммирования этих гребней структуру двухмерного горба,
представленного на рис. 4.26. В месте пересечения гребней образуется
импульс двухмерной формы, ограниченный с четырех сторон ответвлениями
бесконечной длительности. Эти ответвления можно ликвидировать передачей
всего импульса на следующую сигмоидальную функцию (дополнительный
слой нейронов) с соответственно подобранным порогом. Как следствие,
выполняется фильтрация значения суммы на определенном уровне, по-
добранном так, что импульс, сформированный сложением двух гребней,
пропускается, тогда как ответвления гребней отсекаются. Структура
сгенерированного таким образом импульса показана на рис. 4.2 в.

Созданная этим способом двухвходовая ИНС содержит скрытый слой,
состоящий из четырех нейронов, и выходной слой, на котором рас-
положен один нейрон сигмоидального типа. При построении сигмоидальной
функции активации с соответствующим порогом он выполняет суммирование
сигналов от предыдущих четырех нейронов и отсечение ответвлений.

Возможность обобщения приведенных рассуждений на случай много-
входовой сети следует из теории Колмогорова [46, 50, 76, 114]. Если ограничиться
непрерывной функцией, трансформирующей Н-мерное множество входных
данных х в М-мерный выходной вектор 11, то можно доказать, что аппроксимация
такого типа осуществима при использовании сети с одним скрытым слоем. При А!
входных нейронах будет достаточно использовать для реализации злой функции

1 1. Пеедваеительный подбор архитектуры сети 91

скрытый слой с (21\/' + 1) нейронами. Архитектура ИНС, удовлетворяющая
теореме Колмогорова, изображена на рис. 4.3. В предложенном Колмогоровым
доказательство теоремы принято, что выходные сигналы отдельных слоев
описываются зависимостями вида

2,‘ =Ё1А‚ц/‹х‚ +Ь‚)+А‹,‚‚ (44)
]=

Рис. 4.2. Иллюстрация способа формирования импульса двухмерной сетью:

а) разность пары двухмерных сигмоидальных функций; б) структура, сформированная в
результате суммирования разностей двух пар двухмерных сигмоидальных функций;
в) форма импульса после обработки его пороговой сигмоидальной функцией

для нейронов скрытого слоя при /‹= 1, 2, .._, 21\?+1 либо

2м+1 ‹'
У: = Есьдгк +дг‹)+сов (41)

для нейронов выходного слоя. Символами у(*) и 3(*) обозначены некоторые
точно не определенные непрерывные функции, а все используемые в этих
формулах коэффициенты подбираются в процессе обучения.

В случае дискретного преобразования х-› у одного скрытого слоя уже
недостаточно и необходимо создание еще одного слоя нейронов [46]. Это

92 4. Проблемы практического испальзования исшсственных нейшнных сетей

означает, что независимо от вида многовходовой аппроксимирующей функции
максимальное количество скрытых слоев, достаточных для аппроксимации
заданного преобразования, не превышает двух. .

Результат, полученный благодаря применению теоремы Колмогорова, носит
теоретический характер. Он определяет максимальное количество слоев и
число нейронов в отдельных слоях, достаточных для аппроксимации задан-
ного преобразования. Теорема не уточняет ни вид нелинейных функций, ни

    

12ш1

Рис. 4.3. Архитектура сети, удовлетворяюшей теореме Колмогорова

методы обучения сети, создаваемой для реализации данного преобразования
Однако она представляет собой фактор, важный для минимизации структурь
ИНС. В практических реализациях сетей как количество слоев, так и числ‹
нейронов в каждом из них может отличаться от предлагаемых теоремо.
Колмогорова. Помимо немногочисленных исключений (например, неокогни-
трон [36]), чаще всего используются сети, имеющие один скрытый слой
(максимум — два), причем количество нейронов в слое может различаться

(как правило, от Н до ЗА’).

4.2. Подбор оптимальной архитектуры сети

4.2.1. Способность к обобщению |

Одно из важнейших свойств нейронной сети - это способность к обобщеник
полученных знаний. Сеть, натренированная на некотором множестве обучающит
выборок, генерирует ожидаемые результаты при подаче на ее вход данньи.

Ч

1

4.2. Подбо оптимальной а хите ы сети ‘ ' ‘ 93

 

относящихся к тому же множеству но не участвовавших непосредственно в
процессе обучения. Разделение данных на обучающее и тестовое подмножества
представлено на рис. 4.4. Множество
данных, на котором считается истинным
некоторое правило К, разбито на под-
множества Ь и О, при этом в составе 1„ в
свою очередь, можно выделить опреде-
ленное подмножество контрольных
данных И используемых для верифи-
кации степени обучения сети. Обучение
проводится на данных, составляющих
подмножество Ь. Способность отображе-
ния сетью элементов Ь может считаться
показателем степени накопления обу-
чающих данных, тогда как способность
распознавания данных, входящих во гид 4_4_ иллюстрация разделения

множество С и не использованных для данных, подчиняющихся правилу К, на
обучения, характеризует ее возможности обучающее подмножество Ь‚ ТФСТОВОФ

обобщения (генерализации) знаний. Дан- п°дмн°жес1в° 5 и КОНТРОЛЪНОФ
ные, входящие и в Ь, и в О, должны быть подмножество у
гнпичными элементами множества К. В обучающем подмножестве не должно

быть уникальных данных, свойства которых отличаются от ожидаемых
типичных) значений.

Феномен обобщения возникает вследствие большого количества комбинаций
входных данных, которые могут кодироваться в сети с А! входами. Если в качестве
простого примера рассмотреть однослойную сеть с одним выходным нейроном,
то для нее может быть составлено 2“ входных выборок. Каждой выборке может
юответствовать единичное или нулевое состояние выходного нейрона Таким
образом, общее количество различаемых сигналов составит 2”. Если для обуче-
ния сети используются р из общего числа 2“ входных выборок, то оставшиеся
незадействованными (2“ — р) допустимых комбинаций характеризуют потен-
циально возможный уровень обобщения знаний.

Подбор весов сети в процессе обучения имеет целью найти такую
комбинацию их значений, которая наилучшим образом воспроизводила бы
последовательность ожидаемых обучающих пар (хд, ф). При этом наблюдается
тесная связь между количеством весов сети (числом степеней свободы) и
количеством обучающих вьтборок. Если бы целью обучения было только
Япоминание обучающих выборок, их количество могло быть равным числу
весов. В таком случае каждый вес соответствовал бы единственной обучающей
паре. К сожалению, такая сеть не будет обладать свойством обобщения и сможет
только восстанавливать данные. Для обретения способности обобщать
информацию сеть должна тренироваться на избыточном множестве данных,
поскольку тогда веса будут адаптироваться не к уникальным выборкам, а к их

 

 

статистически усредненным совокупностям. Следовательно, для усиления
способности к обобщению необходимо не только оптимизировать структуру сети
в направлении ее минимизации, но и оперировать достаточно большим объемом
обучающих данных.

Обратим внимание на определенную непоследовательность процесса
обучения сети. Собственно обучение ведется путем минимизации целевой
функции Е(и’), определяемой только на обучающем подмножестве 1., при этом

Е(и’)= ЁЕЦд (ш),ф‹), где р обозначено количество обучающих пар (хд, йд), а

у; - вектор реакции сети на возбуждение хд. Минимизация этой функции
обеспечивает достаточное соответствие выходных сигналов сети ожидаемым
значениям из обучающих выборок.

Истинная цель обучения состоит в таком подборе архитектуры и параметров
сети, которые обеспечат минимальную погрешность распознавания тестового
подмножества данных, не участвовавших в обучении. Эту погрешность будем
называть погрешностью обобщения Ед (ш). Со статистической точки зрения
погрешность обобщения зависит от уровня погрешности обучения Е1_(и’) и от
доверительного интервала г. Она характеризуется отношением [46]

Е‹;(›‹›)=з вд») + г (Ё , Ед). (43)

В работе [46] показано, что значение г функционально зависит от уровня
погрешности обучения Е1_(ш) и от отношения количества обучающих выборок
р к фактическому значению п параметра, называемого мерой Вапника—
Червоненкиса и обозначаемого УСдйт. Мера УСдпп отражает уровень сложности
нейронной сети и тесно связана с количеством содержащихся в ней весов.
Значение г уменьшается по мере возрастания отношения количества обучающих
выборок к уровню сложности сети.

По этой причине обязательным условием выработки хороших способностей к
обобщению считается грамотное определение меры Вапника-Червоненкиса для
сети заданной структуры. Метод точного определения этой меры не известен, о
нем можно лишь сказать, что ее значение функционально зависит от количества
сииаптических весов, связывающих нейроны между собой. Чем больше
количество различных весов, тем больше сложность сети и соответственно
значение меры УСсНш. В [158] предложено определять верхнюю и нижнюю
границы этой меры в виде

Е‘

2[—Ё-]Ы з УС (йтп в 21»/„ (1 + 18 щ) ‚ (4-4)
где [ ] обозначена целая часть числа, Н -— размерность входного вектора, К —
количество нейронов скрытого слоя, М, - общее количество весов сети, а М, —
общее количество нейронов сети.

Из выражения (4.4) следует, что нижняя граница диапазона приблизительно
равна количеству весов, связывающих входной и скрытый слои, тогда как верх-

12. Подбор оптимальной аехитектшы сети 95

няя граница превышает двукратное суммарное количество всех весов сети. В
связи с невозможностью точного определения меры УСдйт в качестве ее
приближенного значения используется общее количество весов нейронной сети.

Таким образом, на погрешность обобщения оказывает влияние отношение
количества обучающих выборок к количеству весов сети. Небольшой объем
обучающего подмножества при фиксированном количестве весов вызывает
хорошую адаптацию сети к его элементам, однако не усиливает способности к
обобщению, так как в процессе обучения наблюдается относительное
превышение числа подбираемых параметров (весов) над количеством пар
фактических и ожидаемых выходных сигналов сети. Эти параметры
адаптируются с чрезмерной (а вследствие превышения числа параметров над
объемом обучающего множества — и неконтролируемой) точностью к значениям
конкретных выборок, а не к диапазонам, которые эти выборки должны
представлять. Фактически задача аппроксимации подменяется в этом случае
задачей приближенной интерполяции. В результате всякого рода нерегулярности
обучающих данных и измерительные шумы могут восприниматься как
существенные свойства процесса. Функция, воспроизводимая в точках обучения,
будет хорошо восстанавливаться только при соответствующих этим точкам
значениях. Даже минимальное отклонение от этих точек вызовет значительное
увеличение погрешности, что будет восприниматься как ошибочное обобщение.
По результатам разнообразных численных экспериментов установлено, что
высокие показатели обобщения достигаются в случае, когда количество
обучающих выборок в несколько раз превышает меру УСдйт [57].

На рис. 4.5а представлена графическая иллюстрация эффекта гиперраз-
мерности сети (слишком большого количества нейронов и весов). Аппрокси-
мирующая сеть, скрытый слой которой состоит из 80 нейронов, на основе
интерполяции в 21-й точке адаптирована свои выходные сигналы с нулевой
погрешностью обучения. Минимизация этой погрешности на слишком малом
(относительно количества весов) количестве обучающих выборок спровоци-
ровала случайный характер значений многих весов, что при переходе от обуча-
ющщ выборок к тестовым стало причиной значительных отклонений факти-
ческих значений у от ожидаемых значений д. Уменьшение количества скрытых
нейронов до 5 при неизменном объеме обучающего множества позволило
обеспечить и малую погрешность обучения, и высокий уровень обобщения (рис.
4.56). Дальнейшее уменьшение количества скрытых нейронов может привести к
потере сетью способности восстанавливать обучающие данные (т.е. к слишком

большой погрешности обучения Е1_(и’)). Подобная ситуация иллюстрируется на=

рис. 4.5 в, где задействован только один скрытый нейрон. Сеть оказалась не в
СОСТОЯНИИ КОРРСКГНО ВОСПрОИЗВВСТИ ОбУЧЗЮЦШВ ДЗННЫС, ПОСКОПЬКУ КОЛИЧЕСТВО ее

степеней свободы слишком мало по сравнению с необходимым для такого
ВОСПРОИЗВСДВНИЯ. ОЧСВИДНО, ЧТО В ЭТОМ случае НВВОЗМОЖНО ДОСТИЧЬ ТРСбУСМОГО

уровня обобщения, поскольку он явно зависит от погрешности обучения Щи’).
На практике подбор количества скрытых нейронов (и связанный с ним подбор
количества весов) может, в частности, выполняться путем тренинга нескольких

' ных сетей

вшя еского  гйвенкьцм

4.П

96

   

ыошоцшош оЕьогЁом моё: воигппо Ф
„шошодщо: омьоыгхпом мощшмцюопо: ошёыёд: 8
„ыошоцшыщ Едьзцыо оЕьогЁом ооёщпою 23553 Ё
„Ёыёае шошаовошцо ===ы2=о=оы=:« оыозё: Ё оёшоёюоюо

 

«ЕЗ Е0О=ЮО0Ф=0 пЁПюЁО-ЧЧ: ёйбгыемць тёаЁ а л
шб
#6
об
юб «о
х х
„ё „ё #6 шб ь шб‘ чб‘ об‘ шбэ „Э „ юб 06 ‘б «б о шб‘ Зтч? юб‘ „Ф.“
ч?
Ъь!
об‘
.... .. ‘б!  Ю.Ф|
ч?
 ‚А о Я
1.3412: Ф
«б юб
‘б
„
„ё
Ё в 3 а

 

4.2. Подбор оптимальной аёитстй сета)  97

сетей с последующим выбором той из них, которая содержит наименьшее
количество скрытых нейронов при допустимой погрешности обучения.

Решение по выбору окончательной схемы сети может быть принято только
после полноценного обучения (с уменьшением погрешности до уровня, призна-
ваемого удовлетворительным) различных вариантов ее структуры. Однако нет
никакой уверенности в том, что этот выбор будет оптимальным, поскольку
тренируемые сети могут отличаться различной чувствительностью к подбору
начальных значений весов и параметров обучения. По этой причине базу для ре-
дукции сети (англ. ргипйпд) составляют алгоритмы отсечения взвешенных связей
либо исключения нейронов в процессе обучения или после его завершения.

Как правило, методы непосредственного отсечения связей, основанные на
временном присвоении им нулевых значений, с принятием решения о
возобновлении их обучения по результатам наблюдаемых изменений величины
целевой функции (если это изменение слишком велико, следует восстановить
отсеченную связь), оказываются неприменимыми из-за слишком высокой
вычислительной сложности. Большинство применяемых в настоящее время
алгоритмов редукции сети можно разбить на две категории. Методы первой
группы исследуют чувствительность целевой функции к удалению веса или
нейрона. С их помощью устраняются веса с наименее заметным влиянием,
оказывающие минимальное воздействие на величину целевой функции, и процесс
обучения продолжается уже на редуцированной сети.

Методы второй группы связаны с модификацией целевой функции, в которую
вводятся компоненты, штрафующие за неэффективную структуру сети. Чаще
всего это бывают элементы, усиливающие малые значения амплитуды весов.
Такой способ менее эффективен по сравнению с методами первой группы,
поскольку малые значения весов не обязательно ослабляют их влияние на
функционирование сети.

Принципиально иной подход состоит в начале обучения при минимальном
‘обычно нулевом) количестве скрытых нейронов и последовательном их
добавлении вплоть до достижения требуемого уровня натренированности сети на
всходном множестве обучающих выборок. Добавление нейронов, как правило,
фоизводится по результатам оценивания способности сети к обобщению после
определенного количества циклов обучения. В частности, именно такой прием
оеатшзован в алгоритме каскадной корреляции Фальмана.

При обсуждении способности сети к обобщению невозможно обойти
цтнманием влияние на ее уровень длительности обучения. Численные
Ясперименты показали, что погрешность обучения при увеличении количества
пераций монотонно уменьшается, тогда как погрешность обобщения снижается
япько до определенного момента, после чего начинает расти. Типичная динамика
ппх показателей представлена на рис. 4.6, где погрешность обучения Ед
збозначена сплошной, а погрешность обобщения Ед - пунктирной линией.
Приведенный трафик однозначно свидетельствует, что слишком долгое обучение
пюжет привести к "переобучению" сети, которое выражается в слишком

ктальной адаптации весов к несущественным флукгуациям обучающих данных.
г-Гб?

98 4. Пеобчелды  актичеёкаго использования ЦСШСШВСННЫХ нейшнных сетей

Такая ситуация имеет место при использовании сети с чрезмерным (по сравнению
с необходимым) количеством весов, и она тем более заметна, чем больше
"лишних" весов содержит сеть. Излишние веса адаптируются к любым
нерегулярностям обучающих данных, воспринимая их в качестве важных
характеристик. Как следствие, на этапе тестирования они становятся причиной
возникновения значительных погрешностей воспроизведения.

Для предупреждения переобучения в обучаюшем множестве выделяется
область контрольных данных (подмножество У на рис. 4.4), которые в процессе
обучения применяются для оперативной проверки фактически набранного уровня
обобщения.

9
оо

О:

999
МА

  

0 100 200 300 400 500 600 700 800 900 1000
Циклобучения

Погрешности обучения и обобщения

 

0

Рис. 4.6. Иллюстрация влияния длительности обучения на погрешность обучения Ед и
на погрешность тестирования (обобщения) Ед

Обучение прекращается, когда погрешность обобщения на этом подмно-
жестве достигнет минимального значения (или начнет возрастать).

4.2.2. Методы редукции сети с учетом чувствительности

Ёедукция сети производится для уменьшения количества скрытых нейронов
межнейронных связей. Поскольку каждый скрытый нейрон представляет
гиперплоскость, разделяющую множество данных на кластеры, редукция сети
упрощает такое разделение и усиливает способность к обобщению.

Простейшим критерием редукции считается учет величины весов. Веса,
которые значительно меньше средних, оказывают незначительное влияние на
общий уровень выходного сигнала связанного с ними нейрона. Поэтому их можно
огсечь без существенного вреда для его функционирования.

Однако в некоторых случаях малые значения весов не обязательно оказывают
наименьшее воздействие на поведение нейрона. В таких ситуациях их отсечение
может привести к серьезным изменениям в работе сети. Поэтому лучшим
критерием следует признать учет чувствительности сети к вариациям весов. Без

4.2. Подбор оптийальной аехитешъры сети ' ’ ’ 99

серьезных последствий для сети из нее могут быть исключены только те веса,
чувствительность к изменениям которых оказывается минимальной.

Такой подход к проблеме отсечения весов может быть обоснован разложе-
ннем целевой функции в ряд Тейлора. В соответствии с ним изменение вешлчины
целевой функции, вызванное вариацией весов, можно выразить формулой

1 2 2

АЕ=Ё3‚Аи’‚ +5 2И„[Аи’‚‚] + хйдАшдАид +О(||Аи’ ) , (45)

1 в #1 ‘

в которой Аи’; означает вариацию Е-го веса, 3; — й-ю составляющую вектора
градиента относительно этого веса, гд = Ё , а Ид - это элементы гессиана,

321; щ

.. = ___:
и Эщдиг] ’

Не рекомендуется отсекать веса в процессе обучения, поскольку низкая
чувствительность сети к конкретному весу может быть связана с его текущим
значением либо с неудачно выбранной начальной точкой (например, при
застревании нейрона в зоне глубокого насыщения). Рекомендуется отсекать веса
шроводить регуляризацию сети) только по завершении процесса обучения, когда
все нейроны обретут свои постоянные характеристики. Это исключает
применение градиента в качестве показателя чувствительности, поскольку
минимум целевой функции характеризуется нулевым значением ‘градиента.
Поэтому в качестве показателя важности конкретных весов приходится
использовать вторые производные целевой функции (элементы гессиана).

Одним из лучших — способов регуляризации сети считается метод,
предложенный ЛеКуном [84]. Он называется ОВВ (англ.: Орг1та1ВгаЕп Ватаде).
Исходная позиция этого метода - разложение целевой функции в ряд Тейлора в
окрестности текущего решения. Для упрощения задачи ЛеКун при использовании
нетода ОВВ исходит из того, что вследствие положительной определенности гес-
:нана матрица Н является диагонально доминирующей. Поэтому можно учиты-
вать только диагональные элементы Идд и игнорировать все остальные. В качестве
меры значимости веса шд в методе ОВВ используется показатель Зд, называемый
аээффициентом асимметрии (англ.: зайепсу), который определяется в виде [84]

— 1 ат
3.. = ———м›; — (4-6)

Отсечение весов с наименьшими значениями показателя Зд не вызовет
существенных изменений в процессе функционирования сети. Процедуру ОВВ
аедукции сети можно описать в следующем виде:

1. Полное предварительное обучение сети выбранной структуры ‘Ь использо-

ванием любого алгоритма.
2

2. Определение диагональных элементов гессиана (Ид;‹= ), соответствую-

2
й
щих каждому весу, и расчет значений параметра Зд = Ёщд игё,

харакгеризующего ЗНЗЧИМОСТЬ КЮКДОЙ синаптической СВЯЗИ ДЛЯ СЕТИ В ЦВПОМ.

100 4. Пеобтемы практического использования исшсственных нейаонных сетей

3. Сортировка весов в порядке убывания приписанных им параметров Зд и
ОТССЧВНИС ТСХ ИЗ НИХ, которые ИМСКТГ НЗИМВНЬШИВ ЗНЗЧВНИЯ.

4. ’ Возврат к п. 1 для обучения сети с редуцированной структурой и повторение
процесса отсечения вплоть до исключения всех весов, оказывающих наимень-
шее влияние на величину целевой функции.

Метод ОВВ считается одним из лучших способов редукции сети среди
методов учета чувствительности. Его применение обеспечивает достижение
сетью высокого уровня обобщения, лишь незначительно отличающегося от уров-
ня погрешности обучения. Особенно хорошие результаты дает повторное обуче-
ние сети после отсечения наименее значимых весов.

В качестве примера рассмотрим реализацию этого метода для регуляризации
персептронной сети, использованной авторами [123] для прогнозирования
перегрузок в Польской энергетической системе. На рис. 4.7а представлена
исходная структура сети, а на рис. 4.76 — структура сети после регуляризации по
методу ОВВ. В результате отсечения весов из состава сети были исключены три
скрытых нейрона и ряд взвешенных связей, подходивших к оставшимся нейро-
нам. Из 201 веса оригинальной сети (рис. 4.7а) была исключена почти треть (62
веса). Решения об отсечении принимались по результатам анализа коэффици-
ентов асимметрии 8„ рассчитанных для всех весов сети. На рис. 4.8 приведен
график распределения значений этих коэффициентов, упорядоченных в порядке
их возрастания. Процесс отсечения весов состоял из трех фаз. На первой фазе
было исключено 38 весов, на второй - 16 и на третьей - 8. После каждой фазы
отсечения обучение сети повторялось. Применение процедуры ОВВ позволило
уменьшить погрешность обобщения на 7 %.

дальнейшим развитием метода ОВВ считается метод ОВЗ (англ.: Оргйта!
Вгайп 8иг3еоп), предложенный Б. Хассиби и Д. Шторком тремя годами позднее
[45]. Отправная точка этого метода (так же как и в ОВВ) — разложение целевой
функции в ряд Тейлора и игнорирование членов первого порядка. В этом методе
учитываются все компоненты гессиана, а коэффициент асимметрии веса
определяется в виде (для избавления от чегверньтх индексов вес шд; обозначается
одиночным индексом как игд)

2

 д =1—‘^1—. (41)

2 т“ 1‚‚

Отсечению подвергается вес с наименьшим значением $-. Дополнительный
результат такого подхода заключается в несложной формуле коррекции
оставшихся весов, позволяющей вернуть сеть в состояние, соответствующее
минимуму целевой функции, несмотря на отсечение веса. Уточнение значений
оставшихся (иеотсеченных) весов выполняется согласно выражению [45]

ил _
Аи’ = —%н ‘е, ‚ (4-8)
Ен" 1„
где е; означает единичный вектор с единицей в 1-й позиции, т.е.
е; = [0, ..., О, 1, ..., 017. Коррекция выполняется после отсечения каждого

101

4.2. Н оппшмальной а хитект ы сети

   

        

                 

    

          

        

     

       
  
 

    

          

   

     
    

   

  

   

 

   

      

„ лчёхЁнн х . ‚м/Ёг ‚ а о э с ее ЕЁ ‚ъ Б 1
Ъ „Ф ?\\\+\\\.\\: 511154 Ё .Ё\ЁЁ.1\‹ ‚х:
й»   /‚‚‚‚‚«„‚„‚ „те \3.\\
‚‚ ‚‚ Им . _

    

1

2%
4

„Ё

   

б)

Рис. 4.7. Иллюстрация влияния отсечения весов (методом ОВО) на структуру сети,

использованной для прогнозирования перегрузок Польской энергетической системы

а) исходная структура сеги; б) сеть после отсечения наименее значимых весов

102 4. Проблемы практического использования исшсственных нейронных сетей

очередного веса и заменяет повторное обучение сети, необходимое при

использовании метода ОВВ. Процедуру ОВЗ регуляризации сети можно описать

в следующем виде [45]:

1. Обучение нейронной сети предварительно отобранной структуры вплоть до
отыскания минимума целевой функции. ц

2. Расчет обратной гессиану матрицы Н—1 и выбор веса им, имеющего

2
наименьшее значение показателя 8;  Если изменение величины
П

целевой функции в результате отсечения этого веса намного меньше значения

Е, вес и‘; отсекается и осуществляется переход к п. 3, в противном случае

отсечение завершается.

3. Коррекция значений весов, оставшихся в сети после отсечения й-го веса, в
соответствии с формулой (4.8) с последующим возвратом к п. 2. Процесс
продолжается вплоть до отсечения всех мало значащих весов.

Основное отличие метода ОВЗ от ОВВ, помимо другого определения
коэффициента асимметрии, состоит в коррекции весов после отсечения наиме-
нее важного веса без повторного обучения сети. В методе ОВЗ всякий раз
отсекается только один вес, тогда как при использовании ОВВ можно
на каждом шаге отсекать произвольное количество весов. Вычислительная
сложность метода ОВЗ гораздо выше. Расчет диагональньхх элементов
гессиана в нем заменяется расчетом полной матрицы и обратной ей формы. На
практике этот этап можно значительно упростить при использовании
аппроксимированной формы матрицы, обратной гессиану, определяемой,
например, методом переменной метрики. Однако такое упрощение вызы-
вает снижение точности расчетов и несколько ухудшает качество искомого
решения.

  
 

0.9117 

0,494
3 доодрццкдд"

9410105 ь„„;""9";‚.—‚    
1 611 17 22 27 33 38 43 4964

     

 0%
. лов! .‚‚ дппц’... _

 
 

Рис. 4.8. Графики изменения значений коэффициента асимметрии весов (кривая х) и
функции погрешности (кривая +) для различного количества весов нейронной сети,
упорядоченные по возрастанию значений весов. Вертикальная прямая указывает
предлагаемое количество отсекаемых весов

4.2. Подбор оптимальной аттгшшы сети — ЮЗ

4.2.3. Методы редукции сети с использованием
штрафной функции

Другой метод редукции весов основан на такой организации процесса обучения,
которая провоцирует самостоятельное уменьшение значений весов и в результате
позволяет исключить те из них, величина которых опускается ниже
установленного порога. В отличие от методов учета чувствительности в
обсуждаемых методах сама целевая функция модифицируется таким образом,
чтобы в процессе обучения значения весов минимизировались автоматически
ВПЛОТЬ ДО ДОСТИЖЕНИЯ ОПРСДСЛСННОГО порога, при ПСРЁССЧСНИИ КОТОРОГО ЗНЗЧСНИЯ
соответствующих весов приравниваюгся к нулю.

Простейший метод модификации целевой функции предусматривает
добавление в нее слагаемого, штрафующего за большие значения весов: г‘;

во») = Е“) (ш) +75; „д. (49)
й

В этой формуле Е‹°’(и’) означает стандартно определенную целевую функ-
цию, заданную, например, в виде эвклидовой нормы, а у — коэффициент
штрафа за достижение весами больших значений. При этом каждый
цикл обучения складывается из двух этапов: минимизации величины
функции Е(О)(и’) стандартным методом обратного распространения и кор-
рекции значений весов, обусловленной модифицирующим фактором. Если
значение веса шд после первого этапа обозначить шдЁо), то в результате
коррекции этот вес будет модифицирован по градиентному методу наиско-

рейшего спуска согласно формуле
„г и„‘°’(1—пт)‚ (410)

где п обозначает констангу обучения. Определенная таким образом штрафная
функция вызывает уменьшение значений всех весов даже тогда, когда с учетом
специфики решаемой задачи отдельные веса должны иметь большие значеьшя.
Уровень значений, при котором вес может быть отсечен, должен подбираться с
особой тщательностью на основе многочисленных экспериментов, указывающих,
при каком пороге отсечения процесс обучения сети подвергается наименьшим
возмущениям.

Более приемлемые результаты, не вызывающие уменьшения значений всех
весов, можно получить модификацией представления целевой функции в форме

ш?

1 .
Е(‚‹›)=Е‹°> (ш)+Е’У2——4—7—. (411)
д! (1+ Ёк Щк)
Минимизация этой функции вызывает не только редукцию межнейронных
связей, но может также привести к исключению тех нейронов, для которых

величина Щи/„А близка к нулю. Легко доказать, что правило коррекции весов
1:

В ЭТОМ случае МШКСТ бЫТЬ 33113110 выражением

104 4. П емы п ичесюого использования ис ственных ней онных сетей

1+2 дало»:
„д =„;°› 1_т‚_:1—— . (412)

[‘=‘г‹"ё”>’Т '

При малых значениях весов шдд, подходящих к Е-му нейронуд происходит
дальнейшее их уменьшение. Это ведет к ослаблению выходного сигнала до
нуля и в итоге к исключению его из сети. При больших значениях весов,
ведущих к Е-му нейрону, их коррекционная составляющая исчезающе мала и
очень слабо влияет на процесс редукции сети.

Другой способ минимизации сети основан на такой модификации це-
левой функции, которая позволяет исключать скрытые нейроны, в наименьшей
степени изменяющие свою активность в процессе обучения. При этом
учитывается, что если выходной сигнал какого-либо нейрона при любых
обучающих выборках остается неизменным (на его выходе постоянно
вырабатывается 1 или О), то его присутствие в сети излишне. И напротив,
при высокой активности нейрона считается, что его функционирование дает

важную информацию. И. Шовен в [7] предложил следующую модификацию
целевой функции:

К 11
вы) = Е‹°>‹„›) + #2 Ецкг). (4.1з)

:=1 1=х у

В этом выражении Ад означает изменение значения выходного сигнала Е-го
нейрона для ]-й обучающей выборки, а е(А д2) — это корректирующий фактор
целевой функции, зависящий от активности всех К скрытых нейронов для
всех 1 (/ = 1, 2, ..., р) обучающих выборок. Коэффициент т определяет степень
относительного влияния корректирующего фактора на значение целевой
функции. Вид корректирующей функции подбирается так, чтобы изменение
целевой функции зависело от активности скрытого нейрона, причем при высо-
кой его активности (т.е. частых изменениях значения выходного сигнала)
величина АЕ должна быть малой, а при низкой активности - большой. Это

достигается применением функции е, удовлетворяющей отношению
‚ его?) 1

. (4.14)

е=—-—

дАЕ _(1+АЁ)"

Индекс п позволяет управлять процессом штрафования за низкую активность.

 

При п=2 функция е принимает вид: е= Малая активность нейронов

1+ А? `
карается сильнее, чем высокая, что в результате может привести к полному
исключению пассивных нейронов из сети.

Оба подхода к редукции сети, основанные как на учете чувствительности, так
и на модификациях целевой функции, ведут к минимизации количества весов и

нейронов сети, уменьшая таким образом уровень ее сложности и улучшая

4 3. Методы наращивания сети 105

соотношение между количеством обучающих выборок и мерой УСбйгп. В итоге
возрастает способность сети к обобщению.

4.3. Методы наращивания сети —-

В алгоритмах редукции в качестве исходной точки используется избыточная

дрхитекгура сети, которая в процессе обучения либо по его завершении

д прощается путем исключения наименее значимых весов. _
противоположный подход заключается в первоначальном включении в сеть

чебольшого количества скрытых нейронов (часто они вообще отсутствуют),
во ПО мере РЗЗВИТИЯ процесса ОбуЧСНИЯ ИХ ЧИСЛО ПОСТСПСННО УВЕЛИ-
тнвается. Среди многих существующих методов расширения нейронной сети
ножно выделить: алгоритм Мезарда-Надала [51], алгоритм Мерчанда [51] и
метод Ли-Тафтса [86], в которых все обучающие выборки ортогонально
троецируются в одномерное пространство с последующим выбором такой
‘иперплоскости, которая отделила бы данные требуемого класса от остальных.
Чногократно повторяя эту процедуру на оставщемся множестве выборок, в
шнечном счете можно обеспечить полное разделение данных. Минимизация
юличества гиперплоскостей (скрытых нейронов) в методе [86] достигается
применением булевой алгебры, в частности карты Карно. Перечисленные ме-
годы имеют относительно низкую эффективность при большой размерности
входного вектора и не являются серьезной альтернативой методам редукции
ССТИ.

Одним из наиболее известных методов расгЁйрения сети считается алгоритм
Вскадной корреляции С. Фальмана [34], который будет подробно изложен в

разделе 6.

4.4. Подбор обучающих выборок

С точки зрения цели функционирования нейронная сеть может рассматриваться
как векторный классификатор, определяющий принадлежность конкретного
входного вектора х к определенной группе. Каждый слой нейронов при этом
щполняет в составе сети собственную функцию [99]. Нейроны первого скрытого
:_1оя образуют гиперплоскости, разделяющие М-мерное пространство данных (где
‚Ч — количество входов сети) на области, содержащие данные, принадлежащие к
одному и тому же классу (англ: с1изгег). Нейроны выходного (либо второго
скрытого) слоя представляют множество данных, составляющих конкретный
кластер. При ограниченном выборе обучающих данных из универсального
множества их размещение относительно конкретных гиперплоскостей становится
очень важным. Наилучшие результаты достигаются в случае, когда они
располагаются с разных сторон границ гиперплоскостей, разделяющих
пространство данных. На рис. 4.9 представлены два различных способа выбора

106 4. Проблемы пеаюпического использования исшсственных нейронных сетей

обучающих данных (обведенных окружностями). Выбор, иллюстрируемый
рис. 4.9а, позволил определить две гиперплоскости (два нейрона), однако
он не решает проблему разделения двух классов данных (х и з). При таком
выборе потребуется еще одна гиперплоскость (т.е. еще один нейрон) для
разделения областей В и В. При выборе обучающих данных, лежащих на
границах этих областей (рис. 4.96), получено полное разделение обоих
классов. Кроме того, области В и В не содержат обучающих данных (это
пустая область пространства), что свидетельствует о возможности удаления
одной гиперплоскости (сокращение скрытого слоя до одного нейрона).

1 ` ' 353
ё/‘Х х  х х Х Е к 3
’‚‚ 3 3 3 \` 3 х. \ 3
и " | \
\` | \
В \ Е р \
' з?! а \

Рис. 4.9. Примеры выбора обучаютштх данных (обведены окружностями) из
универсального множества: а) некоррекгный выбор; б) корректный выбор

При подборе обучающих данных очень важна предварительная информация о
количестве областей, по которым распределены эти данные. Пространственные
траницы областей задаются сегментами гиперплоскостей (при проекции из
плоскость такие сегменты отображаются отрезками прямых). На рис. 4.10
представлены сегменты трех гиперплоскостей и области, образованные в
двухмерном пространстве в результате их пересечения. Области обозначены
латинскими буквами от а до 3, а сегменты гиперплоскостей — цифрами от 1 до 9
В [99] доказано, что если обозначить К (п,1\/) максимальное количестве
областей, на которые М-мерное пространство разделяется п гиперплоскостямъ’
(п нейронами), то

П
К(п,1\/)= ёс: , (415
ГДС
п! >-
сг= ‘кл-а! для“ . (ы

0 для п<1

1 4. Добавление ш ма в об чаю ие выбо ки 107

 

Если решаемая задача содержит т классов данных, то подбор мини-
чального количества нейронов должен выполняться таким образом, чтобы
эдновременно выполнялись условия К(п,1\’)2т и К(п—1,1\’)<т. Выбор
количества нейронов в слое (количества гиперплоскостей) позволяет опреде-

ЖИТЬ не ТОЛЬКО

 

х

Рис. 4.10. Иллюстрация способа образования нейронной сетью гиперплоскостей
и областей данных

число областей, но и количество сегментов гиперплоскостей, ограничивающих
эти области. Если обозначить количество этих сегментов А(п, А’), то в

юответствии с [99]  дддд ‚‚
ШШЬШ < ЁЩШ < ШЕШЁЩ (4 17)
2 — ком‘) — 2 ' ' ‚

Оценка количества сегментов гиперплоскостей очень важна для опре-
деления объема множества обучающих выборок. Принимая во внимание, что
оптимально выбранные обучающие векторы должны располагаться вблизи
конкретных сегментов гиперплоскостей, можно сделать вывод, что количество
обучающих выборок должно быть пропорционально либо А (п, А/ ), либо

гпш (п, П) - К (п,1\’).

4.5. Добавление шума в обучающие выборки

Представленные в предыдущих подразделах процедуры формирования сети
позволяют улучшить ее способности к обобщению за счет воздействия на
архитектуру сети. Это основной метод, обеспечивающий достижение требуемо-
го уровня обобщения. Однако и после формирования стабильной и мини-
мальной архитектуры сети возможно дальнейшее улучшение ее способностей

за счет специальной подготовки множества обучающих выборок. Для
хорошо натренированной сети становится актуальной задача выработки у

выходных сигналов нечувствительности к вариациям входных величин
при условии, что эти вариации ННХОДЯТСЯ В опрелеленньхх ДОПУСТИМЫХ

границах, а сеть реализует монотонное отображение. Другими словами,

108 4. Проблемы практического использования исшсственных нейронных сетей

аналогичные входные сигналы должны вызывать аналогичные реакции даже в
случае, если они не входили в состав обучающего множества.

Для математического обоснования такого требования рассмотрим
ш-хогослойную сеть с большим количеством входов›и выходов. При обозначении
вектора ВССХ ВССОВ ССТИ И’, а ВСКТОрОВ ВХОДНЫХ И ВЫХОДНЫХ СИГНаЛОВ
соответственно х и у можно определить вектор у в общем виде как

У =/("’‚ х) (4-18)

С

либо сокращенно как у = /(х)‚ где [обозначен вектор, составленный из сигмои-
дальных функций активации выходных нейронов. Аргументом функции акти-
вации каждого нейрона является сумма весов, определяемая обычным способом,
представленным в разделе 2.

Для последующих рассуждений введем различные обозначения обучаю-
щего и теспарующего входного вектора. Пусть Ё, обозначает 1с-й обучающий,
а х - тестирующий вектор. Решение задачи обучения, критерий которого
определяется как минимизация целевой функции

в =Ё Ём тали’, (419)

1г=1

позволяет оптимизировать значения весов с учетом множества только
обучающих, но не тестирующих выборок.

Минимизация этой функции не может гарантировать правильную реакцию
сети на возбуждение вектором х, который не был элементом множества
обучающих данных. ДНЯ ИССЛСДОВЗНИЯ ЧУВСТВИТСЛЬНОСТИ сети К НСбОЛЬШИМ
вариациям обучающего вектора зЁд предположим, что тестирующий вектор хд

НСЗНЗЧИТЁЛЬНО (УГПИЧЗСТСЯ (ТГ 21‘. Представим ЭТО ОТЛИЧИС В виде
х‚‹=.’Ё‚‹+ 3, 

где з = [з1‚ з;‚..., з„]Т обозначает вектор шума, составленный из случайных
переменных с малой амплитудой. Можно считать, что в тестирующем
векторе хд, близком к соответствующему обучающему вектору зЁд, содержитсх
шум, который вызывает вариации выходного сигнала уд, определяемьк
выражением

Аж =!(ё‚‚+г)—/(ё‚‚)=%г , (421

д
где % обозначен якобиан векторной функции ](х).

Для дальнейших рассуждений предположим, что вектор шума в имеет
математическое ожидание <$>‚ равное нулю, и среднеквадратичное откло
нение <$$Т>=02Е, где Е обозначена единичная матрица размерностью 4‘
а <‘> — ожидаемое статистическое значение. Символом К будем обозначат

ОТНОСИТСЛЬНУЮ ЧУВСТВИТСПЬНОСТЬ СОТИ

4.5. добавление шума в обучающие выборки Ч ` 109

к р,’ А»  -— - — 2 тващрн; . мц:
(и А» и )

К(и›) = Е——Т— , (4.22)
(мы) ‚
отражающую степень изменения значений выходных нейронов (вектор А уд),
вызванного наличием шума (вектор з) в тестирующих выборках. Принимая во
внимание зависимости (4.20) и (4.21), функцию чувствительности можно

представить В ВИДС

А Т а
‚«‚„‚= (за)  „(д/Ёо) {д/ёгд} ‚ (4.23)

С учетом принятых допущений относительно величин математического
ожидания и среднеквадратичного отклонения шума [97] упростим выражение
(4.23) и приведем его к виду

2

1«›«›= Ё1 дх

1‹=1 д’

      

где "А" означает норму Фробениуса матрицы, "А" = ггасе (ААТ) = ЁНЁ.

Очевидно, что чем меньше чувствительность К, тем слабее реагирует сеть на
"возмущения" входного вектора х по отношению к соответствующему
обучающему векгору Ё, поэтому способность сети к обобщению усиливается.
Фактор чувствительности может учитываться на стадии обучения сети. Для этого
целевая функция должна быть модифицирована. Если определить ее в форме
взвешенной суммы

ц») = вы) + ада») ‚ ‘Ё (125)
где (1 > 0 — весовой коэффициент, то получим
2

(4.26)

Ь‹›«›= ‚Ё! н ‹‘‚‚ —‚‘‹»‚›г‚‚›п’ +%

д/(Ёъ)
дх

Вместо минимизации модифицированной целевой функции Ци’) можно

принять, что отношение 1% определяет среднеквадратичное отклонение неко-
торого шума, образующего вектор п = [п 1, п2, ..., п„]Т с нулевым ожидаемым
значением <п>=0 или <ппТ>=г 1. В этом случае целевую функцию 1‚(и’)удается

преобразовать к виду [97]

А 2
и, —/‹„‚г‚‚›—Ё%хЩ„| Е (йм а, —/‹г‚ Нам’)- «На
Е=1

Выражение, которым определяется Модифицированная целевая функция,
имеет форму, идентичную стандартному представлению (4.19), с той разницей,
что вместо входного вектора Я используется зашумленный вектор 2 + п. В итоге

110 4. Пёемы Ектического использования и  пр‘ нных сетей

при минимизации этой функции учитывается не только слагдемое (4.19), но
также и фактор чувствительности Щи’), определяемый выражением (4.24).
Следовательно, в процессе обучения должны приниматься во внимание
характерные для тестовых последовательностей выборки, по которым и
подбираются оптимальные значения весов. Это подтверждает вывод, что при
зафиксированной архитектуре сети ее способности к обобщению можно
дополнительно улучшить.

Подбор среднеквадратичного отклонения шума, при котором действительно
можно повысить качество обобщения, представляет собой самостоятельную
задачу Ее теоретическое решение весьма сложно, однако относительно просто
получить экспериментальную оценку. По результатам многочисленных тестов
МОЖНО утверждать, ЧТО СРСДНСКВЗДРЗТИЧНОС ОТКЛОНСНИС шума ДОЛЖНО
коррелировать с фактическим распределением разности между обучающими
(незашумленными) выборками и тестовыми данными и составлять небольшой
процент от нее.

‚ ›

4.6. Примеры использования персептронной сети
дат

Однонаправленньте Ъейронные сети с сигмоидальной функцией активации
широко применяются на практике, составляя важное звено процесса выработки
решений. В настоящем подразделе мы ограничимся обсуждением нескольких
приложений, позволяющим подчеркнуть универсальность и разнородность
функций, которые они могут выполнять.

4.6.1. Распознавание и классификация образов

Распознаванием и классификацией образа будем называггьтёгопидентифика-
цию и отнесение к соответствующему классу данных. При решении этой
задачи нейронная сеть может выполнять функцию как экстрактора (опре-
делителя) свойств, так и классификатора, приписывающего образ конкретному
классу. Однако чаше всего экстракция свойств производится на отдельном
этапе предварительного преобразования измерительных сигналов. Для опреде-
ления свойств применяются различные методы, в том числе: метод статис-
тических моментов [81], метод преобразования Фурье [30, 151], волновое преоб-
разование [4‚ 23, 93], преобразование РСА [82], преобразование Карьюнена—Лёве
[70] ит.п.

В качестве примера рассмотрим, как персептронная нейронная сеть
используется для распознавания и классификации двухмерных образов по их
внешним описаниям. На этапе предварительной обработки сигналов будет
применяться преобразование Фурье. Описание самого образа должно
приводиться к виду, обеспечивающему его независимость от возможного
перемещения, ротации и масштабирования. В результате такого преобразования

4.6. Пеимеры использования пеесептронной сети 111

формируются значения свойств образа, подаваемые для распознавания на вход
нейронной сети. Важным достоинством преобразования Фурье считается
стабильность трансформации образа, которая в значительной степени обеспе-
чивает независимость распознавания от уровня шумов в исходном сигнале, а
также простой и быстрый в реализации алгоритм преобразования.

Начальная обработка данных на основе
быстрого преобразования Фурье (РРТ)

С ‘Ё

При распознавании образов, заданных некоторой структурой, подлежащий
распознаванию элемент определяется множеством координат (х, у) его контура.

Координатное ОпИСаНИС контура ПРЁДСТЁВПЯЁТСЯ КОМПЛЁКСНЫМ ЧИСЛОМ
в’ - "З —

го’) = х(”)+1т(”), (4.28)

где п — номер очередной пары измерительных данных, описывающих образ. Для
их обработки будем использовать дискретное преобразование Фурье (ВРТ)
в виде [64]

М—1
.  д. =Р‹’‹›= ;0:‹„›е›‹р(-12„;1‘‹п) (429)
для К = 1, 2, ..., М -1, где М означает количество точек описания структуры, а

2(п) — комплексное число, определенное выражением (4.28). Отдельные
компоненты преобразования Фурье образуют вектор Г.

Ё= [17‹), 1:1, . . ., 171144] . (430)

Этот вектор также определяет структуру образа, но в совершенно другом
пространстве параметров. Компоненты этого описания позволяют легко
преобразовывать данные независимо от их положения, масштаба, угла поворота,
а также выбранной начальной точки и общего их количества. Следует
подчеркнуть, что знания составляющих вектора Р‘ достаточны для полного
восстановления формы кривой с помощью обратного преобразования Фурье
ЦВЕТ).

Нулевой компонент ГО преобразования Фурье представляет собой среднее
значение (центр тяжести) измерительных выборок (хд, уд), поскольку

М—1

$101) .

1
17 =—.—
0 М п=О

Приравниванием этого выражения к нулю образ, представленный вектором Г,
перемещается на стандартную позицию относительно системы координат, не
зависящую от фактического первоначального расположения в пространстве
данных. По этой причине вектор Г после такого преобразования имеет вид:
Р}, = [0, Р‘ 1, Г 1, ..., ГМ_;], инвариантный относительно смещения.

112 _ 4. Пшбтемы иштдпического использования исшсстдёинй  бных сетей

Использование в преобразовании Фурье различного количества ориги-
нальных выборок (хд, уд) отражается на размерности формируемых векторов Р.
Для унификации процесса обработки данных количество наиболее значимых
компонентов этого преобразования устанавливается априорно. Согласно теории
преобразования Фурье [64] наиболее значимыми для отображения структуры
компонентами считаются пары координат Р 1 и Р м_1, следующими — Р 2 и Р м_2
и т.д. При определении К таких пар формируется редуцированное представление
вектора Рд = [0, Рд, Рд, ..., РК, Рм_;‹, ..., Р м_2, Рм_1], которое независимо от
количества измерительных выборок, использованных в преобразовании Фурье,
имеет одну и ту же априорно установленную размерность (2К+1).

Инвариантность относительно масштаба образа можно обеспечить
нормированием всех высших компонентов разложения Фурье, амплитудой
компонента, соответствующего паре Р д и Р М_1. Если обозначить коэффициент
масштабирования К‚‚ то его можно определить выражением [30, 151]

1% =\/|1й|2 +|Гм-1|2. (4.31)

В этом случае нормализация компонентов Рд вектора Р выполняется согласно
формуле

. (432)

При таком преобразовании данных полученная форма вектора Р не зависит от
размера образа.

Преобразование Фурье состоит из компонентов, допускающих оригинальную
качественную интерпретацию. Пары компонентов (Р 1 , Р м_д), (Р; , Р М_;›) и т.д.
имеют свой эквивалент в обратном преобразовании ПЭРТ, которое, в частности,
для только одной (первой) пары можно представить в виде

. .2 М-1 1:
2, =й Щехр[— ЁЙЛЁ)+РМ_‚ехр(-1—Е%4—Ь) =

= йрйехрг 121% )+ Рм_,ехр(  —

Уравнение (4.33) описывает эллипс. Первая пара (Р; ‚ Р мд) задает главный
эллипс с наиболее длинной осью, вторая пара (Р; ‚ Р Мд) — следующий по
величине и т.д. Поворот кривой относительно начальной позиции вызывает
поворот главной оси эллипса. Поэтому для обеспечения неизменности
измерительных данных относительно угла их поворота следует нормализовать
положение этой оси. Коэффициент нормализации утла поворота может быть
определен выражением [30, 151]

(4.33)

_ шд + шрш

К‚=г›‹ —1 2 , (434)

где ‘Рг, и ‘Рр„_‚- это углы степенного представления комплексных чисел Рд и Р М_1
соответственно. Нормализация данных, обеспечивающая их инвариантность

 

а) ‚ „ ‚‚‚;„—\;«—‚‚{ъ; щ‘ Исходная структура т»

 

4!‘ _ . . . . . . ‚ .
—0,25 —0‚2 —0,15 —0,1 -0,05 0 0,05 0,1 0,15 0,2 0,25
б) 2 Нормализованная структура

 

-2 —1,5 -1 —о,5 о 0,5 1 1,5 к 2
Все коэффициенты Фурье, "+” -стертоеея точке

е) Нормализоеанная структура

 

-2 -1,5 -1 —а,5 о и 0,5 1 1,5 2
Пять пар коэффициентов Фурье, "+” — стартовая точка

Рис. 4.11. Влияние нормализации и учета ограниченного количества дескрипторов Фурье
на представление кривой с большим содержанием шума:
а) форма исходной кривой; б) нормализованная форма кривой, содержащая
все дескрипторы Фурье; в) нормализованная форма кривой, содержащая только пять пар
дескрипторов Фурье

относительно угла поворота, основана на умножении каждого компонента
вектора преобразования Фурье Р), на коэффициент К;

Д, =Х‚Р‚ _ (435)

—› После такого преобразования вектор характеристик образа, подаваемый на
вход нейронной сети, не будет зависеть от угла поворота этого образа.
Аналогично можно унифицировать выбор точки начального описания образа
[151]. Последовательное выполнение описанных преобразований применительно

К ИСХОДНЫМ КОМПОНСНТЗМ ВСКТОРЗ Г ОбССПСЧИВЗСТ ПОЛНУЮ ИНВЗРИЗНТНОСТЬ
8-2162

.1 14 4. П Ы {встав использования  нных нед’ ‘нных сетей

относительно перемещения, поворота и масштабирования. Компоненты преобра-
зованного таким образом вектора называются дескрипторами образов.

Важным следствием применения преобразования Фурье в качестве препро-
цессора считается уменьшение зависимости результатов распознавания от
шума, возмущающего измерения. Помехи, как правило, имеют характер
высокочастотного шума. В преобразовании Фурье это соответствует полосе
разложения в высокочастотном диапазоне (компоненты высшего порядка
вектора Р). Отсечение этих компонентов вызывает автоматическое умень-
шение уровня шума в образе сигнала после его воспроизведения. На рис. 4.11
иллюстрируется влияние конечного количества дескрипторов Фурье на форму
воспроизведенных образов [30]: оригинальный зашумленный образ (рис.а);
образ, воспроизведенный с использованием всех 64 дескрипторов Фурье
(рис. б), образ, воспроизведенный с использованием пяти наиболее зна-
чимых нормализованных дескрипторов Фурье (рис. в). Из рисунка видно, что
уменьшение количества дескрипторов Фурье автоматически повышает ка-
чество воспроизведенного образа. Коррекция качества заметна также и при
анализе численных значений дескрипторов Фурье. Из анализа зашумленных
данных следует [31], что даже при значительном присутствии шума в
измерительных сигналах амплитудные характеристики дескрипторов изме-
няются очень незначительно. Это очень полезное качество для распозна-
вания образов, скрытых сильными помехами.

Нейронный классификатор

Выходные сигналы препроцессора в виде последовательности компонентов
дескрипторов Фурье после преобразования, обеспечивающего инвариант-
ность к перемещению, поворогу и масштабированию, становятся входными
сигналами для многослойной нейронной сети, играющей роль системы
распознавания образов и одновременно выполняющей их классификацию
(отнесение каждого образа к соответствующему эталонному классу). Количество
входных узлов сети равно количеству дескрипторов Фурье, учитываемых при
классификации. Если допустить, что каждый выходной нейрон представляет
единственный класс, то их количество также будет постоянной величиной, равной
числу классов. Поэтому в соответствии с методикой, предложенной в начале
настоящего раздела, подбираться может только количество скрытых слоев и число
нейронов в каждом слое.

Классификатор тренируется методом обратного распространения с
использованием одного из обучающих алгоритмов на множестве обучающих
данных, последовательно представляющих все классы образов, подлежащих
распознаванию. В режиме воспроизведения классифицируемый образ, прошед-
ший через все фазы препроцессора, подается на вход сети, возбуждая тот
выходной нейрон, который соответствует требуемому классу.

Из-за зашумленности образов на этапе их распознавания выходные сигналы
нейронов сети могут принимать непрерывные значения из интервала [0, 1] вместо

115

жоёёёевоомчм о зощтммыыо ‚оншьгппыпомм ЕоЁоБЕт щ Едщшыыёопо: ‚аоммцюо ЩЁЁпП .н_.ч ‚оп.-

‹..

мб м 6

 

2 6

     
      

„й

 ‚ ч=

‚т „ „в ч= З а ч? ч? „.?_ че „ё З 86 а 8.? ч? 2.? ч? щч?_
—н „ „ „ „ „ ч Ф‘ „ „ „ ‚ „ ‚ „  Ф‘
„ш ч? „ д:
„ а 28
. е че а _

м 28
м Ё „в
м щчь «в 96 ё 86 ь 8_?„.? 2.? ч?„ч„т°

дл и '

Ж  тоб|

и

ы а

  

4.6. П

116 4. Имам»: [шктического испшкьзования исштвенных нейшнных сетей

ожидаемых бинарных нуль-единичных значений (с единицей, обозначающей
распознанный класс).

Один из способов решения этой проблемы заключается в том, что в качестве
представителя распознанного класса признается наиболее активный нейрон
(выработавший самый сильный выходной сигнал). Однако такой подход не
позволяет сравнивать активность различных нейронов и приводит к ситуации, в
которой решение о победе конкретного нейрона принимается даже тогда, когда
активность всех нейронов близка к нулю. Это может приводить к ошибочной
классификации.

Наилучшим подходом представляется двухуровневая интерпретация. Вначале
проверяется, насколько максимальный сигнал превышает следующий за ним.
Если эта разница достаточно велика, победителем признается наиболее активный
нейрон. В противном случае, а также если уровни активации всех нейронов не
превышают определенного порога, интерпретатор при объявлении результата
сообщает, что классификация считается неполной’ и тем самым предостерегает
пользователя от возможной ошибки.

Подобная реализация нейросетевого классификатора была апробированэ
при распознавании и классификации многих разнообразных образов, в том
числе букв и цифр, предметов, объектов и т.п. На рис. 4.12 представленс
тестовое множество объектов различных классов, которые распознавались с
использованием персептронной сети. После предварительной обработки эти‘
данных с помощью преобразования РРТ были сформированы 18-элементньк
векторные дескрипторы (пять пар наиболее значимых коэффициентов
Фурье для амплитуды и для фазы, при этом имеющие нулевьте зна-
чения фазовьте компоненты Р‘; и Рмд не использовались). В ходе мно-
гочисленных экспериментов количество скрытых нейронов выбрано
равным 8. Применялась простейшая интерпретация результатов. Выход-
ной сигнал в диапазоне 0-0,5 рассматривался как нулевой, а свыше 0,5 — ка:
единица. После нормализации компонентов преобразования Фурье эффектив-
ность распознавания незашумленных сигналов составила 100 %. Только значи-
тельная зашумленность измерительных сигналов (исходные данные зрительнс
почти не распознавались) с уровнем шума порядка 70 % уменьшила эффектив-
ность распознавания до 90 %.

9‘-

4.6.2. Нейронная сеть для сжатия данных

Задача сжатия (компрессии) данных состоит в уменьшении количества хранимоб

или передаваемой информации с возможностью ее полного восстановленш
— (декомпрессии). Применение нейронной сети позволяет получить новые решения

для сжатия с потерей (с допустимой утратой определенной части информации
при хороших обобщающих способностях и относительно высоком коэффициент:
компрессии. 

‘ 6_ П име ы использования пе септ онной сети — 117

 

Для иллюстрации будем использовать линейную сеть с одним скрытым слоем,
нзображенную на рис. 4.13. Количество нейронов выходного слоя равно числу
узлов входного слоя. Скрытый слой содержит е; нейронов, причем 9<< п.
Входной и скрытый слои выполняют собственно компрессию данных,
:огда как скрытый и выходной слои осуществляют декомпрессию. Сеть
является автоассоциативной, поэтому ее обучающий вектор а! совпадает с
входным вектором х, а выходные сигналы сети соответствуют входным сиг-
этапам хд. ’

 

Входной слой Скрытый слой Выходной слой

Рис. 4.13. Структура нейронной сети для сжатия данных

Компрессии ПОДВСРГЗЮТСЯ ДЗННЫС, РЗЗДСЛСННЫС на кадры, ПРСДСТЗВ-
ЛЯСМЫС ПОСЛСДОВЗТСЛЬНОСТЬЮ И-ЭЛСМСНТНЫХ ВСКТОРОВ (И —‘ КОЛИЧЕСТВО ВХОДНЫХ

узлов). Кадры имеют форму прямоугольника с размерами И пикселов
по горизонтали и \’ — по вертикали. Градации интенсивности пикселов, вхо-

ДЯЩИХ В кадр, ЗЗДЗЮТСЯ ЗНИЧСНИЯМИ КОМПОНСНТОВ ВСКТОРЗ х. Пример разделения
изображения на кадры С ПОСЛСДУЮЩИМ СООТНСССНИСМ ПОВТОРЯЮЩИХСЯ ПИК-

селов изображения векгору х представлен на рис. 4.14.
Поскольку о << п, в скрытом слое может храниться меньше ин-

формации, чем во входном слое, однако она будет репрезентативной для
множества данных и достаточной для реконструкции с заранее заданной
точностью оригинальных входных данных. Сигналы скрытого слоя образуют
главные компоненты преобразования РСА (англ: Ргтсфа! Сотропепг Ападлсёв),
из которых и образуется информационное ядро {29, 82]. Количество этих

компонентов равно числу нейронов 4 скрытого слоя Большее значение о
соответствует увеличению объема информации, хранящейся в нейронах

скрытого слоя, что в свою очередь обеспечивает лучшее восстановление
входной информации в процессе декомпрессии. В примере используется

полностью линейная сеть. Веса скрытого слоя в матричной форме обозна-
чаются “д”, а выходного слоя -“’(2).

4:

118 4. Проблемы практического использования исшсственных нейронных сетей

ЁЁППППЁЕПППП5ЭППППП
ППЁЗППППБ
ППППППППП
:ПППППППП

ТЁППППП ‹

 

Рис. 4.14. Иллюстрация способа разделения образа на прямоугольные кадры

С учетом однонаправленного распространения сигналов можно получить:

’ вектор сигналов скрытого слоя (сжатые сигналы):
1: = УУшх ; (4.36)

’ вектор выходных сигналов (сигналы, восстановленные в результате
декомпрессии):
‚г = ‘Уши = и = шт т"); . (437)

Обучение сети, состоящее в оптимальном подборе весов; образующих

матрицы “д” и “д”, направлено на то, чтобы разность между ху) и д" для

всех А’ составляющих вектора х“) при 1 = 1, 2, ..., р (где р обозначено количество
векторов) была минимальной. Целевая функция, удовлетворяющая этому
условию, может быть определена в виде

=1— м (д_^(5)2 438
2‚=‚;\;1‹х‚ ‚›‚ ‹‚)

Вследствие прямоугольности обеих матриц “д” и “д” аналитического
решения этой задачи не существует, а результат процесса минимизации целевой
функции (4.38) неоднозначен по отношению к решению, получаемому путем
преобразования Карьюнена-Лёве, потому что любые матрицы, представляющие
собой линейные трансформации матриц “д” и Щи), будут одинаково хорошо
отвечать уравнению (4.37).

Поскольку количество нейронов скрытого слоя ограничено, данные, восста-
новленные в результате декомпрессии (и обозначаемые Ё‘), будут иметь опре-
деленную погрешность. Меру этой погрешности определим в форме МБЕ как

=ф ”" (‘Ф-ЧМ 439

4.6 Пеимееы использования пешептеенной сети 119

где р - это количество кадров, 11 и х’ — размер кадра соответственно по осям
х и у, а А’ — размерность вектора данных, составляющих каждый кадр,
причем А’ = Их’.

Важным параметром, характеризующим соотношение количества информа-
ции, содержащейся в образе до его компрессии, к количеству информации, опи-
сывающей сжатый образ, считается коэффициент компрессии, отражающий отно-
шение исходного и сжатого количества информации и определяемый в виде

К’: рХНХТ , - (440)

р)“; х Т + (1 >< А’ Х 1
те Т и 1 обозначают количество кодируемых битов для данных и весов
соответственно. При большом количестве кадров (р >> А!) в знаменателе
доминирует первый фактор, поэтому формулу расчета коэффициента компрессии

можно упростить и представить как отношение количеств входных нейронов А’ и

скрытых 11, т.е. К‚›= 1! . Чем больше значение К‚, тем больший эффект достигается
‘1

при хранении или передаче информации. Вместе с тем обучение сети становится
все более сложным, и, как правило, в восстановленном образе появляется все
больше искажений.

Уровень декомпрессионного искажения чаще всего оценивается коэффициен-
том РБЫК (англ.: Реа/г Зйдпадго-Ноёве Кагёо), измеряемым в децибелах и опреде-
тяемым в виде

Ё 2
Р$ЫК=10 131112. ‚ (441)
мзв
где 1: - количество битов, используемых для кодирования градаций

интенсивности изображения. При 8-битовом представлении коэффициент РЗЫК
рассчитывается по формуле

2
Р$ЫК=10 1% 255 . (442)
мзв

Большее значение коэффициента РЗЫК соответствует лучшему качеству
восстановленного изображения. Для достижения наилучших результатов
эбучения сети, предназначенной для сжатия данных, необходимо в качестве
обучающих выборок использовать как можно большее количество различных
образов, хотя вполне удовлетворительные показатели дает и обучение на всего
лишь одном изображении. После фиксации подобранных значений весов сеть
может использоваться в качестве системы кодирования (скрытый слой) либо
декодирования (выходной слой) произвольных образов.

На рис. 4.15а представлен исходный образ "Бабуин", который подвергался
вначале кодированию, а затем декодировангпо с помощью нейронной сети,
имеющей по 64 входа и выхода. Приведенное на рис. 4.156 восстановленное
изображение получено благодаря пяти скрытым нейронам (коэффициент
компрессии около 12). Исходное изображение имело размер 512 х 512 пикселов.
Сегь была предварительно обучена на друюм образе "Лес" [114], имеющем

120 .  4. П блемы п ического использования ис 01% ней 119%: сетей

   
  

такие же размеры. Качество восстановленного изображения можно признать
удовлетворительным. Значение коэффициента РЗЫК для восстановленного
образа составило 22,83 дБ. Поскольку сравнительный визуальный анализ
исходного и реконструированного образов недостаточно объективен, на
рис. 4.15в приведен так называемый дифференциальный образ, подчер-

 

‘МЕ’ ' ` .

д?  у ‘ д’:
д, ‘ _ д Ё»;
Ё ‚‹ ‹ '‹ ‘д’:
д ч ‹ ‚Ан

 

Рис. 4.15. Образ "Бабуин", подвергнутый сжаппо и декомпрессии с помощью
нейронной сети:
а) исходный образ; б) реконструированный образ; в) дифференциальный образ

кивающий разницу между ними. Он демонстрирует фактические погрешности,
допущенные нейронной сетью при восстановлении данных.

4.6.3. Идентификация динамических объектов

В динамических системах подлежащий распознаванию объект зависит от
мгновенных значений обучающих пар, представляющих собой функцию времени.
Если в отличие от предыдущих обозначений принять х в качестве вектора

‘ 5 П име ы использования пе септ иной сети "“"""^"’"`“ ч” ‘ц 121

   

юетбяния хе К" [й — входнотовипораи е К”; ау — выходного векторау е К“,
то общее описание нелинейной системы, функционирующей в дискретном
времени, может быть представлено в виде

х(1‹+1) = Ф[х‹1‹)‚ “ОШ; „. (4-43)
Удд = 1141001 › (4-44)

‘те х(1‹), и(1‹), у(1‹) обозначают векторы мгновенных значений соответствующих
‘еременных, ф и у‘ - знаки векторных статистических нелинейных функций,
ее К", ц/е КМ, определяющих инвариантный во времени конкретный нели-

аейньтй объект. т‘
В отличие от линейных уравнений связи, определяемые нелинейными зави-

шмостями, более сложны, и до настоящего времени не существует универсаль-
ного метода их аналитического решения. В качестве его заменителя применяются
приближенные математические модели, уточняющиеся в процессе обучения.

Таким образом, проблема идентификации объекта сводится к построению
такой его параметрической модели, чтобы отклики объекта у(/с) и модели
ЯК) на одно и то же возбуждение и(1‹) совпадали в пределах допустимой
погрешности г, т.е.

Н? —›’ НЁЕ - (4-45)

Среди многих возможных подходов к реализации такой нелинейной системы
выберем способ, основанный на применении нейронной сигмоидальной сети, в
общем случае многослойной. На рис. 4.16 представлена универсальная схема
подключения нейронной сети в качестве нелинейной модели динамической
системы.

Если ограничиться одним входом и выходом, а также представить векторы
возбуждешая и и отклика объекта у состоящими из элементов запаздывания, т.е.
в()'‹) = [и(/‹), и(/с-1), ..., и(1'с—р)]Т, у(/‹) = [у(/‹), у(1‹—1), ..., у(/‹—‹1)]Т, то общее описание
нелинейной динамической модели можно выразить без вектора состояния х в

форме
Р“ + 1) =/(У‹’‹)‚ 1«1‹))- (4-46)

В этом уравнении у (1‹+1) обозначает отклик нелинейного объекта в
ъюмент 1с+1‚ а ‚Ё(1с+1) — отклик нейронной модели этого объекта в тот же момент
времени. Разностный сигнал е(1с+1)=у(1с+1)-у`(/с+1) управляет процессом
адаптации параметров модели. Ряд элементов запаздывания на входе системы
образует линию задержки с огветвлениями (англ: Таррес! 1Эе1ау Ыпе — ТВЬ).

В случае применения для идентификации объектов нейронная сеть, ‘как
правило, подключается порядково-паратшельньтм способом и использует для
предсказания задерживаемые отклики объекта так, как это показано на рис. 4.16.
Достоинства такого подключения - это, во-первых, гарантированная ограничен-
ность входных сигналов модели, представляющих собой прошедшие через
элементы задержки отклики объекта (он априорно считается устойчивым), во-

122 4. П облемы п актического использования ис сственных ней онных сетей

 

вторых ""‘"’  формулы ‘ ГСНСрЗЦИИ ГРЗДИСНТВ. СЛСДУСТ ОТМСТИТЪ,
что такое подключение нейронной сети обеспечивает однонаправленное
распространение сигналов, поскольку выходной сигнал объекта является
сигналом изначально известным (в отличие от выходного сигнала модели),

 

Рис. 4.16. Способ подключения нейронной сети для идентификации
динамического объекта

поэтому сеть не должна быть рекуррентной. Поэтому вектор градиента
формируется в соответствии со стандартным для многослойной сети методом
обратного распространения, описанным в разделе 3.

При таком подключении отклик у(/‹) сети зависит от вектора и(/‹), пред-
ставляющего собой ряд прошедших через элементы задержки реализаций
возбуждающего сигнала, а также от вектора ‹1(1‹) = у(1‹), представляющего со-
бой ряд прошедших через элементы задержки реализаций заданного сигнала,
составляющих ожидаемый выходной вектор сети. В этой ситуации нейронная
сеть выполняет функции классической многослойной статической сети.

Для примера рассмотрим идентификацию нелинейного динамического
объекта Винера, состоящего из каскадно подключенных хшнейного фильтра
Батгерворта шестого порядка и нелинейного элемента в форме полиномиальной
функции х3. В нейронной модели этого объекта использована сеть с одним
скрытым слоем, содержащим 25 нейронов. Входной слой состоит из 24 узлов, а
выходной вектор составлен из 12 прошедших через элементы задержки
реализаций входного вектора х и 12 реализаций вектора 41, сформирован-
ного из откликов объекта.

В качестве входных сигналов и(1‹) использовались случайные значения.
Обучение проводилось с применением программы Пепеасй. После подбора

4.6 Пшдееы использования пеесептвонной сети 1Ё3

значений весов тестировалась способность сети к обобщению, для чего на ее вход
подавались детерминированные сигналы фиксированной структуры. Демонст-
рируемые результаты относятся только к возбуждению в форме синусоидального
сигнала. На рис. 4.17а показаны графики изменения сигнала, сгене-
рированного нелинейным объектом (пунктирная линия), и сиптала, получен-
ного на выходе нейронной модели (непрерывная линия) при синусоидаль-
ном возбуждающем сигнале. Разность (рис. 4.176) между значениями
заданными и фактически сгенерированными моделью системы, подвергнугой
идентификации, относительно мала и свидетельствует о высоком качестве
полученного решения.

9)

Сигнал заданный (объекту)
и фактический (модели)

 
 

а) 0,1

Ё 0,0а
ё 0,06
Ё 0,04 „
д, 0,02
‘О
= 0
Ё
3 —0,02
Ё
„ —0,04
П.
8 -0,0в
с

—0‚оа

_0,1 . : : : : .

0 2 4 в в 10 12 14

Время

Рис. 4.17. Результаты тестирования обученной сети из примера обработки входных
’ синусоидальных данных:
а) выходной заданный сигнал (пунктирная линия) и выходной сигнал
нейронной сети (непрерывная линия); б) график погрешности идентификации

124 4. Проблемы практического использования исшсственных нейронных сетей

4.6.4. Прогнозирование нагрузок энергетической системы

Другим важным свойством нейронных сетей" считается способность
прогнозировать временные ряды. В настоящем подразделе в качестве примера мы
рассмотрим решение задачи предсказания 24-часовых нагрузок Польской
элекгроэнергстической системы (РЗЕ).

Так же как и при классификации образов, предсказание базируется на
учете свойств прогнозируемого процесса. Главная особенность часовых
нагрузок энергетической системы - это определенная повторяемость характе-
ризующих их выборок в зависимости от дня недели и месяца. Выделяются
либо четыре основных вида нагрузок, соответствующих субботе, воскресенью,
понедельнику и остальным четырем рабочим дням, либо только два вида,
соответствующие праздничным (т.е. нерабочим) и рабочим дням. В ходе
проведенных авторами [124] статистических исследований установлено, что
распределение по четырем типам дней хотя и снижает погрешность обучения,
однако увеличивает погрешность обобщения (ухудшает результаты собст-
венно прогнозирования). Поэтому для предсказания 24-часовых нагрузок
использовалось распределение на два типа дней, что потребовало вве-
дения одного дополнительного входного узла с двоичным кодированием:
0 — праздничный день, 1 - рабочий день.

Следующий фактор, который учитывался в прогнозе, - это деление суток на
четыре периода: равномерный ночной, пиковый утренний, равномерный
дневной и пиковый вечерний. Принятое разделение суток предусматривала
смещение выделенных периодов соответственно различным временам года. Для
двоичного кодирования этих четырех периодов в сеть были введены еще два
входных узла.

И все же важнейшим фактором стал учет зависимости прогноза от
значений нагрузки в предыдущие часы и дни (динамические зависимости).
Необходимо учитывать как текущий день, так и несколько дней, пред-
шествующих прогнозируемому. При прогнозировании нагрузки Р(В‚ И) на
И-й час в В-й день во входном векторе сети учитываются следующие
величины: Р(В, 11-1), Р(В, 11-2), ..., Р(В, 11-3), Р(В—1, 11), Р(В—1, 11-1), ...,
Р(В—1, 11-3), ‚..‚ Р(1Э-а', И), Р(1Э-а'‚ 11-1), ..., Р(1Э-а', 11-3). Число а’ указывает,
сколько предшествующих дней, а число 3 - сколько предшествующих часов
принимается во внимание при прогнозировании. Проведенные исследования
показали, что удовлетворнтельные результаты достигаются при о! = 3 и 3 = 4.
С учетом двух типов дня при разделении суток на четыре периода
размерность входного вектора равна 22.

Последняя задача подтотовки данных состояла в их разделении на обучающее
и тестовое подмножества‚ Принимая во внимание огромную базу данных РЗЕ,
было решено ограничиться избранными днями, представляющими все времена
года за последние несколько лет. ‘

411 Примеры использования пешептшнной сети ' 125

Для прогнозирования нагрузок   сигмоидальная сеть с одним
скрытым слоем. Объем входного слоя выбран равным размерности входного
вектора х. Количество выходных нейронов определяется количеством
прогнозируемых периодов. Соответственно для 24-часового прогнозирования
выходной слой должен состоять из 24 линейных нейронов. Самая
трудная задача - подбор количества нейронов скрытого слоя. Если их
слишком мало, то погрешность обучения невозможно уменьшить до
требуемого уровня. Слишком большое их количество приводит к росту
погрешности обобщения. Такая сеть с практической точки зрения не
будет иметь никакой ценности. Как правило, количество скрытых
нейронов можно либо подобрать экспериментально так, чтобы уменьшить
до минимума погрешность обобщения, либо применить один из методов
построения оптимальной структуры сети, представленных ранее в настоя-
щем разделе. Процесс прогнозирования нагрузок состоит из следующих
этапов.

’ Подбор архитектуры нейронной сети.
’ Выбор обучаюших данных и структуры входных векторов.
’ Тренинг нейронной сети.

’ Тестирование сети на контрольном множестве данных и при необходимости
ее дообучение.

’ Использование сети в качеЁтве средства прогнозирования почасовой нагрузки
(этап фактического использования по назначению).

’ Возможное дообучение сети по истечении определенного времени, например
одного года эксплуатации.

Качество прогнозирования оценивается показателем процентной
погрешности МАРЕ (англ.: Меап АЬзо1иге Регсепгаде Еггог‘), определяемым в
виде ‹‘

А
п |‘: - 111

МАРЕ=1 —————-100у
„Б д ‹› ‚ (447)

А
тде Р - прямо спрогнозированное значение, а Р — фактическая нагрузка сис-

темы, тогда как п обозначено число часов, на которые составлялся прогноз.
Рассмотрим результаты 24-часового прогноза для РЗЕ, полученные при
помощи персептронной сети с одним скрытым слоем, состоящим из 25
нейронов. Структура сети имела вид: 22-25-24. Сеть обучалась с исполь-
зованием данных за 1993 и 1994 п: (выбрана четверть дней различных
времен года). Тестирование проводилось на данных 1991—1995п: На рис. 4.18
представлено распределение погрешности МАРЕ для этих лет по
24-часовому прогнозу. Минимальная погрешность, полученная для 1995 в,
составила 3,4%. Несколько лучшие результаты получены при прогнози-
ровании нагрузок только по рабочим дням. На рис. 4.19 приведены погреш-

126 4, П емы п актического использования ис ных ней сетей

 

много ъ 

Погрешность МАРЕ 24—часового прогноза ‘3›“""“Ё

Погрешность МАРЕ

 

Рис. 4.18. Распределение погрешности МАРЕ прогноза 24-часовой нагрузки для РЗЕ,
рассчитанного персептронной сетью по всем дням 1991-1995 п:

Погрешность МАРЕ 24—часового прогнозвдхтя рабошх дней

 

Рис. 4,19. Распределение погрешности МАРЕ прогноза 24-часовой нагрузки для РЗЕ,
рассчитанного персептронной сетью по всем рабочим дням 1991-1995 п:

ности МАРЕ 24-часового прогноза, рассчитанные ‘для рабочих дней.
Минимальная погрешность МАРЕ для 1995 1: составила в этом случае 3,24 %.
Анализ ежедневного распределения погрешности показал возрастание
точности прогнозирования для дней со стабильно высокой нагрузкой
(например, рабочие и зимние дни) и снижение точности для летних месяцев,
в частности в период отпусков. Стабильно высокой оказалась точность прог-
ноза на часы, в которые нагрузка изменяется незначительно (например, на
4-00, 10-00, 14-00, 22-00, 24-00). В то же время фиксировался рост средней

 

погрешности для часов, “в которые ожидались значительные колебания
нагрузок системы, связанные с организацией повседневной жизни (например,
"-00, 16-00, 19-00). Можно сделать общий вывод, что использование
многослойной персептронной сети не позволяет существенно снизить
погрешность 24-часового прогноза. Лучших результатов, как это будет показано
в разделе 9, можно достичь при использовании самоорганизующихся сетей.
Однако многослойный персептрон является очень хорошим средством
для предсказания среднесуточных нагрузок энергетической системы. Значения
таких нагрузок требуются, например, при прогнозировании с применением
лмоорганизации. В [124] авторы представили структуру персептронной
сети с одним скрытым слоем, позволяющую весьма точно предсказывать
среднесуточные нагрузки по тем же самым значениям, взятым из прошлых
периодов. Прогнозирующая модель содержит девять входных узлов,
представляющих среднесуточные нагрузки данного дня за последние годы,
время года и тип дня. Тип дня кодировался одним двоичным узлом (0 - праздник,
| - рабочий день). Кодирование времени года требует двух узлов. Приме-
нялись следующие коды: 11 — зима, 01 - весна, 00 — лето и 10 — осень. На
папе обучения сети в качестве ожидаемых значений выступали известные
среднесуточные нагрузки энергетической системы за прошедшие годы.

рт “щ?” ‘

Р‚‚‚ (11-1, у-З) -

Тип дня
Время ’
года _

Рис. 4.20. Структура персептронной сети для предсказания среднесуточных нагрузок

 

Структура нейронной сети, применявшейся для предсказания нагрузок,
изображена на рис. 4.20. Значение Р‚„ (д, у) соответствует нормализованной
среднесуточной нагрузке в день с! года у. Для улучшения способностей к
обобщению количество скрытых нейронов было подобрано эксперимен-
тально (в рассматриваемом примере оно было принято равным 5). Сеть была

128 4. Проблемы шического использования исшсственных нейронных сетей

МАРЕ 1%]

 

Рис. 4.21. Распределение погрешности МАРЕ прогноза среднесуточной нагрузки для
РЗЕ, рассчитанного персептронной сетью МАРЕ

обучена по данным РЗЕ за 1990-1995 п: На рис. 4.21 представлено
распределение погрешности МАРЕ прогноза среднесуточных значений на
период 1990-1995 п: Наибольшая погрешность МАРЕ в течение года не
превышала 1,3 %.

Раздел 5

РАДИАЛЬНЫЕ НЕЙРОННЫЕ СЕТИ

Многослойные нейронные сети, представленные в предыдущих разделах, с точки
зрения математики выполняют аппроксимацию стохастической функции
нескольких переменных путем преобразования множества входных переменных
хе К“ во множество выходных переменных уе КМ [4б, 56]. Вследствие харак-
тера сигмоидальной функции активации осуществляется аппроксимация
глобального типа. В результате ее нейрон, который был однажды включен (после
превышения суммарным сигналом и; определенного порогового значения),
остается в этом состоянии при любом значении щ, превышающем этот пород
Поэтому всякий раз преобразование значения функции в произвольной точке
пространства выполняется обьединенными усилиями многих нейронов, что и
объясняет название глобальная аппроксимация.

Другой способ отображения входного множества в выходное заключается в
преобразовании путем адаптации нескольких одиночных аппроксимирующих
функций к ожидаемым значениям, причем эта адаптация проводится только в
ограниченной области многомерного пространства. При таком подходе
отображение всего множества данных представляет собой сумму локальных
преобразований. С учетом роли, которую играют скрытые нейроны, они состав-
ляют множество базисных функций локального типа. Выполнение одиночных
функций (при ненулевых значениях) регистрируется только в ограниченной
области пространства данных — отсюда и название локальная аппроксимация.

Особое семейство образуют сети с радиальной базисной функцией, в которых
скрытые нейроны реализуют функции, радиально изменяющиеся вокруг
выбранного центра й и принимающие ненулевые значения только в окрестности
‘того центра. Подобные функции, определяемые в виде ф(х)=ф(||х - с||), будем
чазывать радиальными базисными функциями. В таких сетях роль скрытого
чейрона заключается в отображении радиального пространства вокруг одиночной
заданной точки либо вокруг группы таких точек, образующих кластер.
Суперпозиция сигналов, поступающих от всех скрытых нейронов, которая
выполняется выходным нейроном, позволяет получить отображение всего много-
мерного пространства.

Сети радиального типа представляют собой естественное дополнение
ппмоидальных сетей. Сигмоидальный нейрон представляется в многомерном
пространстве гиперплоскостью, которая разделяет это пространство на две

130 5. Радиальные ней онные сети

 

категории (два класса), в которых выполняется одно из двух условий: либо

Ешдх] > 0, либо Ё шдх; < О. Такой подход продемонстрирован на рис. 5.1а. В
1 1
свою очередь радиальный нейрон представляет‘ собой гиперсферу, которая

осуществляет шаровое разделение пространства вокруг центральной точки
(рис. 5.16). Именно с этой точки зрения он является естественным дополне-
нием сигмоидального нейрона, поскольку в случае круговой симметрии данных

а) да+
+++++ +

О
ООООО
++

дд Рис. 5.1. Иллюстрация способов разделения пространства данных:
а) сигмоидальным нейроном; б] радиальным нейроном

 

а

позволяет заметно уменьшить количество нейронов, необходимых для разделения
различных классов. Поскольку нейроны могут выполнять различные функции, в
радиальных сетях отсутствует необходимость использования большого
количества скрытых слоев. Структура типичной радиальной сети включает
входной слой, на который подаются сигналы, описываемые входным вектором х,
скрытый слой с нейронами радиального тшта и выходной слой, состоящий, как
правило, из одного или нескольких линейных нейронов. Функция выходного
нейрона сводится исключительно к взвешенному суммированию сигналов,
генерируемых скрытыми нейронами.

5.1. Математические основы

Математическую основу функционирования радиальных сетей составляет
теорема Т. Ковера [20] о распознаваемости образов, в соответствии с которой
нелинейные проекции образов в некоторое многомерное пространство могут
быть тшнейно разделены с‘ большей вероятностью, чем при их проекции в

пространство с меньшей размерностью.

Если вектор радиальных функций (р(х) = [ф1(.х‘), ф; (х), ..., ф1‹(х)]Т в
Д-мерном входном пространстве обозначить ‹р(х), то это пространство является
нелинейно (р-разделяемым на два пространственных класса Х + и Х“ тогда,

когда существует такой вектор весов и’, что

шТ‹р(х)>0 ’ хеХ+ ‚ (5_1)

з» ‘от < о хе х‘ . (52)

‚‚

Граница между этими классами определяется уравнением ю7ф(х)=0.

5. 1. Математические основы 131

В [20] доказано, что каждое множество образов, случайным образом разме-
щенных в многомерном пространстве, является (р- разделяемым с вероятностью 1
при условии соответственно большой размерности К этого пространства. На
практике это означает, что применение достаточно большого количества
скрытых нейронов, реализующих радиальные функции ф;(х), гарантирует
решение задачи классификации при построении всего лишь двухслойной
сети: скрытый слой должен реализовать вектор ‹р(х), а выходной слой может
состоять из единственного линейного нейрона, выполняющего суммирование
выходных сигналов от скрытых нейронов с —весовыми коэффициентами,
заданными вектором и’. ‹ 1::

простейшая нейронная сеть радиального ‘типа функционирует по принципу
многомерной интерполяции, состоящей в отображении р различных входных
векторов х; (Е = 1, 2,  р) из входного Н-мерного пространства во множество из
р рациональных чисел д; (1 = 1, 2,  р). Для реализации этого процесса
необходимо использовать р скрытых нейронов радиального типа изадать такую
функцию отображения Р(х), для которой выполняется условие интерполяции

1’ (М) = ‘11- “(5-3)

Использование р скрытых нейронов, соединяемых связями с весами и’; с
выходными линейными нейронами, означает формирование выходных сигналов
сети путем суммирования взвешенных значений соответствующих базисных
функций. Рассмотрим радиальную сеть с одним выходом и р обучающими па-
рами (х‚,‹1‚). Примем, что координаты каждого из р центров узлов сети опреде-
1яются одним из векторов хд, т.е. с; = хд. В этом случае взаимосвязь между
входными и выходными сигналами сети может быть определена системой урав-
нений, линейных относительно весов щ, которая в матричной форме имеет вид:

Фп Фп  Ф1р "й 41
= ‚ (5-4)

где фд =(|| х 1 —х‚ ||) определяет радиальную функцию с центром в точке хд`с

вынужденным вектором 19. Если обозначить матрицу из элементов «д; как Ф и
Вести обозначения векторов и’ = [иц, шг, ..., шд]Т, к! = [а71, 012, ..., аЫТ, система
‘равнений (5.4) может быть представлена в редуцированной матричной форме

Ф и’ = й . (5.5)
В [20] доказано, что для ряда радиальных функций в случае х‘ Ф х; =›=  ч‘ хр

квадратная интерполяционная матрица Ф является несобственной и при этом не-
прицательно определенной. Поэтому существует решение уравнения (5.5) в виде

и’ = Ф ‘1 а, (5.в)
ЧТО ПОЗВОЛЯФТ ПОЛУЧИТЬ ВСКТОР ВЭСОВ ВЫХОДНОГО нейрона СЕТИ.

132 5. Радиальные нейронные сети

„ЩТе  решение проблемы, представленное выражением (5.6), не

может считаться абсолютно истинным по причине серьезного ограничения
общих свойств сети, вытекающих из сделанных вначале допущений. При
очень большом количестве обучающих выборок и равном ему количестве
радиальных функций проблема с математической точки зрения становится
бесконечной (плохо структурированной), поскольку количество уравнений
начинает превышать число степеней свободы физического процесса,
моделируемого уравнением (5.4). Это означает, что результатом такого
чрезмерного количества весовых коэффициентов станет адаптация модели к
разного рода шумам или нерегулярностям, сопровождающим обучающие
выборки. Как следствие, интерполирующая эти данные гиперплоскость не
будет гладкой, а обобщающие возможности останутся очень слабыми.

ё» Чтобы их усилить, следует уменьшить количество радиальных функций и

‘йолучитъ из избыточного объема данных дополнительную информацию для
регуляризации задачи и улучшения ее обусловленности.

‘52. Радиальная нейроннаятеть

‚‚‚

Использование в разложении р базисных функций, где р — это количество
обучающих выборок, недопустимо также и с практической точки зрения,
поскольку обычно количество этих выборок очень велико, и в результате
вычислительная сложность обучающего алгоритма становится чрезмерной.
Решение системы уравнений (5.4) размерностью (р Чр) при больших значениях р
становится затруднительным, так как очень большие матрицы (за исключением
ортогональных), как правило, имеют порядковый характер, а коэффициент
порядка может достигать величины даже 1020. Поэтому так же как и для
многослойных сетей, необходимо редуцировать количество весов, что в этом
случае сводится к уменьшению количества базисных функций. Поэтому ищется
субоптимальное решение в пространстве меньшей размерности, которое с
достаточной точностью аппроксимирует точное решение. Если ограничиться К
базисными функциями, то аппроксимирующее решение можно представить в

ВИДЁ
г‹х›=Ё»‚«›о|х—‹‚||›, (51.

Е=1

где К < р, а с; (1 = 1, 2, ..., К) - множество центров, которые необходимо
определить. В особом случае, если принять К = р, то можно получить точное
рСШСНИС С; = Х; .

; Задача аппроксимации состоит в подборе соответствующего количества
радиальных функций ф(||х -с‚ ||) и их параметров, а также в таком подборе
весов и’; (1 = 1, 2, ..., К), чтобы решение уравнения (5.7) было наиболее близким -

точному Поэтому проблему подбора параметров радиальных функций и значени
весов и’; сети можно свести к минимизации целевой функции, которая пр

5 2. Радиальная нейранная сеть 133

использовании метрики Эвклида записывается в форме

1 к

к 2 ‚

Е = Ё[Е‚1И’;ФЩ х: ’ с:  ’ дн] . 
З этом уравнении К представляет количество радиальных нейронов, а р - коли-
чество обучающих пар (хд, ф), где х, — это входной вектор, а ф - соответст-
гуюшая ему ожидаемая величина. Обозначим а! =[‹11, ф, ..., дуг вектор ожи-
даемых значений, и’ =[и’;, шд, ..., ицДТ- вектор весов сети, а С - радиальную
матрицу называемую матрицей Грина [4б]. ’ ` ‘

Ф(Нх1 —с1 Н) Ф(Н "1 —°2 Н)  Ф(Нх1 "ск Н)

с: Ф(Нх; —с1 Н) Ф(Нх2 —с2 Н)  Ф(Нх; “ск Н)

\

фара/Ни) ‹‚›‹н›‹,‚-с2н›  «›‹н›‹,‚—‹‚‹ н)

При ограничении К базисными функциями матрица С становится
прямоугольной с количеством строк, как правило, значительно большим, чем
число столбцов (р >>К).

Если допустить, что параметры радиальных функций известны, то
оптимизационная задача (5.8) сводится к решению системы уравнений, линей-
ных относительно весов и’ [46]

щ») = а. (59)

Вследствие прямоугольности матрицы С можно определить вектор весов и’ с
использованием операции псевдоинверсии матрицы С, ‘де.

и’ = ст м ‘ — (зло)

где С+=(СТС)'1СТ обозначает псевдоинверсию прямоугольной матрицы С. В
вычислительной практике псевдоинверсия рассчитывается с применением

декомпозиции ЗУВ [42].
В обсуждаемом до этого момента решении использовалось представление

базисных функций матрицей Грина, зависяшееот эвклидовой нормы вектора
Н х -!‚ || . Если принять во внимание, что многомерная функция может ИМСТЬ
различный масштаб по каждой оси, с практической точки зрения оказывается
полезным уточнить норму масштабирования путем ввода в определение
эвклидовой метрики весовых коэффициентов в виде матрицы О:

" Н хНЁ=(Ох)Т(ОХ)=ХТОТОх . ‚ (541)
Масштабирующая матрица при Ы-мерном векторе х имеет вид:
\ 911 912  Ёш ц
‘ 921 921  921‘ "" "“"‘

о:

‘ Ёш 9112  От‘ ‘

134 5. Радиальные нейеонные дети

При обозначении произведения матриц ЧТО матрицей корреляции С в общем
случае получим:

м м
2

||х||9=22Сйх‘х] . 

:=11=1
Если„масщтабирующая матрица О имеет диагональный ‚вид, то получаем
||х ||Ё= хСдхг. Это означает, что норма масштабирования вектора х

|=1

рассчитывается согласно стандартной формуле Эвклида, с использованием
индивидуальной шкалы для каждой переменной х;. При О = 1 взвешенная
метрика Эвклида сводится к классической (немасштабируемой) метрике
||х||Ё=||1г||2.

Чаще всего в качестве радиальной функции применяется функция Гаусса.
При размещении ее центра в точке с; она может быть определена в сокращенной

форме как

||*—с; ||2

20’? '

Ф(1)= Ф(|| Х —с‚ Н) = Ф‘ — (5.13)

В этом выражении о’; — параметр, от значения которого зависит ширина функции.
В случае гауссовской формы радиальной функции с центром в точке с; и
масштабирующей взвешенной матрицы О;‚ связанной с 1-й базисной функцией,
получаем обобщенную форму функции Гаусса

т) =‹р‹и х -‹‚ под =‹›‹р[-(›‹ -‹‚ 70101‘ -‹‚)]=
=‘=›‹р[%(’ —Ф‚)ТС‚(’ ‘сдф (514)

1
20’?

1
где матрица гСд = ОКО, играет роль скалярного коэффициента

_ной многомерной функции Гаусса, заданной выражением (5.13).

Полученное решение, представляющее аппроксимирующую функцию в
многомерном пространстве в виде взвешенной суммы локальных базисных
радиальных функций (выражение (5.7)), может быть интерпретировано
радиальной нейронной сетью, представленной на рис. 5.2 (для упрощения эта
сеть имеет только один выход), в которой (р; определяется зависимостью (5.13)
штбо (5.14). Это сеть с двухспойной структурой, в которой только скрытый слой
выполняет нелинейное отображение, реализуемое нейронами с базисными
радиальными функциями. Выходной нейрон, как правило, пинеен, а его роль
сводится к взвешенному суммированию сигналов, поступающих от нейронов
скрытого слоя. Вес щ), как и при использовании сигмоидальных функций,
представляет поляризацию, вводящую показатель постоянного смещения
функции.

Полученная архитектура радиальных сетей имеет структур); аналогичную
многослойной структуре сигмоидальных сетей с одним скрытым слоем. Роль

стандарт-

5.2. Радиальная ней нная сеть 135

 

 

Рис. 5.2. Обобцтенная структура радиальной сети КЁР

«делах нейронов в ней игрёйт базисные радиальные функции, отличающиеся
своей формой от ситмоидальных функций. Несмотря на отмеченное сходство,
сети этих типов принципиально отличаются друг от друга. Радиальная сегв
имеет фиксированную структуру с одним скрытым слоем и линейными
выходными нейронами, тогда как сигмоидальная сеть может содержать различное
количество слоев, а выходные нейроны бывают как линейными, так и
целинейными. Используемые радиальные функции могут иметь весьма разно-
образную структуру [46, 60, 160]. Нелинейная радиальная функция каждого
скрытого нейрона имеет свои значения параметров с; и вд, тогда как в
сигмоидальной сети применяются, как правило, стандартные функции активации
с одним и тем же для всех нейронов параметром В. Аргументом радиальной
функции является эвклидово расстояние образца х от центра сд, а в сигмо-
цдальной сети это скалярное произведение векторов шТх.

Еще большие отличия между этими сетями можно заметить при деталь-
ПОМ сравнении их структур. Сигмоидальная сеть имеет многослойную
структур); в которой способ упорядочения нейронов повторяется от слоя
к слою. Каждый нейрон в ней выполняет суммирование сигналов с после-
дующей активацией. Структура радиальной сети несколько иная. На рис.5.3
изображена подробная схема сети КВР с радиальной функцией вида
15.13) при классическом понимании эвклидовой метрики. Из рисунка видно, что
первый слой составляют нелинейные радиальные функции, параметры ко-
торых (центры с; и коэффициенты зд) уточняются в процессе обучения. Первый
слой не содержит линейных весов в понимании, характерном для сигмоидальной
сети.

136 ЁРддЁЙд/‘ьные нёй онные сети

 

    
     

Ч

ецр (-0. 5 ик/сЁ)

Рис. 5.3. Детальная схема структуры радиальной сети КВР

Еще более сложной оказывается детальная структура сети, реали-
зующей масштабированную радиальную функцию в виде, определенном
выражением (5.14). Такая сеть, представленная на рис. 5.4, называется
НКВР (анпь: Нурег кааш Ваза‘: Гипсйоп). Радиальный нейрон в ней
имеет особенно сложную структуру, содержащую и сумматоры сигналов,
аналогичные применяемым в сигмоидальной сети, и показательные

 

Рис. 5.4. Детальная схема структуры радиальной сети НКВР с масштабирующей
матрицей О произвольного вида

5.3. Методы об ения диальных ней онных сетей  137

 

функции активации с параметрами, подлежащими уточнению в процессе
обучения. Веса Фу‘) К-го радиального нейрона скрытого слоя — это элементы
матрицы О(1‹), играющие роль масштабирующей— системы. Они вводят
дополнительные степени свободы сети, что позволяет лучше приблизить
выходной сигнал сети у = / (х) к ожидаемой функции с! (х).

 

Рис. 5.5. Детальная схема структуры радиальной сети НКВР с диагональной
масщтабирующей матрицей О

Во многих практических приложениях масштабирующая матрица О(1‹)
имеет диагональную форму, в которой только элементы 9:; принимают
ненулевые значения. В такой системе отсутствует круговое перемешивание
сигналов, соответствующих различным компонентам вектора х, а элемент

5*’ играет роль индивидуального масштабирующего коэффициента для й-го
компонента вектора х 1с-го нейрона. На рис. 5.5 представлена структура
упрощенной сети НКВР с диагональными матрицами ОП‘). Следует отметить,
что в сетях НКВР роль коэффициентов о’? выполняют элементы матрицы О,

которые уточняются в процессе обучения.

5.3. Методы обучения
радиальных нейронных сетей

Введенные в предыдущем подразделе методы подбора весов и’; выходного слоя
радиальной сети КВР были основаны на предположении, что параметры самих
базисных функций известны, в связи с чем матрицы Грина считаются
определенными, и, следовательно, задача сводится к решению избыточной
системы линейных уравнений вида (5.9). Практически такой подход

138 . к, д‹„‚‚д„.  5. Радиальные нейшнныевети

возможен только в абсолютно нереальном случае при К = р, при котором
центры с; = х; известны заранее, а значение параметра о} можно легко подоб-
рать экспериментальным путем при соблюдении определенного компромисса
между монотонностью и точностью отображения. В действительности всегда
К << р, поэтому процесс обучения сети КВР с учетом выбранного типа радиаль-
ной базисной функции сводится:

к подбору центров с; и параметров о} формы базисных функций;
о к подбору весов нейронов выходного слоя. ` _

При этом проблема уточнения весов нейронов выходногоъпоя значительно
упрощается. В соответствии с формулой (5.10) вектор весов и’ может быть
определен за один шаг псевдоинверсией матрицы С, и’ = СЧ. Матрица С,
имеющая р строк и К столбцов, представляет реакции нейронов скрытого слоя
на очередные возбуждения векторами х; (1 = 1, 2, ..., ). Практически псевдо-
инверсия матрицы С рассчитывается с использованием разложения по
собственным значениям, в соответствии с которым

с = оэу‘ (515)

Матрицы П и У ортогональны и имеют размерности (рЧр) и (КЧК)
соответственно, тотда как 5 - это псевдодиагональная матрица с размерностью
(рЧК). При этом К< р, а диагональные элементы з; 2 з;  2 ад 2 0. Допустим, что
только г первых элементов з; имеют значимую величину, а остальными можно
пренебречь. Тотда количество столбцов ортогональных матриц П и У может быть
уменьшено до г. Полученные таким образом редуцированные матрицы П, и \’‚
имеют вид:

Щ=ЫщшщЪ

и=ы„-„т

а матрица 5, = ‹11а3[в1 , 52, ..., 3,] становится полностью диагональной (квад-
ратной). Эту матрицу описывает зависимость (5.15) в форме

сгщву! . (5.16)

д Псевдообратная к С матрица определяется в этом случае выражением
0* = “‚$;‘п{ ‚ (517)

в котором $:1[ 1/51, 1/32,  ,1/$‚], а вектор весов сети, подвергающейся обучению,
задается формулой

„›=у‚$"о{‹1 . (5.18)

Достоинство формулы (5.18) - ее простота. Выходные веса сети подбираются
за один шаг простым перемножением соответствующих матриц, при этом
некоторые из них (\1‚,\’‚) ортогональные и по своей природе хорошо упоря-
дочены (коэффициент порядка равен 1).

‘ 3. Методы обшения Шдиальных нейронных сетей 139

Принимая во внимание решение (5.18), определяющее значения весов
цтходного слоя, главной проблемой обучения радиальных сетей остается подбор
згдраметров нелинейных радиальных функций, особенно центров сд.

Одним из простейших, хотя и не самым эффективным, способом определения
аараметров базисных функций, считается случайный выбор. В этом решении
хнтры с; базисных функций выбираются случайным образом на основе
эавномерного распределения. Такой подход допустим применительно к
классическим радиальным сетям при условии, что равномерное распределение
:6учающих данных хорошо соответствует специфике задачи. При выборе
"вуссовской формы радиальной функции задается значение стандартного
зтклонения зд, зависящее от разброса выбранных случайным образом центров сд!

"х'с1 "2
Ё
К

Ф(||х-с‚ н‘›=‹=›‹ - (119)

‚ыя 1 = 1, 2, ..., К, где с! обозначает максимальное расстояние между центрами
‹‚. Из выражения (5.19) следует, что стандартное отклонение гауссовской функ-

шни, характеризующее ширину кривой, устанавливается при случайном выборе
д

4%

фопорциональна максимальному разбросу центров и уменьшается с ростом
п количества.

Среди многих специализированных методов подбора центров рассмотрим
несколько наиболее важных: самоорганизующийся процесс разделения на
„тасгеры, гибридный алгоритм и обучение с учителем.

тавным сг= и постоянно для всех базисных функций. Ширина функции

5.3.1. Применение процесса самоорганизации для
уточнения параметров радиальных функций

Неплохие результаты уточнения параметров радиальных функций можно
получить при использовании алгоритма самоорганизации. Процесс самоорга-
чизации обучающих данных автоматически разделяет пространство на так
„аазываемьте области Вороного, определяющие различающиеся группы данных.
Пример такого разделения двухмерного пространства показан на рис. 5.6. Дан-
ные, сгруппированные внутри кластера, представляются центральной точкой,
определяющей среднее значение всех его элементов. Центр кластера в
дальнейшем будем отождествлять с центром соответствующей радиальной
функции. По этой причине количество таких функций равно количеству
кластеров и может корректироваться алгоритмом самоорганизации.

Разделение данных на кластеры можно выполнить с использованием одной из
версий алгоритма Линде—Бузо—-Грея [89], называемого также алгоритмом К-ус-
реднений (англ.: К-теапв). В прямой (онлайн) версии этого алгоритма уточнение

5. Радиальные ней онные сети

 

а’?!

центров‘  но" Ёёщттредъ ’ЁнЙЁ1"ЁЁй%гЁ”бЁёБёЁтнбгБ вектора х из
множества обучающих данных. В накопительной версии (оффлайн) центры
уточняются одновременно после

предъявления всех элементов

‘ множества. В обоих случаях

предварительный выбор центров

выполняется чаще всего случай-

"1 › ным образом с использованием
равномерного распределения.

‘Ц Если обучающие данные пред-

о“ т ставляют непрерывную функцию,

х НЗЧЗЛЬНЬПС ЗНЗЧСНИЯ ЦСНГРОВ В
’ первую очередь размещают в точ-

Рис. 5.6. Иллюстрация способа разделения как’ соответствующих всем Макси’

пространства дарпцдхнасферы влияния МаЛЬНЬХМ и минимальным значе‘
отдельных радиальных функций ниям функции. Данные об этих

‚ _, центрах и их ближайшем окруже-
нии впоследствии удаляются из обучаюшего множества, а оставшиеся центры
равномерно распределяются в сфере, образованной оставшимися элементами
этого множества.

В прямой версии после предъявления К-го вектора хд, принадлежащего
обучающему множеству, выбирается центр, ближайший к х;‚‚ относительно
применяемой метрики. Этот центр подвергается уточнению в соответствии с
алгоритмом ЧУТА

е‚(1с + 1) = см) +11 [хд — с(1с)], (5 .20)

тде п - коэффициент обучения, имеющий малое значение (обычно п << 1),
причем уменьшающееся во времени. Остальные центры не изменяются. Все
обучающие векторы х предъявляются по несколько раз, как правило, в случайной
последовательности вплоть до стабилизации значений центров.

Также применяется разновидность алгоритма, в соответствии с которой
значение центра-победителя уточняется в соответствии с формулой (5.20), а
один или несколько ближайших к нему центров отодвигаются в противо-
положном направлении [83], и этот процесс реализуется согласно выражению

сД/с + 1) = см‘) —п [хд — сДд]. (5.21)

Такая модификация алгоритма позволяет отдалить центры, расположенные
близко друг к другу, что обеспечивает лучшее обследование всего пространства
данных (т11<1]).

В накопительной версии предъявляются все обучающие векторы х, и
каждый из них сопоставляется какому-либо центру. Множество векторов,
приписанных одному и тому же центру образует кластер, новый центр которого
определяется как среднее соответствующих векторов:

13. Методы

   

‹‚ (Р? 1)’; д 153%‘) . (522)
Н, ;=1

В этом выражении А’ — количество векторов х(1‹)‚ приписаннь1х в К-м цикле
к Е-му центру. Значения всех центров уточняются параллельно. Процесс
предъявления множества векторов х и уточнения значений центров повторяется
многократно вплоть до стабилизации значений центров. На практике чаще всего
применяется прямой алгоритм, имеющий несколько лучшую сходимость. Однако
пи один алгоритм не гарантирует абсолютную сходимость к оптимальному
решению в глобальном смысле, а обеспечивает только локальную оптимизацию,
зависящую от начальных условий и параметров процесса обучения. При неудачно
выбранных начальных условиях некоторые центры могут застрять в области, где
юличество обучающих данных ничтожно мало либо они вообще отсутствуют,
поэтому процесс модификации центров затормозится или остановится. Способом
разрешения этой проблемы считается одновременная корректировка разме-
щения большого количества центров с фиксацией значения т] для каждого
из них. Центр, наиболее близкий к текущему векгору х, модифицируется
сильнее всего, а остальные - обратно пропорционально их расстоянию до этого
текущего вектора. п’ ‚ад;

Другой подход состоит в использовании взвешенной меры расстояния от
каждого конкретного центра до предъявляемого вектора х. Весовая норма делает
“фаворитами” те центры, которые реже всего становились победителями. Оба
подхода не гарантируют 100%-ную оптимальность решения, поскольку
представляют собой фактически процедуры возмущения предопределенного
процесса локальной оптимизации [11]. Трудностъ состоит также в подборе
юзффициента обучения п. При использовании постоянного значения п он
должен быть очень малым для гарантированной сходимости алгоритма, что
непомерно увеличивает время обучения. Адаптивные методы подбора 11
позволяют сделать его значение зависимым от времени, т.е. уменьшать по мере
роста номера итерации К. Наиболее известным представителем этой группы
считается алгоритм Даркена—Муди [11], согласно которому

П
п‹/‹)= ° . (5.23)
К
147-
Т
Коэффициент Т обозначает постоянную времени, подбираемую индиви-
зуально для каждой задачи. При [с < Т значение п практически неизменно,
но при 1с>Т оно постепенно уменьшается до нуля. Несмотря на то, что адап-
тивные методы подбора п более прогрессивны по сравнению с постоянным
значением, они тоже не могут считаться наилучшим решением, особенно при
моделировании динамических процессов.
После фиксации местоположения центров проводится подбор значений
параметров су, соответствующих конкретным базисным функциям. Параметр о;

радиальной функции влияет на форму функции и величину области ее охвата, в

142 ‚ 5. Радиальные нет‘ онные сети

которой значение этой функции не равно нулю (точнее, превышает опреде-
ленное пороговое значение в). Подбор о; должен проводиться таким образом,
чтобы области охвата всех радиальных функций накрывали все пространство
входных данных, причем любые две зоны могут перекрываться только в незна-
чительной степени. При такой организации подбора значения о; реализуемое
радиальной сетью отображение функции будет относительно монотонным.

Проще всего в качестве значения о; ]-й радиальной функции ‚принять
эвклидово расстояние между _[-м центром с] и его ближайшим соседом
[154]. В другом алгоритме, учитывающем более широкое соседство, на
значение о; влияет расстояние между ]-м центром Ч и его Р ближайшими
соседями. В этом случае значение о; определяется по формуле

1 Р

‹›‚= ; ‚;1||с‚-‹=‚‚ н’ . (514)

На практике значение Р обычно лежит в интервале [З — 5].

‘ При решении любой задачи ключевая проблема, определяющая качество
отображения, состоит в предварительном подборе количества радиальных
функций (скрытых нейронов). Как правило, при этом руководствуются общим
принципом: чем больше размерность вектора х, тем большее количество
радиальных функций необходимо для получения удовлетворительного решения.
Детальное описание процесса подбора количества радиальных функций будет
представлено в последующих подразделах.

5.3.2. Вероятностный алгоритм подбора параметров
радиальных функций

Требования к количеству скрытых нейронов можно смягчить применением
сети типа НКВР, реализующей радиальное отображение с использованием
взвешенной эвклидовой метрики. Коэффициенты О?) масштабирующей
матрицы Од, связанные с соответствующими компонентами вектора х,
определяющими Ё-ю радиальную функцию (см. рис. 5.4), представляют
собой еще одну группу параметров, подлежащих подбору и облегчающих
аппроксимацию обучающих данных радиальной сетью. За счет увеличения
количества подбираемых параметров требуемая точность может быть дос-
тигнута сетью НКВР при меньшем числе нейронов. На рис. 5.7 представлена
примерная зависимость (в процентах) величины погрешности классифи-
кации 10-мерных обучающих данных, представляющих 3 класса, от количества
скрытых нейронов [154] для радиальной сети КВР (кривая, обозначенная г)
и для сети НКВР с диагональной матрицей О (нижняя кривая на
рисунке). Кроме заметного снижения уровня погрешности классификации, в
используемой в данном примере сети НКВР количество скрытых ней-
ронов было снижено со 160 (сеть КВР) до 110 (сеть НКВР).

5.3. Методы обучения Еитыьных нейшнных сетей 143

Оптимальные значения центров и коэффициентов Од для каждой
базисной функции могут быть подобраны с помощью модифицированного
ЯЛГОРИТМЗ, ИЗМВНЯЮЩСГО ОДНОВРСМСННО И характеристики

ЗЭЧЮ

Ю
Ф

Ю
О)

КВР

Ю
-Ь

Погрешность классификации
8 В

НКВР

Ч!
@

16
0 20 40 60 80 100 120 140 160 180 200

Количество скрытых нейронов

Рис. 5.7. Иллюстрация влияния архитектуры сетей КВР и НКВР на эффективность
классификации при различном количестве радиальных нейронов

центров, и матрицу О. Одним из таких алгоритмов, разработанных для сети
НКВР с диагональной масштабирующей матрицей (1, является вероятностный
алгоритм, предложенный в работе [154]. При равномерном распределенни
обучающих данных х и при использовании диагональной масштабирующей
матрицы О процесс адаптации центров и элементов матрицы О; описывается
рекуррентньтми соотношениями

‹‚‹’‹›+и‚[«›‚‹х‚›х‚ —‹‚‹‘‹›1
‹1—‹1‚‚›+‹1‚‹р‚‹х‚› ’

в ‹‘‹› + ‹1‚[Ф‚(’‚‚ на — ‹=‚ (1‹)][’‚‚ — ‹‚ ‹‘‹›1’ — шт „Щ
(1—аь)+аьфд(хь) ’

с‚(1с + 1) = (5.25)

Р‘‚(1‹+т)=

где огд= Е? обозначает изменяющийся во времени коэффициент обучения, а 0:9

- юонстанта, подбираемая из интервала [0, 1] (чаще всего значение 0:9 лежит в
1ределах [0,5 — 0,81). В представляемом методе радиальная функция ‹р(х)
эпределяется в виде

ф(х)= ехр(— %[х — ‹‚‹1‹)1’ г,“ р: —‹‚(1‹)1) ‚ (527)

144 5. Радиальные ней онные сети

 

’”!де‘Ё;= Шаг [171 {ЁРд , .‘.., Рдд]. Ее значение соответствует условной вероятности
того, что вектор х принадлежит к кластеру с центром сд. При таком
определении матрицы Р‘; она связана с масштабируюшей матрицей Од,
используемой в сети НКВР на рис. 5.4, соотношением

1
о, = ЕР," . (5.28)

1 _
Если обе матрицы имеют диагональную структуру, то Од =  .
В зависимостях (5.25) и (5.26) на каждом этапе выполнения алгоритма
одновременно происходит адаптация и центров, и матрицы весов Р, причем
уточняются параметры всех радиальных функций сети. Это существенно
отличает описываемый метод от адаптивных зависимостей, реализуемых в
описанном в предыдущем подразделе алгоритме К -усреднений, в соответст-
вии с которым уточнялось значение только одного центра — победителя в конку-
рентной борьбе. Представленные формулы могут применяться и для сети КВР
при условии, что Р; г 1 и что в соответствии с выражением (5.25) уточняются
параметры только центра, имеющего наибольшее значение функции фд(х).

5.3.3. Гибридный алгоритм обучения радиальных сетей

В гибридном алгоритме процесс обучения разделяется на два этапа:

1) подбор линейных параметров сети (веса выходного слоя) при использовании
метода псевдоинверсии;

2) адаптация нелинейных параметров радиальных функций (центра с; и ши-
рины од этих функций).

Оба этапа тесно переплетаются. При фиксации конкретных значений
центров и ширины радиальных функций (в первый момент это будут
начальные значения) за один шаг, с использованием декомпозиции ЗУП,
подбираются величины линейных весов выходного слоя. Такая фиксация
параметров радиальных функций позволяет определить значения самих
функций фд(х;‹) для 1= 1,2, ...,К и 1‹=1,2, ...,р, где 1—зто номер радиальной
функции, а 1‹ — номер очередной обучающей пары (хьдд). Очередные воз-
буждения хд генерируют в скрытом слое сигналы, описываемые векторами
(рд = [1, ‹р1(х;‚), (рдхд), ..., ‹р1‹(х;‚)], где 1 обозначает единичный сигнал
поляризации. Им сопутствует выходной сигнал сети уд, у), = ‹р‚‚ и’, причем
вектор и’ содержит веса выходного слоя, и’ = [и’‹;, щ, ..., шк]Т. При наличии р
обучающих пар получаем систему уравнений

1 $163) Ф2(х1)  Фкфй) Щ) У1
1 Ф1(х2) Ф2(х2)  Фк(х2) И’; У2

1 ‹‚‚{(ё‚‚›‹„;ё‚‚›ЁЁЁ ‹‚‚‚Д(ё‚› д; Д

‚ (5.29)

ения адиальных ней нных сетей

 

которую в векторном виде можно записать как
Си’ = у. (5.30)

При использовании гибридного метода на этапе подбора выходных весов
вектор у заменяется вектором ожидаемых значений ‹1=[‹11, д), ...‚ ан’, и
образованная при этом система уравнений Си’ = 11 решается за один шаг с
использованием псевдоинверсии

„ест. (531)

В алгоритме расчета псевдоинверсии применяется декомпозиция ЗУВ,
позволяющая получить текущее значение вектора и’ в соответствии с фор-
худой (518).

На втором этапе при зафиксированных значениях выходных весов
возбуждающие сигналы пропускаются по сети до выходного слоя, что
позволяет рассчитать величину погрешности для последовательности
векторов хд. Далее происходит возврат к скрытому слою (обратное
заспросгранение). По величине погрешности определяется вектор градиента
хтевой функции относительно конкретных центров сд и ширины 037. Для
‘оследующего изложения предположим, что используется модель
_:ти типа НКВР с диагональной формой масштабирующей матрицы
„р. Это означает, что каждая радиальная функция определяется в
бщем виде как

1
Ф‚(х‚) = ехр [— Еда  (532)
3 суммарный сигнал нейрона щ), описывается выражением
2
„д =  . (5.33)
1=1 О’

д
При существовании р обучающих пар целевую функцию можно задать в виде

1 Ё 2 1 ‘< 2
Е =5„_‚[у‚ —‘1‚‹1 =5Н ёщФФяд-дь — (534)
В результате дифференцирования этой функции получаем:
дЕ 1 (х- —г‚—
—= Ё (л —‹1‚)ш‚ех ——и‚‚ #5—% ‚ (5.з5)
дсд ь=1 2 9-й
дЕ 1 1: —сг)2
да =‚=‚ (ш —‘1‚‹)‘^’‚г›‹ —5щ‚‹ ———————‘ б, ‘ . (5.36)

Ч й

Применение градиентного метода наискорейшего спуска позволяет провести
=нение Центров и ширины радиальных функций согласно формулам:

146 - 5. Радиальные яейшкьсшсапи

сд(п+1)=сд(п)—п% , (5.37)
Ё
Од (п+ 1) =о'д (п) —1] д? . (5.38)

Уточнение нелинейных параметров радиальной функции завершает
очередной цикл обучения. Многократное повторение обоих этапов ведет к
полному и быстрому обучению сети, особенно когда начальные значения

параметров радиальных функций близки к оптимальным.
На практике выделенные этапы в разной степени влияют на адаптацию

параметров. Как правило, быстрее функционирует алгоритм ЗУП (он за один шаг
находит локальный минимум функции). Для выравнивания этой диспропорции
одно уточнение линейных параметров сопровождается обычно несколькими
циклами адаптации нелинейных параметров.

5.3.4. Алгоритмы обучения, основанные на обратном
распространении ошибки

Обособленный класс алгоритмов обучения радиальных функций составляют
градиентные методы обучения с учителем, в которых используется алгоритм
обратного распространения ошибки. Так же как и в сигмоидальных сетях, их
основу составляет целевая функция, определенная для всех р пар обучающих
выборок (ху, ф), в виде

2
Е=ьй|:ёшгфг(ху)—д;} - (539)

2 ;=1 :=1

Для упрощения записи в дальнейшем будем учитывать только одну
обучающую выборку (х, д), вследствие чего целевая функция принимает вид:

2
в =1[)Ёш‚‹р‚(х)—д] . (540)
2 к=1

Такое упрощение ничем не ограничивает общность рассуждений, поскольку
оно может означать обучение типа “онлайн”, при котором на вход сети каждый
раз подается только один обучающий вектор. Предположим, что применяется
самая общая форма гауссовской радиальной функции ‹рд(х), соответствующей

сети НКВР, в которой

«но =ехр[-%го‚‹х —‹‚›1Ч‹2‚‹’ -‹‚›1] , 6.41)

а матрица О; имеет произвольную структуру. Независимо от выбираемого
метода градиентной оптимизации необходимо прежде всего получить

9 3. Методы об чения адиальных ней онных сетей 147

 

    
    
    
    

эхр (-0,5и,)

ехр (-0,5и,‹)

-0,5 эхр (-0‚5и,)

-0.5 вхр (—0.5и,‹)

Рис. 5.8. Графы сети НКВР, используемые для генерации градиента:
а) исходная сегь; б) сопряженная сегь

‘ехтор градиента целевой функции относительно всех параметров сети.
;1я расчета градиента будем использовать представленный в разделе 3 метод
щпряженных графов, позволяющий определить любой компонент гра-
пеита на основе анализа исходного и сопряженного с ним графа сети.
‘заф сети НКВР с обозначенными на нем сигналами представлен на
гас. 5.8.

В этой сети реализуются две нелинейные функции: квадратич-
ц: ](2)=22 и показательная ](и)=ехр(—0,5 и). В сопряженном графе,
дютветствуюшем исходному графу, обе эти функции линеаризуются

 

.‚ Э д
ОТНОСИТЁЛЬНО ЗНЗЧСНИИ 1 И 1, ОПРСДЭЛСННЫХ В ТОЧКВХ РЕШЕНИЯ ИСХОДНОЁ

82 Эи
системы, так, как это представлено на рис. 5.8 б. Направления всех дуг 1

сопряженном фафе фотивополоэкны их направлениям в исходном графе. 1
качестве источника возбуждения В СОПВЯЖЕННОМ ГВЯФС ВЫСТУПНЁГ ПЗЗНЭСТНЫЙ

сигнал (у — д), представляющий величину фактического рассогласования,
Конкретные составляющие градиента определяются непосредственно по ин-‹
формации об этих двух графах с использованием процедуры, описанной в раза
деле 3. Они принимают следующую форму: -

ъ-ш- = у —‹1 ; (542
0
ав 
Ы)- = ехр(-0,5и;)(у-‹1); в › (5.43
1 *’ 
ЭЁ, =г‹°=—е›‹р«о‚зи‚›и›‚‹у«‘› Ёеёёё"; (щ
де 1‘ ‘ ‘‹=1 
Ё; = и!” г? = — ехр‹—‹›‚зи‚›ш‚ (н) (а — СЕ") 29% (на
1‘!
ЩФ
.‘ Н _ .
15’ = ‚Е12‚$’‹х‚ —с;’› ‚ (ш
и, = Ёдгфдр. (5.4

Конкрегизация компонентов градиента позволяет задействовать для под
параметров любые градиентные методы оптимизации независимо от объеп
обучения - будь то вес и‘; либо центр сЁ", либо коэффициент масштабировани

 . Для обучения могут использоваться любые градиентные методы, пред:

тавленные в разделе 3, а также любые способы подбора коэффициента обучения

Главной проблемой, подлежащей разрешению, остается выбор начальны
значений параметров. Если процесс обучения начинается со случайных значений
то вероятность попадания в точки локальных минимумов, далеких от искомоп
решения, оказывается более высокой, чем для сигмоидальных сетей, из-т
нелинейности показательных функций. По этой причине сщчайный выбл
начальных параметров радиальных функций применяется редко. Он заменяет:
специальной процедурой инициализации, основанной на анализе информации
содержащейся во множестве обучающих данных. Этой цели слуха
представленные в настоящем разделе ашоритмы самоорганизации, действа
которых ограничивается несколькими циклами. Получаемые в результщ
значения параметров радиальных функций принимаются в качестве начальньп

5 4. Пример использования радиальной сети 149

Стартовые величины весов и’; подбираются, как правило, случайным
эбразом, так же как и в типовом алгоритме обучения сигмоидальных сетей.

5.4. Пример использования радиальной сети

Нейронные сети с радиальными базисными функциями находят применение как
при решении задач классификации либо аппроксимации функций многих
ГКРФМСННЫХ, так И при прогнозировании, т.е. в тех прикладных сферах, в которых
зигмоидальньхе сети имеют завоеванные позиции уже в течение многих лет. Они
выполняют те же функции, что и сигмоидальные сети, однако реализуют иные
методы обработки данных, связанные с локальными отображениями. Благодаря
этой особенности обеспечивается значительное упрощение и, следовательно,
ускорение процесса обучения.

В качестве примера рассмотрим аппроксимацию трехмерной функции,
которая описывается формулой

‹1=/‹х.‚›‹2›=3‹1—х‚)‘ сии-х? —‹х‚ +1›‘›+

ЧОЁ-х? —хё )е›‹р‹—х? —х%› —%е›‹р‹—‹х, +1›* —хё› .

Пусть переменные изменяются в пределах -3 5. х; 53 и —-3 5 х; 5 3.
Обучающие данные имеют равномерное распределение в областях определения
ЁЁРЁМВННЫХ х1 И х2- В Общей СПОЖНОСТИ ДЛЯ Обучения использовалось 625
нбучающих выборок в виде пар данных ( [х1, х2], с! ). Для решения задачи была
39911909?“ сеТЪ со СТРУКГУРОЙ 2—'36—1 (2 ВХОда дЛЯ х; и х; соответственно,

Погрешность

 

Номер итерации
Рис. 5.9. График обучения радиальной сети КВР для примера восстановления
трехмерной функции

-——

 

   
         

150   _. ‚„‚ х _‚ 3‘. Радиальные ней онные се’

 

‚‚.ц ’ ' ' _ ‚‚
‚ — „ . . . . — . — — — "
‚.‚-" - 3 —————— - .
. . . . . — - - 1 _ . ‚ Н ' ' ’ . . - -‘

..... "

""""""  „#71“
"` "1/
ФЁ’%О

 
   
   

....... ь! „$Ё‘  4,.“

   

     

Рис. 5.10. Результаты восстановления трехмерной функции радиальной сетью КВР:
а) восстановленная поверхность; б) погрешность восстановления

5.5. Методы подбо количества базисных ‹ ‚ .  151

   

36 радиальных нейронов гауссовского типа и один выходной линейный нейрон,
соответствующий значению ‹1 функции). Применялся гибридный алгоритм
обучения со случайным выбором начальных значений параметров сети. На рис.
5.9 представлен график обучения сети (кривая изменения погрешности с
увеличением количества итераций). Из графика видно, что прогресс в
уменьшении погрешности достаточно велик, особенно в начальной стадии
процесса.

На рис. 5.10 приведены графические представления восстановленной
функции [(х1,х;) и погрешности восстановления данных (характеристика
обученности сети). Максимальная погрешность восстановления не превысила
уровня 0,06, что составляет около 1% от ожидаемого значения. Сравнение
скорости обучения и обобщающих способностей радиальной сети с
аналогичными показателями многослойного персептрона однозначно
свидетельствует в пользу первой. Она быстрее обучается и гораздо менее
чувствительна к начальным значениям параметров как базисных функций, так и
весов выходного нейрона.

5.5. Методы подбора количества
базисных функций

Подбор количества базисных функций, каждой из которых соответствует один
скрытый нейрон, считается основной проблемой, возникающей при корректном
решении задачи аппроксимации. Как и при использовании сигмоидальных сетей,
слишком малое количество нейронов не позволяет уменьшить в достаточной
степени погрешность обобщения множества обучающих данных, тогда как
слишком большое их число увеличивает погрешность выводимого решения на
множестве тестирующих данных. Подбор необходимого и достаточного
количества нейронов зависит от многих факторов, в числе которых размерность
задачи, объем обучающих данных и прежде всего — пространственная структура
аппроксимируемой функции. Как правило, количество базисных функций К
составляет определенную долю от объема "обучающих данных р, причем
фактическая величина этой доли зависит от размерности вектора х и от раз-
броса ожидаемых значений ф, соответствующих входным векторам хд, для
1= 1, 2, ..., р.

5.5.1. Эвристические методы

Вследствие невозможности априорного определения точного количества скрытых
нейронов применяются адаптивные методы, которые позволяют добавлять или
удалять их в процессе обучения. Создано много эвристических методов,
реализующих такие операции [10, 154]. Как правило, обучение сети. начинается
при каком-либо изначально принятом количестве нейронов, а впоследствии
контролируется как степень уменьшения среднеквадратичной погрешности, так и

152 5. Радиальные нейеонные сети

ИЗМСНСНИС ЗНЗЧСНИЙ ПОДбИРЗСМЫХ параметров сети. ЕСЛИ среднее ИЗМСНСНИС
ЗНЗЧСНИЙ ВССОВ ПОСЛС ОПРВДЭЛСННОГО числа обучающих ЦИКЛОВ СПИШКОМ

мало Е‹Ащ) < Ё ‚ добавляются две базисные функций (2 нейрона) с центрами,
Ё

соответствующими наибольшей и наименьшей погрешности адаптации, после
чего обучение расширенной таким образом структуры продолжается.
Одновременно контролируются абсолютные значения весов и‘; всех отдельно
взятых нейронов. Если они меньше установленного вначале порога б,
соответствующие им нейроны подлежат удалению из сети. Как добавление
нейронов, так и’их удаление начинается после выполнения определенного
количества обучающих циклов и может происходить в течение всего процесса
обучения вплоть до достижения требуемой точности отображения.

Другой подход к управлению количеством скрытых нейронов предложил
Дж. Платт в работе [130]. Это метод, объединяющий элементы самоорганизации
и обучения с учителем. После предъявления каждой очередной обучающей

выборки определяется эвклидово расстояние между ней и центром ближайшей

существующей радиальной функции. Если это расстояние превышает
устанъвпеннъхй порог быс), то создается центр новой радиальной функции (т.е.

добавляется нейрон), после чего сеть подвергается стандартной процедуре
обучения с использованием градиентных методов (обучение с учителем). Процесс
добавления нейронов продолжается вплоть до достижения требуемого уровня
погрешности отображения. Принципиально важным для этого метода
считается подбор значения д(/‹), в соответствии с которым принимается
решение о расширении сети. Обычно 5(1‹) экспоненциально изменяется с
течением времени (в зависимости от количества итераций) от значения бтах в
начале процесса до бшд, в конце его. Недостаток этого подхода состоит в
невозможности уменьшения количества нейронов в процессе обработки
информации даже тогда, когда в результате обучения какие-то из них
дегенерируют (вследствие неудачного размещения центров) либо когда
несколько нейронов начинают дублировать друг друга, выполняя одну
и ту же функцию. Кроме того, этот метод очень чувствителен к подбору
параметров процесса обучения, особенно значений бшах и бшдп.

5.5.2. Метод ортогонализации Г рэма—Шмидта

Наиболее эффективным методом управления количеством скрытых нейронов
остается применение специальной технологии обучения сети, основанной на
методе ортогонализации наименьших квадратов, использующем классический
алгоритм ортогонализации Г рэма—Шмидта [8]. Отправная точка этого метода —
представление задачи обучения в виде линейной адаптации вектора
весов сети и’ = [и‘0‚ щ , ..., шК]Т‚ направленной на минимизацию значения вектора
погрешности е. Для р обучающих выборок вектор ожидаемых зна-
чений имеет вид: д = [д0, (11 , ..., дд]Т. При использовании К базисных функ-
ций и р обучающих пар реакции скрытых нейронов образуют матрицу С вида

‘ЙЧ’ ш

5 5‚ Методы подбора количества базисных функций 153

(Рп ‹Р21  ‘Ркп
‹== ‘Ё’? ‘Ё’? 111 “Т? ‚ 6-48’
Ф1р ‹Р2,‚  ‘Рю;

в которой ф]; обозначает реакцию 1-й радиальной функции на ]-ю обучающую
выборку, Ф]; = Ф“! х; — с; Н). Если вектор реакций 1-й радиальной функции на все

обучающие выборки обозначить 3; = [фдь ‹р;2‚..., ФЫТ, то матрицу С можно
представить в форме

с =[е‚‚г‚‚‚—‚;г‚‹1‚ (149)

При таких обозначениях на каждом этапе обучения будет выполняться
линейное равенство

д=Сю+е‚ (5.50)
‘Э ?3 Т .‚
где и’ — вектор весов, а е = [е1, е; ‚ ...‚ гр] — вектор фактической погрешности

обучения. Квадрат произведения Си’ соответствует ожидаемой энергии,
исходящей от сигналов, задаваемых вектором д, которая и подвергается
максимизации в процессе обучения.

Метод ортогонализации наименьших квадратов основан на преобразовании
векторов 3; во множество базисных ортогональных векторов, позволяющее
оценить индивидуальный вклад каждого из них в общую энергию, предс-
гавляемую ПРОИЗВСДСНИСМ Си’. ЭТО В СВОЮ очередь ПОЗВОЛЯСТ удалить те ВСКТОРЬХ,
ВЛИЯНИЕ КОТОРЫХ на ПрОЦССС ОКЗЗЫВЗСТСЯ МИНИМЗЛЬНЫМ.

В процессе обучения матрица Се КРХК раскладывается на произведение
матрицы Ое КРХК с ортогональными столбцами 9; на верхнегреугольную матрицу
Ае Ккхк с единичными диагональными значениями:

С=ОА‚ (5.51)
где
1 “12 “21 дпк
А: О 1 “22 " аж ‚
О О ‚ О - 1

а матрица О соответствует условию
ОГО = Н -

т р 2
При этом Н - диагональная матрица с элементами Н „ = (1, с], = ЁЧд . Реше-
!=1
ние зависимости (5.50) методом наименьших квадратов может быть

спроецировано в пространство, образуемое ортогональными векторами щ.
Если ввести новую векторную переменную Ь, определенную как

154 5. Радиальные нейшнные сети

Ь = А и’ , (5.52)
то из уравнения (5.5О) получим:
‹1=ОЬ+е. (5.53)

Приближенное решение уравнения (5.53) (обозначаемое символом ^ ) мето-
дом наименьших квадратов имеет вид:

Б = [ о’ о 1-1 оТа = н-‘ога. (554)
Принимая во внимание диагональный характер матрицы Н, можно получить
формулу, описывающую ё-й компонент вектора 1’:

‚_ дгй
Ьд: Т .
919:

(555)

Решение, определяющее вектор весов ш, находится непосредственно из
зависимости (5.52), которую можно переписать в форме

‚а = А-‘Б . (5.56)

С учетом треугольной структуры матрицы А вычислительная сложность
решения уравнения (5.56) относительно вектора и’ невелика.

Ортогонализация матрицы О, описанная выражением (5.51), может бьпъ
проведена различными методами, наиболее эффективным из которых считается
алгоритм Грэма-Шмидта. В соответствии с этим методом матрица А
формируется последовательно, столбец за столбцом с одновременным форми-
рованием очередных столбцов ортогональной матрицы О. На К-м шаге создается
столбец 91„ ортогональный ко всем созданным ранее (1с-1) столбцам 9; (1= 1, 2, ...,
1с-1). Процедура повторяется для значений 1: = 2, 3, ..., К. Математическая модель
этой операции имеет вид:

‘11 = 81‚ (5-57)
‘Я:

ад, = Т " ‚ (5.58)
Ч: Ч:

ь-т ‹
Ф: =$1‹ — Еднд: ‚ (5-59)

Ё=1

для 15. 151‘, 1: = 2, 3, ..., К. Многократно повторенная процедура ортогона-
лизации позволяет сформировать все ортогональные векторы 9„ и матрицу А,
на основе которых можно получить методом наименьших квадратов
приближенное решение Ё (уравнение (5.54)), а в дальнейшем из решения
треугольной системы уравнений (5.56) найти вектор ф‘.

Однако важнейшим достоинством описываемого метода ортогонализации
считается возможность селекции векторов 9; с учетом их важности для
отображения обучающих данных. В случае априори определенного количества

5. 5. Методы подбора количества базисных Ёшкций 155

К радиальных функций задача заключается в такой расстановке векторов цд,
чтобы отобрать из них первые К, наиболее значимые в энергетическом плане,
при этом, как правило, К, << К. Использование в дальнейших вычислениях
только К, радиальных функций означает сокращение количества скрытых ней-
ронов с начального их числа К до К‚. Принимая во внимание энергию сигналов,
описываемых вектором д, в соответствии с выражением (5.53) получаем

аТа = >;ь.‹‚{‹;‚ + Ете . (5.60)

Если принять, что вектор ожидаемых реакций с! имеет нулевое среднее
значение, то произведение Ьгдгд, может интерпретироваться как средний вклад,
приходящийся на одну обучающую выборку вектора Ф, соответствующего 1-й
базисной функции. Относительная доля этого составляющего в общем
энергетическом балансе может быть определена по формуле

2 т
г, =ЁЩ‚411 (вы)
с! й
для 1 = 1, 2, ...‚ К. Расчет значений в; для всех базисных функций дает
возможность оценить их важность для функционального отображения
обучающих данных, что упрощает принятие решения о ликвидации тех, чей
вклад оказывается наименьшим. После отбора наиболее значимой радиальной
функции процесс ортогонализации повторяется для получения нового реше-
ния и выбора следующей по значимости радиальной функции. При фиксации
начальной величины К = р после многократного повторения ортогонализации
Грэма—Шмидта можно отобрать К, наиболее значащих базисных функций и
исключить остальные. Таким образом количество скрытых нейронов
уменьшается от начального числа К до К . Алгоритм отбора наиболее значимых

базисных функций выглядит следующим образом [8]:
1. На первом этапе (А: = 1) для 1 <1< К рассчитать

а‚(1)=г‚‚

= [ЧАПГЁ ,

[‹1‚‹1›1‘"‹1‚‹1›

[1›‚(1)1‘[‘1‚(1)1’[‘1‚(1)1 _
аТа

Предполагается, что ад (1)= п1ах{в‚(1)} для 1 5 1 5 К , а вектор 41 = Ч‘. = 31,.

д; (1)

г; (1) =

2. На следующих этапах (К 2 2) для 1 5 1 5 К ‚ 1 1: 11 1:... ч‘: {ы следует провести
очередные циклы ортогонализации:

Т
(д) __ “18!

а -—
11‘ т
Ч;Ч;

156 = 5. Радиальные нейЕонные сети

_ "" а)
ЧЯ(’‹)'—ЁЯ_Е1Д]ЬЧ] ‚

а также оценить влияние очередных радиальных функций на суммарное значение
энергетической функции путем расчета:

[‘1‚(1‹)]"1
‹1‹)=—————— ‚
[‹1«‘‹›1Ч‹1‚‹‘‹›1

[‘›‚‹‘‹›1‘[‹1‚‹‘‹›1‘(‹1‚‹’‹›1

аТа `
Если наибольший вклад радиальной функции в общую энергию обозна-
чить г‚‚(1‹), т.е.

Ь.

1

г‚(’‹) =

51„ (д) = ШаХЁг

для 1 5 3 5 К , 5 =/= 11 ф... з‘: Е“, тогда очередной выделенный вектор щ будет
соответствовать радиальной функции со следующим по важности вкладом в
общую энергию. Этот вектор определяется выражением

!г—|
‘1‚‚’=‘1‚‚(’‹)=г‚‚ —2а‚‚‚‘1‚ ,

_[=

вкотором коэффициент а д =  для 1$]51‹-1.
3. Процедура выявления наиболее значимых для отображения радиальных
функций завершается на этапе !с=1(‚, в момент выполнения условия

К‚
1— Хе] < р ‚
‚=1
где 0 < р < 1 - это заранее установленный порог толерантности.

В результате выполнения процедуры в сети остается только 1(‚ наи-
более значимых радиальных функций, расположенных в ранее определенных
центрах (например, путем самоорганизации). Одновременно при реализации
алгоритма вычисляются конкретные составляющие вектора Ь, на основе
которых по формуле (5.52) находятся значения весов и’ выходного слоя
сети.

Геометрическая интерпретация представленной процедуры ортогонализации
достаточно проста. На Аг-м этапе выполнения алгоритма размерность базисного
пространства увеличивается на единицу, с (1с—1) до 1:, за счет введения
дополнительной базисной функции. Вводя всякий раз наиболее значимую
базисную функцию, мы получаем оптимальный их набор, что позволяет получить
наилучшие результаты обучения.

Толерантность р, определяющая момент завершения процесса обучения, - это
важный фактор, от которого зависит, с одной стороны, точность отображения
обучающих данных, а с другой стороны, — уровень сложности нейронной сети. Во
многих случаях ее значение можно оценить на основе статистического анализа

5.6 Сшвнение радиальных и сигмоидальных сетей 157

обучающих данных и фактических успехов в обучении. С методами подбора
оптимальных значений р можно ознакомиться в [8].

Еще одно достоинство процесса ортогонализации - возможность избежать
неудачной комбинации параметров процесса обучения. Выполнение условия
1дТ9д=О означает, что соответствующий вектор 31, является линейной комби-
нацией векторов 31, 31, ..., у“. Поэтому если в процессе ортогоналнзации
произведение 9,?“ меньше, чем заданное (пороговое) значение, то функцию
31, можно не включать во множество базисных функций.

5.6. Сравнение радиальных 
и сигмоидальных сетей

Радиальные нейронные сети относятся к той же категории сетей, обучаемых с
учителем, что и многослойный персептрон. По сравнению с многослойными
сетями, имеющими сигмоидальные функции активации, они отличаются
некоторыми специфическими свойствами, обеспечивающими более простое
отображение характеристик моделируемого процесса.

Сигмоидальная сеть, в которой ненулевое значение ситмоидальной функ-
ции распространяется от некоторой точки в пространстве до бесконечности,
решает задачу глобальной аппроксимации заданной функции. В то же время
радиальная сеть, основанная на функциях, имеющих ненулевые значения
только в определенной области вокруг их центров, реализует аппроксимацию
локального типа, сфера которой, как правило, более ограничена. Поэтому
необходимо понимать, что обобщающие способностн радиальных сетей
несколько хуже, чем у сигмоидальных сетей, особенно на границах области
обучающих данных. Вследствие глобального характера ситмоидальной
функции многослойные сети не обладают встроенным механизмом
идентификации области данных, на который сильнее всего реагирует конк-
ретный нейрон. Из-за физической невозможности связать зону активности
нейрона с соответствующей областью обучающих данных для сигмоидальных
сетей сложно определить исходную позицию процесса обучения. Принимая во
внимание полимодальность целевой функции, достижение глобального
минимума в такой ситуации становится чрезвычайно трудным даже при самых
совершенных методах обучения.

Радиальные сети решают эту проблему гораздо лучше. Наиболее часто
применяемые на практике радиальные функции гауссовского типа по своей
природе имеют локальный характер и принимают ненулевые значения
только в зоне вокруг определенного центра. Это позволяет легко установить
зависимость между параметрами базисных функций и физическим разме-
щением обучающих данных в многомерном пространстве. Поэтому удается
относительно просто найти удовлетворительные начальные условия процесса
обучения с учителем. Применение подобных алгоритмов обучения при начальных

158 _ „ — ==‹’ 5. Радиальные нейшнные сети

условиях, близких к оптимальным, многократно увеличивает вероятность
достижения успеха с помощью радиальных сетей.

Считается [85, 154], что радиальные сети лучше, чем сигмоидальные, решают
такие классификационные задачи, как обнаружение повреждений в различных
системах, распознавание образов и т.п. Применение радиальных сетей для
прогнозирования таких сложных временных процессов, как ежемесячные
колебания занятости трудоспособного населения в масштабах страны [8],
экономические тренды и т.д., также дает неплохие результаты, сравнимые или
даже лучшие, чем получаемые с использованием сигмоидальных сетей.

ВЗЖНОС ДОСТОИНСТ ВО радиальных сетей — ЗНЗЧИТСЛЬНО УПРОЩСННЬЖЙ алгоритм
ОбуЧСНИЯ. ПРИ НЗЛИЧИИ ТОЛЬКО ОДНОГО СКрЫТОГО СЛОЯ И ТССНОЙ СВЯЗИ ЗКГИВНОСТИ

иейрона с соответствующей областью пространства обучающих данных точка
начала обучения оказывается гораздо ближе к оптимальному решению, чем это
имеет место в многослойных сетях. Кроме того, можно отделить этап подбора

'параметров базисных функций от подбора значений весов сети (гибридный

алгоритм), что сильно упрощает и ускоряет процесс обучения. Выигрыш во
времени становится еще большим, если принять во внимание процедуру
формирования оптимальной (с точки зрения способности к обобщению)
структуры сети. При использовании многослойных сетей это очень трудоемкая
задача, требующая, как правило, многократного повторения обучения или
дообучения. Для радиальных сетей, особенно основанных на ортогонализации,
формирование оптимальной структуры сети оказывается естественным этапом
процесса обучения, не требующим никаких дополнительных усилий.

Раздел 6

СПЁЦИАЛИЗИРОВАННЫЕ СТРУКТУРЫ
НЕИРОННЫХ СЕТЕИ

6.1. Сеть каскадной корреляции Фальмана

Сеть каскадной корреляции Фальмана - это специализированная многослойная
вейронная конструкция, в которой подбор структуры сети происходит
параллельно с ее обучением путем добавления на каждом этапе обучения одного
скрытого нейрона. Таким образом, определение структуры сети и реализацию
алгоритма ее обучения можно трактовать как выполнение процедуры подбора
оптимальной архитектуры искусственной нейронной сети.

Архитектура сети каскадной корреляции представляет собой объединение
нейронов взвешенными связями в виде развивающегося каскада (рис. 6.1).
Каждый очередной добавляемый нейрон подключается к входным узлам и ко всем
уже существующим скрытым нейронам. Выходы всех скрытых нейронов и
входные узлы сети напрямую подключаются также и к выходным нейронам.

Выходы

      
  

Выходные
нейроны

Скрытый
нейрон 1

Входы

1
Поляризация

Рис. 6.1. Структура сети каскадной корреляции Фальмана

160 6. Ст иалЕЁованные сшгкттры нейшшных сетей

Каждый нейрон старается так адаптировать веса своих связей, чтобы быть
востребованным для выполняемого сетью отображения данных. На начальном
этапе формируется сеть, состоящая только из‚‚ входных узлов и выходных
нейронов. Количество входов и выходов зависит исключительно от специфики
решаемой задачи и не подлежит модификации. Каждый вход соединен со всеми
выходами посредством связей, веса которых уточняются в процессе обучения.
Выходные нейроны могут быть как линейными, так и нелинейными, с
практически произвольной функцией активации. Скрытые нейроны добавляются
в сеть по одному. Каждый добавляемый нейрон подключается ко всем входам сети
и ко всем ранее добавленным скрытым нейронам. В момент подключения
нейрона к ранее созданной структуре фиксируются веса его входных связей,
которые в дальнейшем не подлежат модификации, тогда как веса его связей с
выходными нейронами постоянно уточняются. Каждый добавляемый скрытый
нейрон образует отдельный одноэлементный слой.

Процесс обучения сети начинается до ввода в нее скрытых нейронов.
Непосредственные соединения входов и выходов тренируются таким образом,
чтобы минимизировать значение целевой функции. Для этого могут применяться
любые методы обучения. В оригинальной работе Фальмана [34] исполь-
зовался алгоритм цигс/сргор, характеризующийся быстрой сходимостью к точке
решения.

Если результат функционирования сети считается удовлетворительным с
точки зрения ожидаемой или допустимой погрешности, процесс обучения и
формирования структуры сети завершается. В противном случае следует
расширить структуру сети добавлением одного скрытого нейрона. Для этого
применяется специальная процедура, при выполнении которой вначале
формируются и фиксируются входные веса нового нейрона, после чего он
вводится в существующую сетевую структуру и его выход подключается
ко всем выходным нейронам посредством связей с соответствующими
весами. После подключения очередного скрытого нейрона происходит уточнение
(с использованием выше описанной процедуры) весов выходных нейронов.
Если полученный результат признается удовлетворительным, обучение
завершается. В противном случае процедура включения в сеть очередного
скрытого нейрона повторяется вплоть до достижения желаемых результатов
обучения.

Формирование скрытого нейрона начинается с подключения его в качестве
кандидата. Он представляет собой обособленный элемент, соединяемый со всеми
входами сети и с выходами ранее введенных скрытых нейронов. Веса связей
нейрона-кандидата подвергаются обучению, но его выходной сигнал на этом
этапе никуда не подается. В таком состоянии вновь вводимый нейрон обучается с
использованием множества обучающих выборок. Цель обучения состоит в таком
подборе весов, при котором максимизируется корреляция между его
активностью, определяемой выходным сигналом, и значением погрешности на
выходе сети. Эта зависимость определяется коэффициентом корреляции 5‘ в виде

С 1. Сеть каскадной ковре/мини Фальмана 161

$=Ё1Ё‹»‹"’—г›‹е;*’—г‚) , м)

щ р - количество обучающих выборок, М —— количество выходных нейронов, у“)
- выходной сигнал нейрона-кандидата при 1с-й обучающей выборке, ф") —
щчение погрешности /—го выходного нейрона для [г-й обучающей выборки,

д“) = ф“) - И“). 7 и г‚ обозначены средние значения соответственно 1’ и е,
пссчитанные по всему множеству обучающих выборок. ‘

Для максимизации значения функции 5‘ следует определить ее производную

В
а‘ ОТНОСИТСЛЬНО ВССОВ И’; ВСЕХ ВХОДНЫХ СВЯЗСИ НСЙРОНЗ-КЗНДИДЗТЗ. На ОСНОВЕ
1

щавила разложения составной функции и с учетом физической интерпретации
кдельных ее компонентов, по аналогии с методом обратного размножения

получаем

Ё = 1% (е? —г‚ "‹“>л‹*’‚ (61)
' 1

пе о} — обозначение корреляции между нейроном-кандидатом и ]-м выходом се-
п. Г“) — рассчитанная для 1с-й обучающей выборки производная функции
яггивации нейрона-кандидата относительно взвешенной суммы его выходных
апналов, а Д“) — импульс, получаемый от Е-го возбуждающего сигнала (входного
агиала сети либо выходного сигнала от ранее введенных скрытых нейронов).
После определения вектора градиента функции 5‘ относительно всех под-
бцраемых весов нейрона выполняется максимизация 5‘ (на практике обычно
яинимизируется значение функции 5‘) на основе любого метода оптимизации. В
оригинальной работе Фальмана это тот же самый алгоритм цийсйргор, который
применяется для подбора весов выходных нейронов. После достижения
иаксимального значения 5‘ нейрон-кандидат включается в существующую
зруктуру нейронной сети, подобранные веса его входных связей фиксируются, и
юзобновляется процесс подбора значений весов выходных нейронов за счет
минимизации целевой функции. Следует подчеркнуть, что, несмотря на большое
цшичество слоев, в сети Фальмана не требуется использовать алгоритм обратного
распространения ошибок, поскольку в процессе минимизации целевой функции
шейсгвованьт только весовые коэффициенты выходного слоя, для которых
погрешность рассчитывается непосредственно.

Для достижения наилучших результатов корреляционного обучения, как
аравило, одновременно обучается не один, а несколько нейронов-кандидатов.
Принимая во внимание, что обучение начинается со случайных значений, каждый
кандидат получает различные конечные значения весов, характеризующиеся
различными значениями коэффициента корреляции. Среди таких обученных
пндидатов выбирается имеющий наибольшее значение 8, который и вводится в
структуру сети. Параллельное корреляционное обучение нескольких нейронов-
цнцидатов уменьшает вероятность попадания в точку локального минимума и
ввода в сеть нейрона с плохо подобранными весами, которые на последующих

‘ ‘—2162

162 6. Смшалранные т ‘вы ню‘ ' сетей

этапах обучения уже невозможно будет откорректировать. Стандартное
количество одновременно обучаемых нейронов-кандидатов, рекомендуемое
авторами метода, составляет от 5 до 10.

Каждый нейрон-кандидат, прегендующий на вкточение в сетевую структуру.

может иметь свою функцию активации: сигмоидальную (биполярную или
униполярную), гауссовскую, радиальную и т.п. Побеждает тот нейрон, который
лучше приспосабливается к условиям, созданным множеством обучающих
выборок. Вследствие такого подхода сеть каскадной корреляции может
объединять нейроны с различными функциями активации, подобранными
обучающим алгоритмом с учетом той роли, которую они играют в структуре
сети.
р Алгоритм каскадной корреляции был реализован авторами на языке С и
известен под названием Сазсог [34]. После некоторых изменений, упростивших
его применение, этот алгоритм был откомпилирован в Институте теоретической
электротехники и электроизмерений Варшавского политехнического универ-
ситета с использованием компилятора РУатсот. В ходе всесторонних
исследований он продемонстрировал прекрасные качества как средство обучения
и построения сети.

В качестве численного примера рассмотрим аппроксимацию функции двух
переменных, заданную выражением

/(х‚у)=0‚5$1п(ш2)$11}(2ду)

для значений -1 51:51 и -1$у$1.

Заданная функция

0,5

 

Рис. 6.2. Пример заданной трехмерной функции, преобразуемой сетью каскадной
корреляции

6.2. Сеть Вольтет 163

На рис. 6.2 представлен трафик аппроксимируемой функции. В качестве
збучаютцих данных использовалось 500 значений этой функции, равномерно
распределенных по всему диапазону. В качестве тестирующих данных были
спенерированы 1000 значений функции в других точках того же диапазона.
Сеть обучалась исходя из условия, что значение целевой функции должно
быть меньше 0,01. Кривая обучения сети (трафик изменения погрешности обу-
щтия в зависимости от номера итерации) представлена на рис. 6.3. Ожидаемое

18

3

Кривая обупния

  

——.__‚

0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000

Номер итерации

Рис. 6.3. График кривой обучения сети каскадной корреляции на примере
преобразования трехмерной функции

значение погрешности обучения было получено на выходе сети при вве-
дении в ее структуру 41-го скрытого нейрона. Результаты тестирования
подтвердили хорошие обобщающие способности сети. График функции,
восстановленной по результатам тестирования, приведен на рис. 6.4а, а
график погрешности восстановления структуры поверхности — на рис. 6.46.

6.2. Сеть Вольтерри

Сеть Вольтерри -— это динамическая сеть для нелинейной обрабопси последо-
вательности сигналов, задержанных относительно друг друга. Возбуждением для
сети в момент п служит вектор х = [х„, х„_1, ..., х„_1‚]т, тде Ь - количество единичных
задержек, а (1‚+1) означает длину вектора. В соответствии с определением ряда
Вольтерри выходной сигнал у генерируется по формуле [123, 137].
1‚ ь 1.
т) = 2»‚х‹„-‘›+ 2 2 »‚‚‚‚›=‹п-‘‚»«п-‘‚›+

:,=\ в,=1д=\

+  - - Ё] ш‚‘‚я__‚кх(п - Е‚)х(п - 12). . .х(п -1К)‚ ‚ш, (5-3)

11‘

164 6. СтЦиалЁЁдЁньге с  НЕЁ нных сетей

а) Восстановпенная сетью функция

Рис. 6.4. Результаты восстановления трехмерной функции сетью каскадпой корреляции
Фальмана:
а) восстановленная поверхность; б) погрешность восстановления

6‚2«‚Сеть Вольт .  ” ‚ И п 165

   

где х обозначает входной сигнал, а веса щ, щ; ‚ ..., шт, и ъд., называемые
ядрами Вольтерри, соответствуют реакциям высших порядков. Нелинейная
функциональная зависимость Вольтерри является естественным поли-
номниальным обобщением описания линейного фильтра ШК [137]. Порядок
этого полинома К также называется степенью ряда Вольтерри. В случае
адаптации реакции системы Вольтерри к заданной последовательности
значений необходимо определить соответствующую целевую функцию,
например Е = 0,5[у(п) - ‹1(п)]2‚ и минимизировать ее значение с исполь-
зованием универсальных способов оптимизации нейронных сетей, сводящихся к
решению системы дифференциальных уравнений, описываемых выражением
(2.1б), которое в данном случае приобретает вид

за; %=—Д'%Е;. (6.4)

из ш‘
Векгорст обозначает вектор весов сети, Е -— целевую функцию, а сЪЕ/ди’ -
градиент. Легко показать, что при ограничении в разложении К = 3 система
дифференциальных уравнений может быть записана в виде

9%9=-и[у‹п›—‹‘‹„›1х‹п—1›‚ (65)
‹1и›——(п) ‘Ё
—й7=-м[у‹„›—‹‘‹„›1›«„—‘»«„-1›‚ (м)
а ‚.
дШьнкуш—‹1‹п›1х‹п—лх‹п—л›«п-‘› (т)

д:

для 1, 1, 1 = Г; 2, ..., Ь. Нейронная сетъ, основанная на такой модели, миними-
зирует целевую функцию Е=0,5 [у(п)-‹1(п)]2, которая, как следует из принятого
определения, является квадратичной относительно весов щ, шд, шт,  . Если эта
стратегия реализуется техническими средствами, следует считаться со
значительной сложностью системы, вызваннойсгромным количеством весов
сети. Уже при длине фильтра Ь = 6 и порядке К = 3 количество подбираемых
весов составит 84. Это количество геометрически возрастает с увеличением
щшны Ь и порядка К. „д“

Еще один недостаток непосредственного подхода к подбору весов системы
Вольтерри - ухудшение обусловленности задачи с возрастанием порядка К и
длины Ь. Следует отметить, что поскольку расчет значений ядер Вольтерри
относится к процедурам линейного типа, обусловленность задачи является
неудовлетворительной, так как содержащая многочисленные произведения
выборок х(п—1;‚) матрица коррешщии системы имеет, как правило, очень
большое число обусловленности.

166 6. Спшишнизированныг структы нейронных сетей
6.2.1. Структура и особенности обучения сети

Для упрощения структуры сети и уменьшения ее вычислительной сложности
разложение Вольтерри (6.3) можно представить в следующей форме:

Ь Ь
ул = Ехп-Т и’! + 2 хп—][шй + Ё хп-й (Шу! + "’)] 9 
Ё=0 ]=0 й=0

1

где используются обозначения у,‚ = у(п), х„.; = х(п - 1) и т.д. Каждое сла-
гаемое в квадратных скобках представляет собой линейный фильтр
первого порядка, в котором соогветствуюхцие веса представляют импульсную
реакцию другого линейного фильтра следующего уровня. Количество
уровней, на которых создаются фильтры, равно порядку К. На рис. 6.5 по-
казано распространение сигналов по сети, реализующей зависимость
(6.8)‚ при ограничении К = 3. Система представляет собой структуру
типичной многослойной однонаправпенной динамической нейронной сети. Это
сеть с полиномиальной нелинейностью. Подбор весов производится после-

Ул

————————— —————.—————————— —————————————‚———

“’ 9 9 9 9 9 9 9 9 9
У | ' 1 1 1 1 ' 1
шоа шт шаг шю шн шг: шго шг: ш22

Ха х‚ "гм д, "м: Х Хи х, ХМ х, хтг х„ "И х,‚_‚ ‘т’ х,‚_; "т?

„ Уоа „ У „ Уо: П Ута „ Ум „ Уи „ Уго „ Угт „

т
Р! . . И/д, ‚ И! ‚ И, . . „по „1 ‚ ш 1 1 ш21 ш? ‹‘
со: 012 ‘ 022 юг с т 122 202 шг’: ш
шва‘ шдп шар’ шум шут шут шго‘ шт‘! ш, 1
‘пХдд хп-З "Х„_1 ‘хо-ё "Хдд хп-Э о п о "Хдц хтёпхды х”! "хм! х“!

Рис. 6.5. Граф сети Вольтерри

5 2 Сеть Вольтшш ‚. ‹ _ у 167

ювательно слой ‚за слоем, причем эти процессы независимы друг от
друга, и, следовательно, увеличение как количества весов в слое, так и коли-
чества самих слоев в сети в незначительной степени сказывается на
обусловленности задачи. Это дает возможность существенно увеличить дли-
ну Ь и порядок К системы при ее практической реализации. Обучение
нсйронной сети, структура которой изображена на рис. 6.5, лучше всего
проводить с использованием технологии сопряженных графов, представленной
вразделе 3.

„Гид
и/д шу И’,
"п Мы хп-З
70 - Й 72
дБ

шва шаг шаг и/ю ши ш’: шга И/г, И!”
х“ хт’ хд-Э хп хм! хп-г Хи хм! хп-г
700 - 701 902 — 710 - Й: 712 720 721 722

И! 1 2 шт и’ 1 И‘, И/„д и/д , ш ‚ ‚ ш” ш’ ‚

002 шаг: 022 97102 112 шт 202 212 7/222

шт’ м" шт’ шт’ шт шт шт шт “221
Рис. 6.6. Сопряженньтй граф сети Вольтерри

Сопряженный граф для сети, представленной на рис. 6.5, строится без
особого труда. После его создания можно получшъ достаточно простые формулы,
определяющие компоненты вектора градиента, составляющие основу процесса
обучения. Сопряженньтй граф сети изображен на рис. 6.6. В соответствии с
обозначениями, принятыми на этих рисунках, возбуждением сопряженного графа
служит разностный сигнал (у„ — ‹1„), где 11„ обозначает ожидаемое, а у„ -
фактическое значение в выходном узле системы в момент п. Принимая во
внимание выражение (3.22), опредетшющее компоненты градиента, на основе

168 6. Спшишшзирнные стшдшы нейшнных сетей

Ёсходнбто и сопряженного с ним графа можно простым образом вывести
конкретные компоненты этого вектора. В частности,

дЕ
5ш_г=хп—{(уп—ад)‚ 
дЕ _ /\
'ЕТ‚Т— „—;У1, (610)
у
дЕ ‚„
= „_;‚_У;- , (611)
дЕ /\
__ _ _ = хп-ЕК Уд1‚...г„_, . (612)
|112...|К_|!К

^

В приведенных формулах сигналы, обозначенные символом , соответст-
вуют сопряженному‚ а остальные — исходному графу системы. После определения
конкретных компонентов градиента обучение сети с применением
оптимизационного метода наискорейшего спуска может быть сведено к решению
системы дифференциальных уравнений:

%”1=— 5%, (ыз)
Ёё"‚1=— %‚ (6.14)
‘Ёщь „дай; ‚ (6.15)
 то

где т обозначен коэффициент обучения. Важным достоинством метода
сопряженных графов считается простота учета равных значений весов в
различных ветвях сети. Легко заметить, что симметрия ядер Вольтерри приводит
к равенству весов шыгдк для всех перестановок индексов 11, 52, ..., ЁК [137]. Это
означает, что в случае двухиндексных весов наблюдается равенство шд = идд, а
в случае трехиндексных весов - шт, = иди, = шт = идд; = иидд = шт. Подобное
соотношение, только еще более громоздкое, относится к четырехинцексным,
пятииндексным и т.д. весам. Анализ обозначений весов сети, нзображенной на
рис. 6.5, позволяет легко найти веса, которые должны иметь одни и те же
значения. После расчета градиента относительно таких весов следует обратить
внимание, что они присутствуют на различных позициях дифференцируемого
выражения. При использовании правила суперпозиции дифференцирования
такой функции можно заметить, что расчет градиента потребует повторения

„ операции дифференцирования относительно всех ветвей сети, описанных общим

12. Сеть Вольттеи 169

весом, с последующим суммированием отдельных компонентов. С учетом сим‘-
метрии ядер Вольтерри выражения, описывающие компоненты градиента
относительно весов шд, шдд и т.д., могут быть„ определенным образом
‘юдифицированы по сравнению с введенными ранее формулами. Их можно

представить в виде (см. формулу 3.28)

дЕ
д = ХНЙ + Хи-Й"; ‚ (517)
“Ъ
ЭЕ А
дш Чы-ЬЙ + ‘мы + Хн-ЬЁ’): + Хп-‘Йд + Хп-уун + Хв-‘Ёл; - (6-13)
т‘ ‚а

При использовании ядер Вольтерри высших порядков будет действовать
аналогичное правило, обусловленное существованием ветвей, которые
вписываются весами с одинаковыми значештями. Выделение соответствующих
компонентов градиента позволяет реализовать процесс оптимизации путем
сведения его к решению системы дифференциальных уравнений, описываемых

формулами (6.13) - (6.16).
6.2.2. Примеры использования сети Вольтерри

Идентификация нелинейного объекта

В процессе идентификации объекта одна и та же последовательность входных
сигналов х(п) подавалась параллельно на объект и его модель так, как это
показано на рис. 6.7. Разность фактических реакций модели у(п) и объекта ‹1(п)
‘последняя рассматривалась как ожидаемое значение) воспринималась как
сигнал погрешности г(п) = у(п) - а’ (п), управляющий адаптивным алгоритмом,
шторый подбирает параметры модели таким образом, чтобы уменьшить сигнал
рассогласования г(п) до нуля. Использование в качестве модели нелинейной
системы, описываемой полиномом Вольтерри, позволило значительно расширить
класс идентифнцируемых объектов. При этом следует учитывать, что сеть

 

Рис. 6.7. Схема включения сети Вольтерри в адаптивной системе идентификации
динамического объекта

170 6. Спгшшвизшованные сЖШЁ пр" них сетей

Вольтерри является обобщением линейного фильтра типа РНК, поэтому она
накрывает классы как линейных, так и нелинейных систем. При применении ее
для идентификации объекта реализовалась описанная выше общая стратегия
адаптации, основанная на разложении Вольтерри (6.8) и на концепции
сопряженных графов. В экспериментальных исследованиях учитывался принцип
естественной симметрии ядер Вольтерри, вследствие которой все веса ш‚‚‚‚__‚‚

имеют одни и те же значения для каждой комбинации индексов 21, 12, ...‚ ЭК.
Уравнения адаптации весов были представлены в форме дифференциальных
уравнений (6.13) - (6.16) при описании компонентов вектора градиента
выражениями (6.9), (6.17), (6.18). Вся адаптивная система была реализована на
языке Зйтийпк со значением коэффициента обучения т = 106. На рис. 6.8

0,8

Погрвшноапь

  

0 (24 0‚6 0,8 1,4 1,6
Время "104
Рис. 6.8. Процесс обучения сети Вольтерри в примере идентификации

представлен график обучения е(п) как функция от времени для системы.
идентифицирующей нелинейный динамический объект, который описывается

ЗЗВИСИМОСТЬЮ
а»: = хп—1 +хп-1хп—2 +хпхп-|хп—2 .

За время, меньшее 15 микросекунд, погрешность идентификации был:
уменьшена до нуля, а реакции объекта и модели стали совпадать с точностью до
второго знака после запятой. Параметры объекта были идентифицированн
следующим образом:

“оп = “он = “т = “по = "’2о1 = "’210 = О›1649 ›
ш” = игд = 0‚4999‚
и’, = 1,02 .

 

' ‘Значения отличия весов фильтра были равны нулю с толерантностъю 104.
В итоге объект был идентифицирован в виде

у‚‚ =1,02х‚‚_‚ + 0,999х‚‚_‚х„_2 + 0,989х„х‚‚_‚х„:2

цтгорый с высокой точностью обеспечивает получение принятых в качестве
псходных значений ‹1„.

Устранение интерференционных шумов ‹

Общая структура адаптивной системы для устранения интерференционных
цумов представлена на рис. 6.9. Полезный сигнал з смешан с некоррелируемым с
Щи шумом по. Сигнал п является установочным, он не коррелирован с з, однако
неизвестным образом коррелирует с сигналом помехи по. Считается, что з, п

х=в+п‹‚

    
    

  

Сеть
Вольтерри

Рис. 6.9. Схема вкшочения сети Вольтерри в адаптивной системе исключения
интерференционных шумов

п по статистически стационарны, а их средние значения равны нулю. Задача
сети Вольтерри состоит в такой обработке сигнала п, чтобы сигнал у на выходе
сети был как можно более близок к сигналу помехи по. Сигнал погрешности е,
вырабатываемый сумматором (рис. 6.9), определяется как

г=з+п‚‚—у. (619)

Целевую функцию можно представить в форме ожидаемого значения Е
вадратичной погрешности

Ё = О‚5Е[г21=О‚5Е[$2 +("0—У)2+2$("0—У)]- (610)

Если принять во внимание, что сигнал з не коррелирует с сигналами помехи,
то ожидаемое значение Е [в ( по - у)] = 0 и целевая функция упрощаются до
выражения

Ё= 0,5(Е [з2]+Ё[п9—у]2)- (621)

Поскольку фильтр не изменяет сигнал з, минимизация функции погреш-
ности Ё обеспечивается таким подбором его параметров, чтобы значение
Е [по — у]2 было минимальным. Таким образом, достижение минимума целевой

172 6. Специализированные стеукты нейеонных сетей

функции означает нанлучшую адаптацию значения у к помехе по. Минимально
возможное значение х равно Е [52], при котором у = по. В этом случае выходной

СИГНЗЛ 8 СООТВВТСТВУСТ ПОЛНОСТЬЮ ОЧИЩСННОМУ ОТ ШУМИ ПОЛСЗНОМУ СИГНШТУ 5.

Зашумлэнный входной сигнал

10

 

Время

 

2 4 6 8 10 12 14 16 18 20
Время

Рис. 6.10. Иллюстрация процесса устранения интерференционного шума д,

При использовании сети Вольтерри в качестве адаптивной системы следует
помнить, что сигнал а’ равен измеренному сигналу х = з + по, а в качестве
входного сигнала сети в данном случае используется установочный сигнал п.
Поэтому выходной сигнал у„ может быть определен выражением

ь 1. ь
Ул = 2пп4[ш1 + 2 пп—-_]|:шй + 2 "п-Йюдь  - (6-22)
:=0 ;=о ь=о
Если в рассуждениях ограничиться К = 3 и предположить эргодичность
сигналов’, то можно получить следующие уравнения адаптации весов
нейронного фильтра Вольтерри (ф, = 3„ + п0„):
дм’,

—д‚——=—д(п„‚‚(у‚. —‘1„)) , (6.23)

1 СИГНЯЛ СЧИТЗСТСЯ ЭРГОДИЧССКИМ, ССЛИ ПРИ РЗСЧСТС СГО ОЖИДЗСМОГО ЗНЗЧСНИЯ
УСРСДНСНИС ПО МНОГИМ реализациям МОЖНО ЗЗМСНИТЬ УСРСДНСНИСМ ПО ОДНОЙ РЁШШЗЗЦИИ
СТОХЭСТИЧССКОГО ПРОЦСССЗ.

5.2‘ беть Вальтера‘: р 173

   
 
   

ашГ __ А А 24
‘Е? ——д(п„4у: + "„—:›д)‚ (6- )
‘мдЁ \ А А А А А А
ф =—1‘( гуд + ‘мин "„—ь›у;+ "тип ‘ыдуы + пмуц) (615)

На базе привед нньгх зависимостей было выполнено моделирование
нейронного филь Вольтерри с К = 3 и Ь = 3 с помощью программы
` , которого получены удовлетворительньге результаты для таких
сигналов, как синусоидальньгй‚ прямоугольный, треугольньгй‚ а также для
суперпозиции синусоидальньгх сигналов. Применение описанного фильтра
позволило устранять шум даже тогда, когда полезный сигнал частично
присутствовал в установочном сигнале.

На рис. 6.10 иллюстрируется результат фильтрации сетью Вольтерри,
содержащей три скрытых нейрона, сигнала в, образованного суммированием
двух синусоидальных сигналов с сильно отличающимися частотами, на
который накладывалась помеха, имеющая‘ равномерное распределение.
В системе наблюдалось частичное проникновение полезного сигнала в
установочный сигнал.

ю
з
ё

ПРОГНОЗИРОВЗНИЕ ПЕРЕМЕННЫХ ВО ВРЕМЕНИ нестационарных
СИГНЗЛОВ

Блок-схема адаптивной системы для прогнозирования сигналов представлена на
рис. 6.11. Введение нелинейности в адаптивное устройство обогащает его
внутреннюю структуру и увеличивает способность к адаптации при решении
более сложных задач. При использовании обозначений сигналов, приведенных на
рис. 6.11, выходной сигнал фильтра Вольтерри описывается формулой

у" = Ё!1„_‚|:ш‚ + Ё 11„_][шд + Ёойтд (шт,  ‚ (626)

в которой 11„ = !1(п) обозначает задержанный сигнал х(п). Решение задачи
адаптации весов находится из дифференциальных уравнений (6.13) — (6.16),
причем конкретные компоненты градиента (при ограничении порядком К = 3) в
этом случае имеют вид:

дЕ ’
я = „—:(У„ _ арт) ‚ 
дЕ „ А
ж Чггыу: + Йп-ти ‚ (618)
ЭЕ

КГ“ = Йткэу + ’1„4Ё>и‹+ ЙНЙН’ ЙмЙк+ Ип-[Йсй + Йп-‘Ёк; - (619)
д: 

174 6. Сие: иализ ‚ ванные ст ‘от не‘ ных сетей

 

‘ ‘ ‘г-"чзг 5:1 

 
     
 

Щи)

Сеть 9
Вольтерри

  

‹

Рис. 6.11. Схема включения сети Вольтерри в качестве прогнозирующей системы П

в) 2 Начальная фазе обучения в процессе прогнозирования

 

0 0,1 0,2 0,3 0,4 0,5 0,6 0.7 0,8 0,9 1
Время

6) 1 Звевршающая фаза обучения а процессе прогнозирования

1,а
› о‚а
5 0,4
0,2
о
-0,2
_ —о,4
—о,в ‚
—о,а

-1
4,5 4.55 4,6 4,65 4,7 4,75 4,8 4,85 4,9 4,95 5

Время
Рис. 6.12. Иллюстрация адаптационных возможностей сеш Вольтерри, решающей

задачу прогнозирования псевдослучайной последовательности:
а) начальная фаза обучения; б) завершающая фаза обучения

бт2. Сеть Вольтерш _‚ ‚ 175

Как показали исследования, учет иелинейности фильтра значительно
повышает качество прогнозирования. Это хорошо заметно на примере псевдо-
лучайного сигнала, представляющего собой временной ряд, сформированный
днскретизацией белого шума. На рис. 6.12 представлен процесс адаптации
жстемы, предназначенной для прогнозирования этого сигнала. График на рис.
5.12а демонстрирует временное распределение дискретизированного шума:
фактическое (пунктирная линия) и спрогнозированное (сплошная линия) на
первой стадии адаптации (от 0 до 1-й секунды). Видны существенные отличия
между этими временными рядами. На рис. 6.12 6 показано фактическое и спрог-
нозированное адаптивной системой распределение шума по истечении 4,5 сек.
Заметно значительное улучшение результатов прогнозирования. Погрешности
наблюдаются на границах скачкообразньпс изменений значений сигнала и имеют
небольшую амплитуду. Сравнение полученных результатов с результатами
линейного прогнозирования свидетельствует о резком повышении качества
прогноза вследствие использования нелинейных элементов.

Раздел 7

РЕКУРРЕНТНЫЕ СЕТИ КА|5 АССОЦИАТИВНЬ|Е
ЗАПОМИНАЮЩИЕ УСТРОИСТВА

7.1. Введение

Отдельную группу нейронных сетей составляют сети с обратной связью между
различными слоями нейронов. Это так называемые рекуррентные сети. Их
общая черта состоит в передаче сигналов с вьпсодного либо скрытого слоя во
входной слой.

Главная особенность, выделяюшая эти сети среди других нейронных сетей, —
динамические зависимости на каждом этапе функционирования. Изменение
состояния одного нейрона отражается на всей сети вследствие обратной связи
типа “один ко многим”. В сети возникает некоторый переходный процесс,
который завершается формированием нового устойчивого состояния,
отличающегося в общем случае от предыдущего. Есшт, как и прежде, функцию
активации нейрона обозначить ](и), где и - это взвешенная сумма его
возбуждений, тр состояние нейрона можно определить вьпсодным сигналом
у; = [ (щ) = [(_Еи’д)9). Принимая во внимание, что при обратной связи типа
“один ко многимз’ роль возбуждающих импульсов для нейрона играют выходные
сигналы других нейронов, изменение его состояния может быть описано
системой дифференциальных нешанейных уравнений [46, 51]

_ и
Тгёёь: ъ; ЙЪ/(“Н-“г "д: (7.1)
1—‚л=’
для 1= 1, 2, ..., Н, где Ь; представляет собой пороговое значение, задан-
ное внешним источником (в однонаправленных сетях это показатель
поляризации). Коэффициент ц является численной константой, а его
интерпретация аналогична постоянной времени в уравнениях, описывающих
динамические состояния. Состояние нейрона рассчитывается в результате
решения дифференциального уравнения (7.1) как у; = /(и). При определенном
уровне возбуждения нейронов, описываемом значениями их выходньж

11. Введение ’ 177

 

ппналов уд, рекуррентной сети можно сопоставить энергетическую функцию
‚Тяпунова [46, 51, 54]

П д: 1 › Е‘ й
Е = “АХ 2 “дугу; + (У:)'1Уг+ ЁЁУ: . (71).
2 1 и“; ‘ад: о

1=1

Она связана с каждым возбужденным состоянием сети и имеет тен-
зенцию убывания с течением времени. Изменение состояния какого-либо
нейрона инициализирует изменение энергетического состояния всей сети в
направлении минимума ее энергии вплоть до его достижения. Обычно
существует множество локальных минимумов, каждый из которых пред-
ставляег одно из состояний системы, сформированных на этапе обучения
сети. В пространстве состояний локальные энергетические минимумы Е
представлены точками стабильности, называемыми аттракторами из-за
тяготения к ним ближайшего окружения.

В настоящем разделе будут рассмотрены только отдельные избранные
классы сетей, функционирующих в качестве ассоциативных запоминающих
устройств. Ассоциативная память играет роль системы, определяющей
взаимную зависимость векторов. В случае, когда на взаимозависимость
исследуются компоненты одного и того же вектора, говорят об ассоциагивной
памяти. Если же взаимозависимыми оказываются два различных вектора а и Ь,
можно говорить о памяти гетероассоциагивного типа. Типичным представителем
первого класса является сеть Хопфилда, а второго — сеть Хемминга и сеть типа
ВАМ (англ; Вёдёгесйопа! Азвосдате Метогу — двунаправленная ассоциативная
память).

Главная задача ассоциативной памяти сводится к запоминанию входных
(обучающих) выборок таким образом, чтобы при представлении новой выборки
система смогла сгенерировать ответ — какая из запомненных ранее выборок
наиболее близка к вновь поступившему образу. Наиболее часто в качестве меры
близости отдельных множеств применяется мера Хемминга. _

При использовании двоичных значений (О, 1) расстояние Хемминга между
двумя векторами у = [у1, уг, ...‚ у‚,]Т и 11 = [с11, (12, ...‚ с1‚‚]Т определяется в виде [46]

дн(у‚‹1)=Ё[‘1‚(1—у‚)+(1—‘1‚)у‚1 . (из)

При биполярных (Н) значениях элементов обоих векторов расстояние
Хемминга рассчитывается по формуле

4н‹у‚‘1)=% п- Ёут . (14)

!=3

Мера Хемминга равна нулю только тогда, когда у = 41. В противном случае оиа
равна количеству битов, на которое различаются оба вектора.

12-2162

178 7. Ртентные сети как асоошативные запоминающие устройства

7.2. Автоассоциативная сеть Хопфиттдё’

7:21. Основные зависимости

Одним из наиболее известных типов ассоциативной памяти является сеть
Хопфилда. Обобщенная структура этой сети представляется, как правило, в виде
системы с непосредственной обратной связью выхода со входом (рис. 7.1).
Характерная особенность такой системы состоит в том, что выходные сигналы
нейронов являются одновременно входными сигналами сети: хД/с) = уД/г- 1),
при этом возбуждающий вектор особо не выделяется. В классической системе
Хопфилда отсутствует связь нейрона с собственным выходом, что соответствует
щ; = О, а матрица весов является симметричной: И’ = “д.

Рис. 7.1. Обобщенная структура сети Хопфилда

т

Процесс обучения сети формирует зоны притяжения (аттракции) некоторых
точек равновесия, соответствующих обучающим данным. При использовании
ассоциативной памяти мы имеем дело с обучающим вектором х либо с
множеством этих векторов, которые в результате проводимого обученш
определяют расположение конкретных аттракторов (точек притяжения). В
последующих рассуждениях в соответствии с рекомендацией Хопфилда будем
предполагать, что каждый нейрон имеет функцию активации типа зёдпит со

`_2. Автоассоциативная сеть Хопфилда _‚ ,  з. ‚ 179

 

значениями 11. Это означает, что выходной сигнал г-то нейрона определяется
функцией

П
у‚=$‚‘;п 2ш.х.+1)‚ ‚ ‚ (7-5)

у 1
у=о
где Ы обозначает количество нейронов, 1\/` = п.

Для упрощения дальнейших рассуждений допустим, что постоянная
составляющая (поляризация), определяющая порог срабатывания отдельньпс
нейронов, является компонентом вектора х. Без учета единичных задержек сети,
представляющих собой способ синхронизации процесса передачи сигналов,
основные зависимости, определяющие сеть Хопфилда, можно представить в виде

у‚(*)=$з“ Ё: щудй-В ‚ т)

;=1,ь=;

с начальным условием у;(0) = 29. В процессе функционирования сети Хоп-
Филда можно выделить два режима: обучения и классификации. В режиме
Чучения на основе известных обучающих выборок х подбираются весовые
оэффициенты шд. В режиме классификации при зафиксированных зна-
гниях весов и вводе конкретного начального состояния нейронов у(0) = х
возникает переходный процесс, протекающий в соответствии с выраже-
нием (7.6) и завершающийся в одном из локальных минимумов, для которого
гЦг) =у(1‹— 1).
При вводе только одной обучающей выборки х процесс изменений
продолжается до тех пор, пока зависимость (7.6) не начнет соблюдаться для всех
- нейронов. Это условие автоматически выполняется в случае выбора значений
есов, соответствующих отношению

Ч’:- =——"‹Х— (7-7)

1 ^’ _‚

тоскольку только тогда Я 2х‚х‚х‚ = х, (вследствие биполярных значении
1=‘

элементов вектора х всегда х ‚ = (1 1)2 = 1). Следует отметить, что зависимость

`.7) представляет введенное ранее правило Хебба.
При вводе большего количества обучающих выборок х(1‹) для 1: = 1, 2, ..., р
веса шд подбираются соптасно обобщенному правилу Хебба, в соответствии с
вторым

‘д

1
шд. = 7]- Ёхуоху‘) . (7.8)

Благодаря такому режиму обучения веса принимают значения, определяемые
усреднением множества обучающих выборок.

20

180 2 Рзкди‘ „Ъшье сети как дссокиативные заполшнаюШе Штйстеа

В случае множества обучающих выборок становится актуальным фактор
стабильности ассоциативной памяти. Для стабильного функционирования сети
необходимо, чтобы реакция ё-го нейрона д") на 1-ю обучающую выборку х“)
совпадала с ее 1-й составляющей хда). Это означает, что с учетом выражения (7.8)

мы получаем

      «а
]=0

;=о 1‹=1

Если взвешенную сумму входных сигналов Е-го нейрона обозначить иЗд.
то можно выделить в ней ожидаемое значение хд“) и остаток, называемый

диафонией: г

ну) = 2:5’) + 2- Ё ;‚‹}"’‚‹;"’х;" - (7-10)
и ;=0 Ка‘!

Вследствие применения функции активации типа вгдпит выполнение условия
(7.9) возможно тогда, когда значение диафонии настолько мало, что оно не в
состоянии изменить знак хд“). Это означает, что несмотря на определенное
несовпадение битов (значение диафонии не равно нулю), переходный процесс
завершается на нужном агтракторе. Ассоциативная память демонстрирует
способности к коррекции. При представлении тестовой выборки, отличающейся
некоторым количеством битов на отдельных позициях вектора, нейронная сеть
может откорректировать эти биты и завершить процесс классификации в:
нужном апракюре.

Важным параметром ассоциативной памяти считается ее емкость. По:
этим термином следует понимать максимальное количество запомненньп
образов, которые классифицируются с допустимой потрешностью аш. В [5|:
показано, что при использовании для обучения правила Хебба и прг
выборе значения гтах = 1% (1% битов образца отличается от нормально:
состояния) максимальная емкость памяти (количество запомненных образцов
составит всего лишь около 13,8 % от количества нейронов, образующих
ассоциагивную память. Это свидетельствует о невысокой продуктивносп
хеббовского обучающего правила. Именно по этой причине оно применяется
редко. В качестве альтернативы используются методы обучения, основанные в
псевдоинверсии, которые характеризуются гораздо более высокой эффек-
тивностью обучения.

‚7.2.2. Режим обучения сети Хопфилда

Фаза обучения сети Хопфилда ориентирована на формирование таки‘

значений весов, при которых в режиме функционирования задание начальног:

состояния нейронов, близкого к одному из обучающих векторов х, пр:
соблюдении зависимости (7.6) приводит к стабильному состоянию, в которои
реакция нейронов у = х остается неизменной в любой момент времени.

1 2. Автоассоциативная сеть Хопфилда 181

 

Выше было показано, что применение правила Хебба для обучения
малозффекгивно, а в режиме функционирования при наличии шума (когда
начальные выборки отличаются от запомненныю значений) оно приводит к
многочисленным неточностям в виде локальных минимумов, далеких от
искомого решения.

Гораздо лучшие результаты можно получить, если для обучения исполь-
зуется псевдоинверсия. Отправной точкой этого метода считается пред-
положение, что при правильно подобранных весах каждая поданная на вход
выборка х генерирует на выходе саму себя, мгновенно приводя к искомому
состоянию (зависимость (7.6)). В матричной форме это можно представить в виде

шх=х, (111)

где И’ — матрица весов сети размерностью 1\/`›‹1\/`, а Х — прямоугольная матрица
размерностью А! х р, составленная из р последовательных обучающих векторов
Н“, т.е. Х = [х(1), хо), ..., хш]. Решение такой линейной системы уравнений имеет
вид [42]:

УУ = Х Х", (7. 12)
пхе знак + обозначает псевдоинверсию. Если обучающие векторы линейно
независимы, последнее выражение можно упростить и представить в форме [42,
100]:

и‘= х (хТ х у‘ х’. (из)

Псевдоинверсия матрицы размерностью Нхр в этом выражении заменена
обычной инверсией квадратной матрицы ХТХ размерностью рхр. Допол-
нительное достоинство выражения (7.13) — возможность записать его в
итерационной форме, не требующей расчета обратной матрицы. В этом случае
(713) принимает вид функциональной зависимости от последовательности
обучающих векторов хш для 1= 1, 2, ..., р :

(г) = (Н) 1 (н) ‹‘)_ (г)
ш ш +[х(1)]Тх(1)_[х(1)]7`\›у(1—1)х(1)х[ш х х ]х

 

х[ш“'1)х(0 __ х“) 17.. . 

при начальньпс условиях УУЮ) = 0. Такая форма предполагает однократное
предъявление всех р обучающих выборок, в результате чего матрица весов сети
принимает фиксированное значение И’ = УУЧ’). Зависимость (7.13) либо ее
кгерационная форма (7.14) называется методом проекций. Следует подчеркнуть,
что применение метода псевдоинверсии увеличивает максимальную емкость сети
Хопфилда, которая в этом случае становится равной 1\/`—- 1.

Модифицированный вариант метода проекций — так называемый метод
А-проекций — это традиентная форма алгоритма минимизации определенной
особым образом целевой функции. В соответствии с этим способом веса
подбираются рекуррентно с помощью циклической процедуры, многократно
повторяемой на всем множестве обучающих выборок:

131 7. Ре нтные сети как асоо `Ыг  “т”

ЧЧ (—- ЧЧ Ж 971%‘) ‚ «ХМ ЦхШЗ’ - | ‘ (11 5)

коэффициент ц — это константа обучения, выбираемая обычно из интервала

[0,7 — 0,9]. Его смысл тот же, что и в случае многрслойньщ сдччыЖ чакжьчжкч‘
«ачачжшъ хметхъъфа проекции метод А-проекции предполагает многократно-

предъявление всех р обучающих выборок вплоть до стабилизации значенъ-
весов. Процесс обучения завершается, когда изменения вектора весов становятс
меньше априорно принятого значения толерантности г.

Созданная в Институте электротехники и электроизмерений Варшавско:
политехнического университета компьютерная программа Н]ие1, реализуюшь
алгоритм, основанный на методах псевдоинверсии, продемонстрирова:
значительные преимущества над методом обучения по Хеббу. В режим
распознавания она правильно воспринимала значительно большие отклонени‘
начального вектора от соответствующего ему аттрактора (одного из векторов
использованных для обучения).

7.2.3. Режим распознавания сети Хопфилда

По завершении подбора весов сети их значения “замораживаются”, и сеть может ‚
использоваться в режиме распознавания. В этой фазе на вход сети подается ‘
тестовый вектор х и рассчитывается ее отклик в виде

УФ = $в“(\’*‘у(1 — 1)) (7-16‘

(в начальный момент у(0) = х), причем итерационный процесс повторяется для
последовательных значений у(2) вплоть до стабилизации отклика. итерационный
процесс стабилизации отклика системы состоит из определенного количества
циклов и в значительной степени зависит от размеров сети и от распределения
локальных минимумов.

В процессе распознавания образа по зашумленным сигналам, образующих
начальное состояние нейронов сети Хопфилда, возникают проблемы с опреде-
лением искомого конечного состояния, соответствующего одному из запом-
ненных образов. Неоднократно итерационный процесс будет сходиться не к
искомому, а к ошибочному решению. Этому есть много объяснений. Во-первых,
значение энергетической функции, заданной выражением (7.2)‚ зависит от
произведения состояний двух нейронов и симметрично относительно поля-
ризации. Одно и то же энергетическое состояние приписывается обеим поляри-

‘ зациям =Ьуд, 1:” при условии, что они одновременно изменяют свои значения на
противоположные. Поэтому для трехнейронной сети состояния (+1, —1, _+1) и
(—1, +1, —-1) характеризуются идентичной энергией, и оба состояния считаются
одинаково хорошим решением задачи. Переход из одного состояния в другое
возможен при простой одновременной замене поляризации всех нейронов.

Другая причина выработки сетью Хопфилда ошибочных решений
заключается в возможности перемешивания различных компонентов

7.2. Автоассоциативная сеть Хопфилда 183

запомненных образов и формирования стабильного состояния, воспринимаемого
как локальный минимум. Следовательно, смешанное состояние соответствует
такой линейной комбинации нечетного количества образов, которая
сопровождается стабильным состоянием сети. (рно характеризуется более
высоким энергетическим уровнем нейронов, чем искомое состояние.

При большом количестве образов образуются косвенные локальные
минимумы, не соответствующие ни одному из запомненных образов, но
определяемые сформированной структурой энергетической функции сети.
Процесс распознавания может сойтись к одному из таких локальных минимумов,
вследствие чего полученное решение не будет соответствовать состоянию ни
одного из нейронов, принимавших участие в процессе обучения.

 г%%ж%%
жжщжж

Рис. 7.2. Образы цифр, использованные для обучения сети Хопфилда ‚д

На рис. 7.2 и 7.3 демонстрируется эффективность функционирования
сети Хопфилда на примере образцов 10 цифр, представленных в пиксельной
форме размерностью 7 х 7. Поэтому количество нейронов сети Хопфилда
составляет 49, а количество обучающих выборок - 10. Обучение проводилось с
использованием программы Н[пе1 с применением трех описанных выше
методов: по Хеббу, методов проекций и В-проекций. На этапе обучения

ЁШШЁШ
ЁЁЁЁЁ
 Ё%ЁЁ%‹

ЁЁЁЁЁ

Рис. 7.3. Зашумленные образы цифр, использованные для тестирования сети Хопфилда

184 ——‚- „и 7. Ре ентные сети как ассоциативные запоминаю ие“ йапва

обрабатывались представленные на рис. 7.2 идеальные (незашумленные)
образцы, дающие безошибочное восстановление. Обученная сеть подверглась
тестированию на 20 сильно зашумленных образах, показанных на рис. 7.3.

Результаты распознавания сильно отличались в зависимости от приме-
няемого метода обучения. В случае обучения по Хеббу только один
образ был распознан безошибочно, а остальные не привели к искомому
решению, поскольку процесс распознавания завершался в точках локальных
минимумов, очень далеких от образов, использованных для обучения. Методы
проекций и А-проекций дали возможность почти безошибочно распознать
каждый из запомненных образов.

В завершение обсуждения сети Хопфилда следует упомянуть, что, помимо
упомянутой выше программной реализации, существуют также ее аппаратурные
реализации на основе стандартных элементов микроэлекгронной технологии.
Исходной точкой являются описание сети в виде дифференциального
уравнения (7.1) и его реализация в виде специализированной аналоговой цепи.
Мы не будем подробно останавливаться на сети Хопфилда этого типа, а
интересующимся ею можно порекомендовать такие публикации, как [46, 53, 54,
55, 113, 182].

7.3. Сеть Хемминга

предложенная Е Липпманном в работе [91] сеть Хемминга - это трехслойная
рекуррентная структура, которую можно считать развитием сети Хопфилда. Она
позиционируется как специализированное гетероассоциативное запоминающее
устройство. Основная идея функционирования этой сети состоит в минимизации
расстояния Хемминга между тестовым вектором, подаваемым на вход сети, и
векторами обучающих выборок, закодированными в структуре сети.

На рис. 7.4 представлена обобщенная схема сети Хеммиша. Первый ее
слой имеет однонаправленное распространение сигналов от входа к выходу и
фиксированные значения весов. Второй слой, МАХЫЕТ, состоит из нейронов,
связанных обратными связями по принципу “каждый с каждым”, при этом
в отличие от структуры Хопфилда существует ненулевая связь входа
нейрона со своим собственным выходом. Веса нейронов в слое МАХЫЕТ также
постоянны. Разные нейроны связаны отрицательной (подавляющей) обратной
связью с весом —г, при этом обычно величина в обратно пропорцио-
нальна количеству образов. С собственным выходом нейрон связан
положительной (возбуждающей) обратной связью с весом, равным +1. Веса
поляризации нейронов принимают значения, соответствующие нулю. Нейронн
этого слоя функционируют в режиме ЧУТА, при котором в каждой фикси-
рованной ситуации активизируется только один нейрон, а остальные пребы-
вают в состоянии покоя. Выходной однонаправленный слой формирует выходной
вектор, соответствующий входному вектору. Веса нейронов этого слоя
подбираются в зависимости от входных обучающих выборок.

13. Сеть Хемминга 18Ё

 

В процессе функционирования сети можно выделить три фазы. Впервой из
них на ее вход подается Н-элементный вектор х. После предъявления этого
вектора на выходах нейронов первого слоя генерируются сигналы, задающие
начальные состояния нейронов второго слоя, т.е. Ь/ЩХЫЕТЪ.

У1 У2 Ум

   
    
  
  

 
  

   

о - в

ЁЧёГЗЬУ

—@Й‹СЁЭ шт’
т“ Слой МАХМЕТ

   
 

    

’ Ё’ ч” ‘Ж

Рис.7.4. Структура сети Хемминга

Во второй фазе инициировавшие МАХЫЕТ сигналы удаляются, и из
сформированного ими начального состояния запускается итерационный процесс
внутри этого слоя. Итерационный процесс завершается в момент, когда все
нейроны, кроме одного (победителя с выходным сигналом, равным 1), перейдут
в нулевое состояние. нейрон-победитель с ненулевым выходным сигналом
становится представителем класса данных, к которому принадлежит входной
вектор.

В третьей фазе этот же нейрон посредством весов, связывающих его с
нейронами выходного слоя, формирует на выходе сети отклик в виде вектора у,
соответствующий возбуждающему вектору х.

Сеть Хемминга считается гетероассоциативным запоминающим устройством
с парой связанных между собой векторов (у, х), где х и у — это соответственно
входной и выходной биполярные векторы сети со значениями элементов 1:1.
Входные узлы сети 1, 2, ..., А! принимают значения, задаваемые аналогичными
компонентами вектора х. Нейроны первого слоя рассчитывают расстояние

186 7. Ретрентные сети как асооииативные запоминающие Етройства

Хемминга между фактически предъявленным ‚входным вектором х и
каждым из р закодированных векторов-образцов х“), образующих веса
нейронов первого слоя. Нейроны в слое МАХМЕТ выбирают вектор с
наименьшим расстоянием Хемминга, определяя таким образом класс, к
которому принадлежит предъявленный входной вектор х. Веса нейронов
выходного слоя формируют вектор, соответствующий предъявленнощ’
входному вектору. При р нейронах первого слоя емкость запоминающего
устройства Хемминга также равна р, поскольку каждый нейрон представляет

единственный класс.
Подбор весов сети Хемминга оказывается чрезвычайно простым. Веса
первого слоя соответствуют очередным векторам образов х“), поэтому

и’? =х;" (117)

для 1 = 1, 2, ...‚ р. Аналогично веса выходного слоя соответствуют очередным
векгорам образов уш, связанным с хш:

(718)

В случае нейронов слоя МАХЫЕТ, функционирующих в режиме Ш 1А, веса
сети должны усиливать собственный сигнал нейрона и ослаблять остальные. Для
достижения этого эффекта принимается

„до =1 , (119)

„р = уу’ .

а ТЗКЖС

1 (т)
——-—-<и›—— <0 7.
р_1 „ ф ( 20)
для Е э‘ 1. Для обеспечения абсолютной сходимости алгоритма веса
и?) должны отличаться друг от друга. В Липпманн в своей работе принял

м’ =——Ь+‹5 ‚ (121)

с!‘ у 

где ё — случайная величина с достаточно малой амплитудой.

Нейроны различных слоев сети Хемминга функционируют по-разному.
Нейроны первого слоя рассчитывают расстояния Хемминга между поданными на
вход сети вектором х и векторами весов ют = хш отдельных нейронов этого
слоя (1 = 1, 2, ...‚ р). Значения выходных сигналов этих нейронов определя-
ются по формуле [35]

(д)
9‚=1—“"( Ё, ‘х’ ‚ (122)

 

где дН(х(д, х) обозначает расстояние Хеммиша между входными векторами
х и х“), т.е. количество битов, на которое ‚различаются эгги два вектора. Значе-
ние 9, =1, если х = хт, и 3950, если х=—х(д. В остальных случаях значения Ё’;
располагаются в интервале [0‚ 1].

7.3. Сеть Хемминга т 187

 

Сигналы 9; нейронов первого слоя‘ становятся начальными состояниями
нейронов слоя МАХЫЕТ на второй фазе функционирования сети. Задача
нейронов этого слоя состоит в определении победителя, т.е. нейрона, уровень
возбуждения которого наиболее близок к 1. Такой нейрон указывает на вектор
образа с минимальным расстоянием Хемминта до входного вектора х. Процесс
определения пойгдителя — это рекуррентныгг (процесс; ввгггактгемвкё сагжгаго

формуле

ч

у‚‹‘‹›= 2ш;’"’у‚‹‘‹-1› = у‚‹’‹—1)+>:»«;"’у‚‹’‹—1› ‚ (т)
1 1:1
при начальном значении ;у(0) =}";. Функция активации Ду) нейронов слоя
МАХЫЕТ задается выражением

удляуг0

!(у)= . (124)
О для у <0

Итерационный процесс (7.23) завершается в момент, когда состояние

нейронов стабилизируется и активность продолжает проявлять только один
нейрон, тогда как остальные пребывают в нулевом состоянии. Активный нейрон
становится победителем и через веса и’? линейных нейронов выходного слоя

представляет вектор И’), который соответствует вектору х“), признанному слоем
МАХМЕТ в качестве ближайшего к входному вектору х.

Важным достоинством сети Хемминта считается небольшое количество
взвешенных связей между нейронами. Например, 100-входовая сеть Хопфилда,
кодирующая 10 различных векторных классов, должна содержать 10000
взвешенных связей с подбираемыми значениями весов. При построении
аналогичной сети Хемминта количество взвешенных связей уменьшается до
1100, из которых 1000 весов находятся в первом слое и 100 - в слое МАХЫЕТ.
Выходной слой в этом случае не учитывается, поскольку сеть Хемминта,
аналогичная сети Хопфилда, является ассоциативной.

В результате многочисленных экспериментов доказано, что рекуррентная сеть
Хемминта дает лучшие результаты, чем сеть Хопфилда, особенно в ситуациях,

штда взаимосвязанные векторы х н у являются случайными. В частности,’

реализованная в программе МагЫаЬ сетъ Хемминта, протестированная на 10
цифрах, изображенных на рис. 7.3, позволила почти безошибочно распознать все
представленные зашумленные образы. Достигнутая эффективность распоз-
навания зашумленных образов составила 100%. На рис. 7.5 и 7.6 изображены
искаженные образы цифр О - 9, поданные на вход натренированной сети Хеммин-
га, и соответствующие им образы, распознанные эггой сетью. Для цифр с рис. 7.5
только искаженным образам цифр 0, 3 и 6 были ошибочно приписаны другие
оригиналы. Однако такое решение не может считаться результатом неправиль-
ного функционирования сети, поскольку распознанные образы соответствовали

188 7. Ре ентные сети как ассоциативные запаминдю е ‘ства

 

эталонам с наименьшим расстоянием Хемминга дб  образЁЕ (после
повреждения эталонов шумом они стали подобны‚‚ остальным обучающим
выборкам).

 

Рис.7.5. Тестовые (сверху) и распознанные сетью Хемминга (снизу) образы цифр при
обработке первой группы искаженных входных данных

ЁШШЁШ
ЁЁЁЁЁ

ЁЁЁЁЁ
ЁЁЁЁЁ

Рис. 7.6. Тестовые (сверху) и распознанные сетью Хемминга (снизу) образы цифр при
обработке второй группы искаженных входных данных

Единственная проблема, связанная с сетью Хемминга, проявляется в случае.
когда зашумленные образы находятся на одинаковом (в смысле Хемминга)
расстоянии от двух или более эталонов. В этом случае выбор сетью Хемминга
одного из этих эталонов становится совершенно случайным.

‘ 4. Сеть типа ВАМ _ 189

 

7.4. Сеть типа ВАМ ‚

7.4.1. Описание процесса функционирования сети

Обобщением сети Хопфилда на случай двухслойной рекуррентной структуры,
позволяющей кодировать множества двух взаимосвязанных векторов,
питается двунаправленное ассоциативное запоминающее устройство,
называемое ВАМ (англ.: Вйсйгесгогта! Аввосйагёге Метогу), предложенное
Б. Коско в работе [78]. Его обобщенная структура представлена на рис. 7.7.
Сигналы распространяются в двух направлениях: от входа к выходу и
эбратно. Функционирование имеет синхронный характер. Это означает,
что если в первом цикле сигналы вначале проходят в одну сторону
ыя определения состояния нейронов-получателей, то в следующем цикле
они сами становятся источником, высылающим сигналы в обратную сто-
рону. Этот процесс повторяется до достижения состояния равновесия.

и/——-›

    

‹———— и,’
Рис. 1.1. Структура сети ВАМ

Функция активации нейронов имеет пороговый характер: она может быть
двоичной со значениями 1 или 0 либо биполярной со значениями :Ь1. При
нулевом сигнале возбуждения нейрона его текущее состояние остается равным
предыдущему состоянию. Для обеспечения лучших характеристик сети в режиме
распознавания на этапе обучения используются только биполярные сигналы.
Матрица весов Щ, связывающая обе части сети, является действительной и
несимметричной. С учетом симметрни связей входного и выходного слоев сети
при прямом направлении распространения сигналов веса описываются матрицей
УУ, а при противоположном направлении - матрицей “д. Предположим, что
входные обучающие данные определены в виде множества из т биполярных пар
{(а;, Ьд}, где и; = [ид, ад, ..., им], Ь; = [Ь„, Ьд, ..., Ьф] (векторы-строки). Этому
множеству сопоставляется множество биполярных пар {(х;, уд}, где х; — это
биполярное представление а; (0 —-› —1, 1 —-› 1), а у; - биполярное представление Ьд.

190 Н д щ 7. Редрдентные сети как ассшиативные запоминаюади: Шюйства

В соответствии с определением Б. Коско [78] матрица весов Ж’ формируется на
основе множества {(хд, у;)} как матрица корреляции

т
и‘ = Ду, ‚ (125)

‚=
Показано, что использование биполярных обучающих векторов дает лучшие
результаты на стадии распознавания. Определение весов межнейронных связей
позволяет проследить процесс стабилизации состояния на обоих концах сети.
Если допустить, что начальное состояние сети было задано парой (хо, уо), то
процесс двунаправленной обработки сигналов состоит из последовательных

ЦИКЛОВ
11%“): У1"’ /(У1“’Т) =х1 "9 1,951“) =У2 “9
 от —›/‹»‚"‹’›=›‹2 —›т‹›‹‚"’›=у‚ —+

алых’) =х‚ —› /‹х‚ч›=»‚ ‚

в результате чего формируются две стабильные величины х/ и уд свидетель-
ствующие о достижении стабильного состояния сети. В случае бинарното
описания начального состояния в виде (щ), Ьд) биполярным величинам (хд у!)
сопоставляются бинарные представления (ад Ьд. Каждой промежуточной точке
процесса (хд, уд) можно сопоставить энергетическую функцию Ед, определяемую
в виде [78]

Т

Е‚‚ =—’‹‚‚\’\‘у‚‚ . (7.26)
Доказано [78], что каждое очередное изменение состояния переходного
процесса ведет к уменьшению значения энергетической функции сети вплоть до
ДОСТИЖЕНИЯ локального МИНИМУМЗ. ЭТОТ МИНИМУМ ДОСТИГЗСТСЯ за КОНСЧНОС

КОЛИЧЕСТВО итераций, И ОН ИМВСТ ЗНЗЧСНИС

Е .

ШШ

=—х‚шу} . (127)

Иными словами, любое другое решение (в том числе и ближайшее,
отличающееся лишь на 1 в смысле меры Хемминга от (хд у‚’)) будет
характеризоваться большим значением энергетической функции. При выпол-
нении некоторых дополнительных условий парой (хд у!) становится одна из
обучающих пар, участвующих в формировании матрицы Ж’, которая наиболее
подобна (наиболее близка по мере Хемминга) паре, определившей начальное
состояние (хо, уо).

В качестве примера рассмотрим обучение по правилу Коско сети ВАМ,
имеющей 4 входа (векторы х состоят из 4 элементов) и 5 выходов (5-элемент-
ные векторы у). Задача сети состоит в запоминании множества из пяти
сопряженных векторов х и у, заданных в биполярной форме. Обучающие векторы

' 4. Сеть типа ВАМ 191

 

хруппированы в приведенные ниже матрицы Х и У. Каждая строка матрицы х
представляет собой один обучающий вектор, сопряженный с соответствующей
гтрокой матрицы У.

1
1
У: -1 -1 —1 1 1
1
1

Матрица весов сети, сформированная согласно формуле “’=х{у‚ +х;у2 +_
-х;у3 +хЁу4 +хёу5 , имеет вид:

3 1 -1 -3 -5

1 -1 -3 -5 -3

-1 —з —5 —з —1
—з —5 —з -1 1

И:

В режиме распознавания при начальных значениях векторов, совпадающих с
нспользованными при обучении, сеть распознает их безошибочно. Значения
энергии, соответствующие конечному состоянию, равны: Е, =— х1\’\’у1Т = — 40,
Е, = —х‚\’\’у2Т = —34, Е; = — хдУУудТ = —32, Ед = — хдшудт = —34 и Е5 = —- х5УУу5Т =
= — 40. При искажении значений векторов х и у, использовавшихся в процессе
распознавания, спроектированная по алгоритму Коско сеть ВАМ не всегда
способна откорректировать эти векторы, и распознает их с определенными
погрешностями. Оригинальное решение, предложенное Б. Коско, характе-
ризуется относительно невысоким качеством распознавания. Если размер-
ности векторов х и у обозначить соответственно п и р, то удовлетворительное

качество аспознавания можно получить при выполнении зависимости
т < ‘/т1п(п, р) .

7.4.2. Модифицированный алгоритм обучения сети ВАМ

В работе [161] показано, ‘по если сопоставленная 1-й обучающей паре энергия
Е; = — аДЙУЬЁ не составляет локальный минимум, то обучающая пара (ад, Ьд) не
может быть распознана сетью даже тогда, когда начальные значения также
равны (ад, Ьд).

Помимо того, ВАМ показывает неважные результаты, если в процессе
обучения используются не похожие друг на друга векторы (например, подобным

192 7. Редшрентные сети как ассоииативные запоминающие устройства

векгорам х сопоставляются не подобные друг другу векторы у, при этом степень
подобия векторов измеряется расстоянием Хемминга дн(а;, иу), т.е. исследуется
степень выполнения условия %‹1„(и‚‚и‚) =‹ йдн (1›‚‚1›‚) для всех значений 1 и 1‘).

В работе [163] предложена модификация правила Коско, обеспечивающая
распознавание вектора (щ, Ьд) независимо от того, образует он локальный мини-
мум или нет. Вместо выражения (7.25) предлагается использовать

ш=ёх{у‚+(‹1—1)х}у‚. (718)
‚=

Поправочный компонент (ц — 1)  равнозначен увеличению в (ц - 1) раз
участия пары (.’9,у]) в процессе обучения. Подбор значения с; важен для
достижения ассоциативным запоминающим устроиством хорошего качества
распознавания. Процедуру добавления поправок можно повторять для каждой
пары, не соответствующей условиям критерия минимизации энергетической
функции, с использованием зависимости

‘И’ = т“ + (д —1)х}у‚ , (129)

принимая в качестве “(Щ матрицу, полученную на предыдущем цикле обучения.
В энергетическом смысле предложенная И. Вангом поправка уменьшает
значение связанной с 1-й парой энергетической функции с Е;(а;, Ьд) = —а;УУЬ;Т до

ЕЁ‹‘1;‚1›‚)=—‹1;“1’?—‹‘1—1)д‚ХЁУ‹1’Ё,

соответствующего локальному минимуму. Предложенный Й. Вангом в работе
[161] метод подбора значения 9 основан на формуле

‚4 в
цгша 1, Ё%+1, ё9й+1 , (7.30)

ще 861 и Е: равны максимальным разностям энергии й-го оригинального
вектора и векторов, отстоящих от него на расстояние Хемминга, равное 1, во
множествахА и В соответственно, 86% = шах Е; — Е(‚‚), за = шах(Е‹Ё —Е‹Ё‚) . Как
показали исследования, обсуждаемая модификация также не обеспечивает 100%-
ной безошибочности функционирования сети на стадии распознавания. Полную
достоверность гарантирует только модификация матрицы весов, пред-ложенная в

работе [163].

7.4.3. Модифицированная структура сети ВАМ

Авторы работы [163] предложили заменить матрицу УУ расширенной матрицей
А
И} вида

и; = [ хущ] ‹7.з1›

Ч Сеть типа ВАМ  Щ ‚\ _‚‚‚„ ‚.‚д‚‚›—‚—>‹“‚ т 193

 

т ПСРВДЗЧС СИГНЗЛЗ В НЗПРЗВЛВНИИ О!‘ Х, И МЗТРИЦВЙ «И, ВИДЗ
я, =[\>\’Т\’У‚]‚ (т)

ф‘: передаче сигнала в направлении от у. Вводимая таким образом поправка
газрушает симметрию передачи сигналов в противоположных направлениях.
Дополнительные матрицы “С, и Ж’, конструируются так, что при нормальной
заботе алгоритма Коско их влияние нивелируется; они включаются в работу
голько при возникновении ошибок распознавания.

Пусть р‘ и п’ обозначают количество обучающих пар, для которых в про-
цссе распознавания получены неправильные ответы для векторов у и х
соответственно. Индексами у и х будем обозначать процессы, приводящие к
формированию ошибочных векторов у и х соответственно. Если (х), уд)
цляется очередной 1с-й обучающей парой, для которой [ (хдУУ) ту; , то прини-
пается Е), = 1, )7д= 0 для 1 а‘ 1: (1: = 1, 2, ..., р‘). Если для (х), уд) выполняется
условиеДхдУУ) = у;, ТО 5771? 9 дЛЯ 1г= 1, 2, ..., р’. Компоненты яд образуют вектор
7, длиной р’. Аналогичным образом для процессов, распространяющихся в
цютивоположном направлении, при замене векторов у на х можно получить
векторы Э; длиной п’. Корректирующие матрицы ЧУ, и ЧУУ формируются
согласно формулам [163]:

на; ууу= ЕД}, ‚ (733)

ш, = Ё у, ‚т, . (7.з4)

Ё=1

На следующем шаге создаются матрицы дополнительных узлов сети Т, и Тх,
причем

т‚= Ё‹1‚г}у‚‚ (т)
т‚‚= Ё‹;‚‚:‹}х‚. (7.зв)

Параметры 9„ и (1, подбираются таким образом, чтобы они соответствовали
условиям:

а, > "(т—2)-2“51п{?;_‹1„("‚‚а‚)}, (737)
‘1, > ”(т—2)—1т}‘1{Е„дн (1›‚‚1›‚)}. (7.3з)

Модифицированная структура сети ВАМ, в которой учитываются связи через
матрицы Т, и Т , представлена на рис. 7.8. Зачернеиные нейроны увеличивают
размерность сети, они коррекгируют неточности функционирования связей,

1 3-2162

 194 7. Ре ентные сети как ассо иативные запоминаю ие ст ойства

 

задаваемых матрицей “Ё После предъявления на вход` сети тестовой пары
(хо, уо) осуществляется аналогичный протекаюшему в сети Коско рекуррентный
процесс, приводящий к получению конечных значений (хд уд

(хшуо) "’ (х1‚у1)—>(’‹руд‚

Рис.7.8. Структура расширенной сети ВАМ

при этом описание отдельных его этапов должно содержать дополнительные
связи, показанные на рис. 7.8. При использовании введенных обозначенг’

ПОПУЧаЁМ
у1=!(хОш+8у(хОшу)ту) я
х1=.‚`(у1ш+гх(у1шх)тх)э

у/=!(х;—‚“+гу(х;—1“,)‚

Ё’ " д" ’ ‘ у1=[(х0“‚+8у(х0шу)ту) я т

где 3,0 и 3,0 обозначают векторы функций активации дополнительньг
корректируюших нейронов. В алгоритме Ванга эти функции подбирают

‘ Сеть типа ВАМ _ _ ’ ` 195

 

Исходное состояние

 

Состояние
после двух итераций

    

 

Конечное состояние

————‹

    

 

Рис. 7.9. Иллюстрация последовательности распознавания сегью ВАМ двух
СОПрЯЖСННЬКХ образов, ПРСДВЗРИТСЛЬНО ИСКЗЖСННЬКХ ШУМОМ

13’

196 1 Режвентные сети как ассоииативные запоминающие устройства

следующим образом:

8_у(У) = [8у(У1)’8у(у2)""9гу(ург)]‚
84») = [гАн )‚в‚(\’1)‚———‚е‚ (УШ ‚
ГДЁ ЭПСМЁНТБЁ векТоров г; и в’, ОпреДеЛЯЮТсЯ вЫражеНиЯМи:

1 длямрп-г,
8у(УЁ)= ,

О длядругих

1 для \›‚>р—г
Ехщ): 2 ’

0 для других

ВСЛИЧИНЫ 81 И 31 ИМВЮТ ПОЛОЖИТСЛЬНЫС ЗНЯЧСНИЯ, УДОВПЕТВОРЯЮЩИС УСЛОВИЯ)!

9 << 8 1 << 2111111 {дн (ад, 01)} , (739

та;
0 << г2<< {‹1„(ь‚, Ьд}. (7.40)

В работе [163] доказано, что при подобной модификации сеть ВАМ всегда
обеспечивает хорошее распознавание запомненных сигналов независимо от того.
образуют они локальные минимумы или нет

На рис. 7.9 показаны последовательные циклы функцибййрования моди-
фицированной сети ВАМ на примере распознавания зашумленноп
схематического образа корабля и связанной с ним надписи зИф. Обучаюши:
данные, составляющие векторы а и Ь, формировались на базе пиксельных кар:
представляющих упрощенный образ корабля (вектор а) и надпись $Н1ё
(вектор Ь). Размерность вектора а равнялась 288, а вектора Ь - 280. Процес;
распознавания исходного идеального образа оказывается совсем не простым, г
обычная структура ВАМ выполнить его не в состоянии. Модификация Ванп
позволяет получить правильное решение, однако и в этом случае важную роль
играет грамотный подбор коэффициентов 81 и 83. Слишком малые или слишком
большие значения этих коэффициентов приводят к тому же эффекту, вызывая
снижение фильтрационных способностей сети и невозможность полученш
образа, очищенного от шума.

На рис. 7.10 приведен тестовый набор из пяти различных образов (вертолет
танк, самолет, корабль и лицо), связанных с соответствующими надписями н;
английском языке. Векторы х; описывают образы, а векторы у; — надписи
Размерности всех векторов х; равны 288, а векторов у; - 280. На рис. 7.11
представлены последовательные этапы распознавания этих образов посл:
предъявления их сети в искаженном виде (шум повреждал также и надписи
После двухкратного прохождения сигналов через модифицированную сеть ВА_\’
произошло безошибочное распознавание как образов, соответствующи-
изображениям (векторов х), так и связанных с ними надписей (векторов у).

' 1 Сеть типа ВАМ 197

 

тнкционирование системы огромное влияние оказывает подбор параметров
’ ‘полнительной части сети, который в значительной степени зависит от степени
жажения образов. Это считается определенным неудобством метода,

  
    
 
     

    
   

   
  

  
 

 

Рис. 7.10. Набор данных для тестирования сети ВАМ с расширенной структурой

поскольку параметры дополнительной части сети, подобранные оптимальным
образом для одного уровня шума, необязательно будут эффективны при
изменении этого уровня. Для набора образов, исследовавшихся в описываемом

йства

щытмёыаюоэ: язычок»
ЫЁЁЁМИО: ЕЗтЁоы Ё: щоёцюо „Ё коем шоЁцБ щошшмшоцёёеёыо: о Е<ш оЗБо Ёыыымшмопомц „Боотдпонмшоцыпоош ‚ПЫ ‚Ёщ

„

„

‚‚

п _
„‚

КШКЫЕ сети как ДССОЧЦДМЦЗНЫЕ ЗЛИОМИНСЮПДЮ УСт

   

„„
я 
„ЕЕ: Ёцшё 38: . „бцЁы
=Е8 Ё „ёёфйаыьоц: =Е8 Ё ш==ъЁ=ёоц= =Е8 Ё ыьгшёьыъец: =Е8 Ё ыЁЁашьоцс зозё: Жоы о ЗЁЁЕФ оЁочшЕм
_ „Зшз „ЭК. 333 „Её ммшз. ьёёо . шмшз омоёо дЁиоЕооь шоёоё: зЁьо
Ёё: шьЁоЕооо эссе: ФЁЁбЁООО ЕВЁ Зёоеьоо Ёоо: шахпоЕооо

Ж у „
1 к .

7.4. Сеть типа ВАМ 199

 

численном эксперименте, обученная при 20%-ном шуме (20% пикселов
находилось в искаженных состояниях) сеть также обеспечивала безошибочное
распознавание образов, искажение которых достигало 50%. и ‘ Ё

Интересным представляется сравнение емкости сети ВАМ при использованит?
различных алгоритмов обучения. Оригинальная "процедура Коско харак-
теризуется относительно невысоким качеством распознавания. Если размерности
векторов х и у обозначить п и р соответственно, то распознавание будет считаться
удовлетво-рительным при емкости т < ‚/гп1п(п, р) . При использовании
модифицированной Вангом структуры сети какие—либо условия_и ограничения
распознаваемости входных векторов отсутствуют. Однако это достигается за счет
увеличения размерности сети и количества межнейронных соединений. При
т>> ‚[ш1п(п, р) дополнительные связи, вводимые применяемым алгоритмом,

становятся доминируюшими и оказывают решающее влияние на функциони-
рование сети. '

Раздел 8
РЕКУРРЕНТНЫЕ СЕТИ НА БАЗЕ ПЕЁЁЕПТРОНА

8.1. Введение

Рекуррентные сети, рассматриваемые в настоящем разделе, представляют
собой развитие однонаправленных сетей персептронного типа за счет добав-
ления в них соответствующих обратных связей. Обратная связь может исходить
либо из выходного, либо из скрытого слоя нейронов. В каждом контуре такой
связи присутствует элемент единичной задержки, благодаря которому поток
сигналов может считаться однонаправленным (выходной сигнал предь1-
дущего временного цикла рассматривается как априори заданный, который
просто увеличивает размерность входного вектора х сети). Представленная
подобным образом рекуррентная сеть с учетом способа формирования
выходного сигнала функционирует как однонаправленная персептронная сеть.
Тем не менее алгоритм обучения такой сети, адаптирующий значения
синаптических весов, является более сложным вследствие зависимости сигналов
в момент времени г от их значений в предыдущие моменты и соответственно
ввиду более громоздкой формулы для расчета вектора традиента.

При обсуждении рекуррентных сетей, в которых в качестве выходного
элемента используется многослойный персептрон, мы обсудим наиболее
известные структуры сетей и разработанные для них алгоритмы обучения. В этом
разделе мы ограничимся сетями КМЬР, КТКЫ Вильямса-Зипсера и сетью
Эльмана. Будут рассмотрены примеры реализации таких сетей и результаты
численного моделирования при решении конкретных тестовых задач.

8.2. Персептронная сеть с обратной связью

8.2.1. Структура сети ВМ|.Р

Один из простейших способов построения рекуррентной сети на базе однонап-
равленной ИНС состоит во введении в персептронную сеть обратной связи.

В дальнейшем мы будем сокращенно называть такую сеть КМЬР (англ.:
Кесиггет МитЬауег Ретсергтоп - рекуррентный многослойный персептрон). Ее
обобщенная структура представлена на рис. 8.1.

Рис. 8.1. Структура сети КМЬР

Это динамическая сеть, характеризующаяся запаздыванием входных й
выходных сигналов, объединяемь1х во входной вектор сети. Рассуждения
будут касаться только одного входного узла х(/‹) и одного выходного нейрона, а
также одного скрытого слоя. Такая система реализует огображение:

у(1с+1)= /(х(1с), х(/с—-1), ..., х(1с—-(1\/-1))‚ у(/‹—1), у(1‹—2), ..., у(1‹—Р) , (8.1)

где 1\/-1 — количество задержек входного сигнала, а Р - количество задержек
выходного сигнала. Обозначим К количество нейронов в скрытом слое. В этом
случае сеть КМЬР можно характеризовать тройкой чисел (Н, Р, К). Подаваемь1й
на вход сети вектор х имеет вид: х(1с) = [1, х(1с), х(1‹-1), ..., х(/‹—(1\/—1)),
у(1с-Р), у(1с-Р+1), ..., у(1‹—1)]Т. Допустим, что все нейроны имеют сигмои-
дальную функцию активации. Обозначим и; взвешенную сумму сигналов й-го
нейрона скрытого слоя, а 3 — взвешенную сумму сигналов выходного нейрона.
При введенных обозначениях выходные сигналы конкретных нейронов
описываются зависимостями:
!‘/+Р

и, = Е) шёпх] ‚ (8.2)

У: =!(иг) ‚ (83)

202 8. Решегентные сети на базе пеесептеона

г = ЁшР/(ид ‚ о.“

Ё=О

‹ у =;(;) . (вы

8.2.2. Алгоритм обучения сети КМЬР

Сеть КМЬР адаптируется с применением градиентного алгоритма обучения. Каъ
и в ситуации с однонаправленной сетью, рассчитывается градиент целевой

функции относительно каждого веса. Для упрощения будем рассматривать сеть к
одним выходным нейроном. В этом случае целевую функцшо в момент 1 мож-
но определить в виде

Е‹’‹›=%гу‹’‹›-‹‘‹‘‹›1’ . «вы

„ш
Дифференцируя згу функцию относительно произвольного веса и (а = 0,
1, ...,К) выходного слоя сети, получаем:

31500 дуб‘)

4/(300) 4300

М? ‚[у(1‹)—‹1(1‹)1ашь2‚=[у(1‹)—‹1(1‹)1 да“) (М? . (8.7)
С учетом зависимостей (8.2) - (8.5) получаем

это _ аж ‹‘‹» ‘‹ ‹‘‹ш$*’»‚‹‘‹»

„з, —[у‹‘‹)-‹‘‹‘‹›1 ай,“  ‘М? ‚ (за)

404”)

ом»?
тальных случаях. С учетом этого факта

где щ=/(и;). Производная равна 1 только при 1= а и равна 0 во всех ос-

два а к к ‹1‚‹1‹)
ашш) ‚ [у(‘‹) — ‹1(1‹)] [»„ (к) + „р душ ] ‚ (8.9)

причем

‹‘\›‚‹‘‹› = ‹1/‹и‚‹’‹»НЁР„9› Фе =
а»? ‘1и‚(/‹) у=о у от?

= д/(ЩПФ) ‘М’ „до ду(’‹—Р—1+(1—”)) =

с1и‚(1‹) гён у от?
_ 4701110) ” (1) д)“ — Р—1 +1)
—————аи‘(,с) ёшддд ‘М? . (810)

С учетом зависимостей (8.6) - (8.10) получаем

’ 1 Пеесептронная сеть с обратной стыд 203

‹1(’‹)_‹У( (М)  611410)’ ‘11(’‹—Р—1 ')
ай?) — [1/д(/‹)+Ё”:2)—д\ 1/7:,9+П ] . 

г=о дну‘) ;=1
Бркуррентная формула (8.11) позволяет рассчитать значение производной
$'(

‚цъг,

В ПРОИЗВОПЬНЬЕЙ момент времени ПО ее значениям В предыдущие моменты.

@3 связывает значения ПРОИЗВОДНЫХ В момент 1 СО значениями тех же ФУНК-

дий в моменты г —- 1, 1 - 2, ...‚ 1 —- Р. Можно предположить, что начальные
яначения производных от сигналов перед началом обучения равны, т.е.

‹1у(О) = ‹1у(—1) =  = ‘М-Р) = 0_ ‚

При использовании в процессе обучения метода наискорейшего спуска
цаптация весов выходного слоя определяется формулой

Ашё?’ =—п[»(1‹)—‹1(1‹)1:уЁЁЗ . (8.12)
и,“

Актуализация весов скрытого слоя происходит аналогичным образом. После
гасчета производной сигнала у(1с) относительно веса шЕЪд скрытого слоя полу-

чаем (б ш здесь означает дельту Кронекера)

ил‘) = ‹1/‹›‚›‹‘‹» «М ‹1/‹и‚‹‘‹»[Ё ‹‚‚ ‹‘у‹‘‹—Р-1+1›

Ё “духи

‚ +д‚ х 8.13
дм)’; 43(1с):=1 м?’ 1=1 вид? “ 4‘ )

Следовательно, формула, определяющая адаптацию веса тщдд скрытого

СГЮЯ, ПРИ ИСПОЛЬЗОВЗНИИ метода наискорейшего СПУСКЗ принимает ВИД

МЁ’ =—д[»‹‘‹)—‹1‹‘‹›1“””" ‚ (814)

В окончательном виде алгоритм обучения сети КМЪР можно сформулировать

следующим образом.

|. Выполнить инициатшзацию случайным способом весов нейронов скрытого и
выходного слоев.

2. Для каждого момента 1 при заданном возбуждении в виде вектора х рассчи-
тать состояние всех нейронов сети в соответствии с формулами (8.2) - (8.5).

3. С помощью зависимостей (8.11) и (8.13) определить значения производных
‹1у(1‹) ‹1у‹’‹)
И
ещё” фиг‘;
начально выбранной структурой.
4. Акгуализировагь веса в соответствии с формулами (8.12) и (8.14)‚ после чего
вернуться к п.2 настоящего алгоритма.
Представленный алгоритм функционирует в режиме “онлайн”, принимая
поступающие входные данные и соответствующие им значения ожидаемого

вектора д и оперативно коррекгнруя значения весов.

ДЛЯ всех значений а И В, СООТВСТСТВУЮЩИХ весам сети С ИЗ-

204 8. Рекшшшные сети на базе пежптшна

8.2.3. Подбор коэффициента обучения

При обучении нейронной сети по методу обратного распространения
ошибок решающее влияние на скорость обучения и на получаемые
конечные результаты оказывает коэффициент обучения п. Значение этого
коэффициента в процессе обучения может оставаться постоянным либо
подбираться адаптивным способом. Сохранение постоянного значения
коэффициента обучения считается самой простой формой определения 1].
Такой способ имеет много недостатков, в том числе медленную сходимость.
высокую вероятность расходимости процесса при слишком большом
значении п, легкость попадания в точки локальных минимумов. Тем
не менее до настоящего времени он остается наиболее простым
и эффективным методом, используемым при обучении в режиме
“онлайн”. Адаптивный подбор коэффициента п позволяет контролировать
погрешности обучения, в результате чего проводится увеличение или
уменьшение его значения. Для ускорения процесса обучения предус‹
матривается непрерывное возрастание коэффициента п, если уровень
фактической погрешности по сравнению с погрешностью предыдущей
итерации находится в допустимых пределах. Если обозначить вы и г
погрешности адаптации на Е-м и (й -1)-м шаге, а пы и 11; — соответст-
вующие им коэффициенты обучения, то в случае г; > /с„г;_1 (/с„ — коэффициеш
допустимого прироста погрешности) производится уменьшение значения
11 по формуле

Пан = там (315)

где щ является коэффициентом уменьшения значения п. В противном случае,
когда г; 5 ыгы, значение этого коэффициента увеличивается по формуле

Пш = Пгаь (3151

где а; ЯВЛЯСТСЯ КОЭффИЦИСНТОМ УВСЛИЧСНИЯ ЗНВЧСНИЯ П.

8.2.4. Коэффициент усиления сигнала

Применение выходных нейронов с сигмоидальной функцией акти-
вации дает возможность минимизировать структуру рекуррентной ней-
ронной сети. В сети КМЬР стандартной структуры, описываемой
в большинстве литературных источников, как правило, используются
выходные нейроны с линейной функцией активации, что облегчает
приведение сигнала к любому числовому диапазону. Опубликованные в
последнее время работы наводят на мысль о возможности их замены
сигмоидальными нейронами, позволяющими значительно сократить раз-

12. Певсептеонная сеть с обратной связью 205

мерность сети. Так, для сети, предложенной Нарендрой и содержащей
линейные выходные нейроны, необходимо большое количество скрытых
нейронов, например К = 10. Тот же эффект может быть достигнут в сети с
сигмоидальным выходным нейроном и всего двумя скрытыми нейронами.
Однако следует учитывать, что значения сигнала сигмоидального нейрона
ограничены интервалом от -1 до +1. Чтобы обеспечить любой требуемый
диапазон значений, на выходе сети добавляется линейный блок, уоиливающий
сигнал в М раз (О < М < т). При грамотном подборе коэффициента усиления
М подобная сеть демонстрирует такие же хорошие возможности адаптации
при значительно меньшем количестве скрытых нейронов.

8.2.5. Результаты компьютерного моделирования

Сеть КМЬР повсеместно применяется для моделирования динамических
процессов в режиме “онлайн”. Типичным примером ее приложения может
служить имитация нелинейных динамических объектов, для которых
сеть КМЬР выступает в роли модели, а алгоритм уточнения весов - в роли
процедуры идентификации параметров этой модели. Идентифипированная
модель объекта может в последующем использоваться для управления
данным объектом. Именно по этой причине сети КМЬР наиболее попу-
лярны для имитации систем управления машинами, устройствами и
динамическими процессами [156]. В настоящем разделе мы обсудим
подход к моделированию нелинейных динамических систем, предложенный в
работах К. Нарендры [107]. В отличие от работ Нарендры будем использовать
сеть с нелинейным выходным нейроном, описываемым сигмоидальной
функцией активации. На первый взгляд нелинейность выходного нейрона
осложняет проблему идентификации нелинейного объекта (из-за ограниченности
выходного сигнала диапазоном (-1,1), меньшей динамики изменения сигнала,
более сложного процесса обучения и т.п.). В действительности она имеет другие
достоинства, которые отсутствуют у сети с линейным вьпюдным нейроном:
количество скрытых нейронов может быть существенно уменьшено, например, с
К = 20 в работах Нарендры до К = 2 при обсуждаемом подходе; намного
сокращается длительность обучения; в начальных фазах обучения и тестирования
возникает меньше ошибок, связанных с нулевыми начальными значениями.
Ограниченность выходного сигнала легко преодо-левается включением в
структуру сети усилителя, масштабирующего значения, изначально
нормализованные в интервале (-1, 1).

Сеть обучапась с использованием программы КМЬР, приспособленной для
обучения в режиме “онлайн”. Обучение было основано на адаптивной
идентификации нелинейных динамических объектов. Объект, описываемый
известной нелинейной функцией, генерировал последовательность заданных
сигналов а! (п) в качестве реакции на возбуждение в виде векторов х, форми-
руемых случайным образом. Сеть КМЬР со структурой, изображенной

206 8. Репдштные сети на базе пе а

на рис. 8.1, испожшзовалась в качестве модели этого объекта. В результате
сравнения выходного сигнала этой модели у(п) с заданным сигналом е! (п
рассчитывалось значение погрешности в (п):

г (п) = у(п) — ‹1(п), (8171

управляющей процессом уточнения параметров нейронной сети. На рис. 8.1
показан способ включения сети при проведении экспериментов. Символом М
обозначен постоянный коэффициент усиления модуля, масштабирующего
выходной сигнал сети таким образом, чтобы его динамический уровень лежал в
том же диапазоне, что и уровень заданного сигнала а7(п).

х“) _ Динамический
объект

 

Рис. 8.2. Схема включения сети КМЬР при решении задачи идентификацгш

Во всех численных экспериментах использовалась сеть со структурой 2-2-1.
Вход системы состоял из одного входного узла х(п) и одного контекстного узла,
вырабагывавшего копию задержанного на один такт выходного сигиала. Скрытый
слой состоял всего из двух нейронов, а выходной слой - из одного нейрона. При
реализации процесса обучения выполнялся описанный выше адаптивный подбор
коэффициента обучения п. Уточнение весов проводилось в двух режимах.

В первом режиме предъявление каждой новой обучающей выборки
сопровождалось однократным уточнением значений всех весов сети и переходом
к следующей выборке. Этот режим будем называть в дальнейшем однократной
адаптацией.

Во втором режиме каждая обучающая выборка вызывала многократное
уточнение весов сети (предъявление обучающей выборки на вход сети
сопровождалось изменением выходного сигнала, после этого уточнялись
значения весов; повторная подача на вход сети сигнала обратного распрост-
ранения ошибок при неизменной обучающей выборке приводила к очередному
изменению выходного сигнала с соответствующим уточнением весов и т.д.). Этот
режим обучения сети будем называть многократной адаптацией. Каждый
процесс обучения сети начинался со случайных значений весов, равномерно
распределенных в заданном интервале. В проводимых экспериментах это был
интервал (-0,1, 0,1).

8.2. ПЁсептЕонная сеть с обратной связью 207

Первый численный эксперимент был связан ‹“с динамической системой,
предложенной в работе [107] и описываемой выражением

удд = 0,3 уд + 0,6 у,‚_‹ + 0,6 $1п(т4,‚ ) + 0,3 з1п(31ш‚‚ ) + 0,1 з1п(51ш д ) . (818)

ш)

250
На рис. 8.3 представлена форма заданных сигналов, генерируемых динами-

ческой системой, определенной выражением (818). Из этого уравнения следует,
что выходной сигнал системы будет ограничен при условии, что на входной
сигнал также наложены ограничения. В экспериментах применялись обе мето-
дики уточнения весов ‹— как однократной, так и многократной адаптации [156].

дискретный входной сигнал задавался функцией ид=з1п(

Заданные значения выходных сигналов объекта

   
 

Заданный сигнал объекта

_6 2 2 : 2 1 1 1 1 2
0 100 200 300 400 500 600 700 800 900 1000
Выборка

Рис. 8.3. Заданные сигналы динамического объекта, определенного выражением (8.18).

При использовании первой методики значения весов уточнялись после предъ-
явления каждой обучающей выборки по алгоритму наискорейшего спуска с
постоянньпи коэффициентом обучения 11 = 0,085 (адаптивный подбор коэффи-
циента обучения при однократной адаптации не имеет смысла). Результаты
процесса обучения в виде изменений погрешности г(п) = у(п) - ‹1(п) пред-
ставлены на рис. 8.4. Они свидетельствуют, что погрешность обучения (уже после
20 циклов) быстро уменьшилась до несущественной величины, которая
воспринималась только благодаря высокой точности идентификации системы.

Согласно второй методике значения весов уточнялись трижды на протяжении
каждого цикла с применением адаптивного коэффициента обучения п и значений
коэффициентов [(4 = 0,7 и /с,„ = 1,03. График погрешности обучения для этого
случая представлен на рис. 8.5. '

На графике видно, что погрешность, особенно в первой фазе обучения,
оказалась меньше, а процесс адаптации модели к реакциям объекта протекал
быстрее, особенно в начале обучения. Следует подчеркнуть, что и в первом,

208 8. Рёдгттпые сети на базе шамана

Й ВО ВТОрОМ СЛУЧЗС ОСТЗТОЧНЗЯ ПОГРЁШНОСТЪ ОбУЧСНИЯ СТЗбИЛИЗИРОВЗЛЗСЬ на

ОПРСДВЛСННОМ, ДОСТЗТОЧНО НИЗКОМ УРОВНЕ, ЯВЛЯЯСЬ движущей СИЛОй МСХЗНИЗМЗ
адаптации параметров МОДСЛИ.

‚‚‚
; Е!‘

ПОЗРЭШНОЩПЬ ПРОЦЭССЕ ОБУЧЕНИЯ

9
св

9
о:

99
ю-д

Погрешность
з’ Ь Ъ
Ф -\ М О

  
  

т:

0 100 200 300 400 500 600 700 800 900 1000
Выборка

Рис. 8.4. График обучения сеги КМЬР при однократной адаптации весов
в каждом цикле для динамического объекта из первого эксперимента

ПОЗРОШНОСЩЬ ПРОЦЭССЕ ОЁУЧЭНПЯ

О
07

9
о

9
а;

9
м

|
99
мм

Погрешность
|
О

|
9
О:

ё

—1 1 С С З 1 С 2
0 100 200 300 400 500 600 700 800 900 1000
Выборка

Рис. 8.5. График обучения сети КМЬР при трехкратной адаптации весов в каждом цикле
для динамического объекта из первого эксперимента

Во втором эксперименте исследовалась нелинейная динамическая система,
опись1ваемая следующей зависимостью:

уйуд-А (Ух + 25) +и
1*’ У: + Угч

Уьн — ь (3-19)

42. Пеесептеонная сеть с обратной связью 209

21т1с

со входным сигналом щ‚= зйп {ЕЕ} Это динамический объект с нелинейностью

пмерительного характера, неудобный для численного моделирования.
На рис. 8.6 приведен трафик изменения выходного сигнала объекта (заданных
пачений), описываемого выражением (8.19). Результаты обучения в виде

Заданные значения выходных сигналов объектов

5

заданный сигнал объекта
М

  
   

0 100 200 300 400 500 600 700 800 900 1000
Выборка

Рис. 8.6. Заданньхе сигналы динамического объекта, определенного выражением (8.19).

графика погрешности при однократной адаптации весов представлены на рис. 8.7.
Погрешность обучения, принимавшая в начале процесса значения 4 - 5-г0
порядка, очень быстро (примерно за пять циклов) сократилась до остаточной
величины, уменьшающейся в ходе обучения.

График погрешности обучения, соответствующий трехкратной адаптации ве-
сов, изображен на рис. 8.8. Погрешность обучения при трехкратной адаптации

Погрешностьпроцесса обучения

   

Ь
о

0 100 200 300 400 500 600 700 800 900 1000
Выборка

Рис. 8.7. График обучения сети КМЬР при однократной адаптации весов в каждом цикле
для динамического объекта из второго эксперимента

‘ 4-2162

 
  
 
  
  

210  . . . 8. Р ‘гнтные сети на базе т

Погрешностьпроцесса обучения

|
9
м

Погрешность
Ь
д

Ь

ЁЬ

0 100 200 300 400 500 600 700 800 900 1000

Ё Выборка

Рис. 8.8. График обучения сети КМЬР при трехкратной адаптации весов
в каждом цикле для динамического объекта из второго эксперимента

намного меньше, чем при однократной, а процесс обучения оказывается
601166 КОрОТКИМ И ПРИВОДИТ К СОКрЗЩСНИЮ ВСЛИЧИНЫ погрешности ДО УРОВ»
ня 1о—1 —1о—3.

‘ 8.3. Рекуррентная сеть Эльмана

8.3.1. Структура сети

Рекуррентная сеть Эльмана характеризуется частичной рекуррентностью в
форме обратной связи между скрытым и входным слоем [46, 114], реали-
зуемой с помощью единичных элементов запаздывания 24. Обобщенная
структура этой сети представлена на рис. 8.9. Каждый скрытый нейрон
имеет свой аналог в контекстном слое, образующем совместно с внешними
входами сети входной слой. Выходной слой состоит из нейронов.
однонаправленно связанных только с нейронами скрытого слоя, подобно сета
МЬР. Обозначим внутренний вектор возбуждения сети х (в его состав
входит также единичный сигнал поляризации), состояния скрытых нейронов -
\’ е К“, а выходные сигналы сети — у е КМ. При таких обозначениях входной
вектор сети в момент г‘ имеет форму

100 =[хо(’‹)‚х1(’‹)‚---›хм(’‹)‚"1(’‹ —1)‚";›(’‹ —1)‚---‚\’;‹(/‹ — 1)] . (820)

Веса синаптических связей первого (скрытого) слоя сети обозначим шь”, а

2 . .‚
ВТО ОГО ВЬГХОДНОГО СЛОЯ —И"- ) . ЕСЛИ ВЗВСШСНН Ю С 1—ГО НСИ она С ЫТОГС
И

 

8.3. Р т-ентная сеть Эльмана _ 211

 

Рис. 8.9. Структура сети Эльмана

слоя обозначить щ, а его выходной сигнал - щ, то

Л+К

и‚‹‘‹›= 20 ш$’х‚‹‘‹)‚ (821)
,=

‘а (К) = А (щ (1‹)) . (8.22)
(Ш

Веса "г образуют матрицу “д” синаптических связей скрытого слоя, а
_Д(и;) — функция активации Е-го нейрона этого слоя. Аналогично можно
обозначить взвешенную сумму Е-го нейрона выходного слоя д, а соответст-
вующий ему выходной сигнал сети — уд. Эти сигналы описываются фор-
мулами

_ К (г)
8:(’‹)— 10% У;(’‹) ‚ (813)
‚=
Ум’) = 1’: (8:00) . (314)

(2)
В свою очередь, веса “у образуют матрицу “т, описывающую синап-
пгческие связи нейронов выходного слоя, а 15%) — функция активации й-го
нейрона выходного слоя.

14‘

К

212 _ 8. Редщздёнтные сети на базе пешептеона

8.3.2. Алгоритм обучения сети Эльмана

Для обучения сети Эльмана будем использовать градиентный метод
наискорейшего спуска, основанный на работах Р. Вильямса и Д. Зипсера [171].
Для этого метода необходимо задать формулы, позволяющие рассчитывать
градиент целевой функции в текущий момент времени. Целевая функция в
момент г определяется как сумма квадратов разностей между значениями
выходных сигналов сети и их ожидаемыми значениями для всех М выход-
ных нейронов:

Е‹’5)=Е5[Уг(’5)—дг(’5)] =5Еч00 -  (825)

При дифференцировании целевой функции относительно весов выходного
слоя получаем:

Ё‘ дЕ К М д/( г(‚‹))д ;(’‹)
у$вад= дшё) =ёедкьёйг за? .  (8.26)

С  выражений (823) и (8.24) зависимость (8.26) можно представить в
виде
М 41209410)‘ ‹1‹"ё”ч‹’‹»_

(2) = _

(2)
=^йе‚(‚дд1ё(в‚(1‹)) 5% Ф’; „‹;›+‹1‘ч„„‚‹‚‚‚]_ ‚   

г=1 дат‘) 1=0 бшёъ) и ёшьд
Связи между скрытым и выходным слоем однонаправлегптые (см. рис. 8.9).
д .
поэтому Е) = 0 . С учетом этого факта

(‘шар (1)
— Ф» ан ‹‘‹»
УШЕ/с =м .1‹ ————"Ы8‘("» к д .1‹ = к ———1 д“ к . 8.28

«в ‹› Бел) (‚М‘) ‚ёофуд? т) м) бы,” т) ( ›

При использовании метода наискорейшего спуска веса  угочняются по
формуле  (К +1) =  (к) + АшЁЬ , где

АшЁЬ = 4175:}, вы) . (829)

Простое СРЗВНСНИС С ПСрССПТрОННОй СВТЬЮ показывает, ЧТО веса ВЫХОДНОГО
СЛОЯ ССТИ ЭПЬМЗНЗ ПОДВСРГЗЮТСЯ ТОЧНО такой же адаптации, как И веса ВЬШОДНЫХ

нейронов персептрона.
Формулы уточнения весов скрытого слоя сети Эльмана более сложны из-за

наличия обратных связей между скрытым и контекстным слоями. Расчет компо-
нентов вектора градиента целевой функции относительно весов скрытого слоя
требует выполнения значительно большего количества математических операций

1.! тёнтная сеть Эльмана _ 213

3 ясгности,

(п) _ М д! (8:09) К ‘КУМРЧ _
уфЕад-Ёел‘) 318, (к) Ё 4%}; ‘-

_ М ‘у (8100) к ажиг)
“Бел” Ёаш  «#33; “Ё” ' (кво)

С учетом зависимости (8.22) получаем:

а . к а _ ‹1‹ к Ф а п. ' д
п‘; = 1Ё(и‚) МЁк х‚‚( Км) = .Й(11‚) бшхр +1УЁКС1ХЬЕ1))ШЁ) _ (831)
бшад йи] ‘‹=о (Мад Ф‘; л=о (Мад

Из определения входного вектора х (формула (8.20)) в момент г следует, что

(Мёд (119 ш л=м+1 (МЬЗ 1
дШщ) Ка» (к-х)
= д. а Ф _
д“! „мы + Е! МЬВ "Эдик (8.32)

Это выражение позволяет рассчитать производные целевой функции
ггносительно весов скрытого слоя в момент г. Следует отметить, что это
хкуррентная формула, определяющая производную в момент г в зависимости от
и значения в предыдущий момент г- 1. Начальные значения произво ных в

исходный момент г‘ = 0 считаются нулевыми: ‘МЕ? = ф’ ) =  = “Ка? = 0 .
би’ дм’ дшад

Таким образом, алгоритм обучения сети ЭльЙЁна моЁЁно представить в
ыедующем виде.

|. Начать обучение с присвоения весам случайных начальных значений,

имеющих, как правило, равномерное распределение в определенном интер-

вале (например, между —1 и 1).

Для очередного момента г (г = 0, 1, 2, ...) определить состояние всех нейронов

сети (сигналы У; И у;)— На этой основе можно сформировать входной вектор

х(1‹) для произвольного момента 1‘.

3. Определить вектор погрешности обучения е(п) для нейронов выходного слоя
как разность между фактическим и ожидаемыми значениями сигналов
выходных нейронов.

4. Сформировать вектор градиента целевой функции относительно весов
выходного и скрытого слоя с использованием формул (8.28), (8.30) и (8.32).

5. Уточнить значения весов сети согласно правилам метода наискореёпцего
спуска:

’ для нейронов выходного слоя сети

ИЁЪ(1‹)= шЬЁЪ(1‹—1)—п7ЁЪЕ(1‹); (ваз)

е)

214 8. Рекиерентные сети на базе пеЕептрона

’ для нейронов скрытого слоя сети

„Щ, (к) = „Щ, (к — 1) 41735509 . (834)
После уточнения значений весов вернуться к пункту 2 алгоритма для расчетов
в очередной момент г. ‚

Для упрощения вычислений при выводе формул (8.33) и (8.34) была
предложена онлайн-версия алгоритма обучения, согласно которой значения весов
уточнялись после предъявления каждой обучающей пары (х, (1). Обычный офф-
лайн—алгоритм несколько более эффективен, поскольку при его выполнении
значения весов уточняются только после предъявления всех обучающих пар.
Реализация такой версии алгоритма аналогична рассмотренной выше с той
разницей, что в ней суммируются компоненты градиента последовательно
предъявляемых обучающих пар, а процесс изменения весов выполняется в
каждом цикле только один раз. д и ; Ю

Представленный алгоритм считается нелокальным, поскольку уточнение
каждого отдельного веса требует знания значений всех остальных весов сети и
сигналов конкретных нейронов. Его требования к размерам памяти компьютера
дополнительно повышаются в связи с необходимостью хранить все значения

‹1\’‚(1‹)

дшж

8.3.3. Обучение с учетом момента

Практические реализации алгоритма обучения сети Эльмана строятся на методе
наискорейшего спуска, усиленном моментом. Это значительно повышает
эффективность обучения и вероятность достижения глобального минимума
целевой функции. При использовании такого подхода уточнение вектора весов
сети в момент г выполняется в соответствии с формулой

Аи’(1с) = — Ц7Е(1с) +а(1с) Аи’(1с—1), (835)

где ‹х(1с) - это коэффициент момента, выбираемый из интервала (О, 1). Первое
слагаемое этого выражения соответствует обычному методу обучения, тогда ка:
второе, учитывающее фактор момента, отражает последнее изменение весов и не
зависит от фактического значения градиента. Чем больше величина а, тем
большее влияние на подбор весов оказывает слагаемое момента. Его значение
существенно возрастает на плоских участках целевой функции и около

локального минимума, где значение градиента близко к нулю.

В окрестности локального минимума не связанный с градиентом фактор
момента может вызвать изменение весов, ведущее к росту значения целевой
функции и к выходу из зоны притяжения этого минимума с возобновлением
поиска области, в которой целевая функция имеет меньшее значение. Фактор
момента не может доминировать при уточнении весов, поскольку в этой ситуации

&3. Рреентная сеть Эльмана 215

процесс обучения и, следовательно; поиска минимума никогда бы не завершился.
Обычно для управления процессом обучения вводится понятие допустимого
прироста погрешности, например, 3%. В таком случае, если в 1с-й итерации
значение целевой функции удовлетворяет зависимости Е(1с)< 1,03 Е(1‹ - 1), то шаг
принимается и значения весов уточняются, в противном случае фактор момента
игнорируется, и принимается ‹х(/‹) = 0. Выбор оптимального значения
коэффициента момента — это непростая задача. Для ее решения требуется
провести значительное количество численных экспериментов, цель которых
состоит в адаптации значения этого коэффициента к решаемой проблеме. Обычно
удовлетворительным считается субоптимальное значение, которое обеспечивает
достижение (хотя, возможно, и не самое быстрое) хороших показателей обучения.

8.3.4. Пример компьютерного моделирования сети Эльмана

Сеть Эльмана имеет рекуррентную структуру с обратной связью между скры-
тым и входным слоями. С учетом непосредственного влияния сигналов в момент
(п -1) на ее поведение в момент п такая сеть естественным образом предраспо-
ложена к моделированию временных рядов.

В практической реализации алгоритма обучения сети Эльмана (программа
Е1тап) использовался способ адаптации весов типа “оффлайн” и применялся
метод наискорейшего спуска с учетом момента со значениями коэффициента
момента в интервале от 0 до 1 (значение по умолчанию равно 0,95). Для уско-
рения обучения использовался адаптивный коэффициент обучения т], подстраи-
ваевшй к фактическим изменениям значений целевой функции в процессе
обучения.

В настоящем подразделе будут представлены результаты применения сети
Эльмана для распознавания амплитуд двух синусоидальных сигналов по каждой
реализации сигнала, поданного на вход сети. Задача состояла в предсказании
амплитуды сигнала на основе текущего значения входного сигнала и запом-
ненных значений из предыдущего временного цикла. В итоге сеть должна
сформировать на своем выходе сигнал, соответствующий амплитуде входного
сигнала.

В численном эксперименте входной сигнал представлял собой последо-
вательность из 80 синусоидальных сигналов с двумя различными амплитудами,
равными 1 и 2 соответственно, описываеме. зависимостью

наш для 0 ‹ к з 20
2$йп(1‹—20) для 20 < к 5 40

х‘ = нщк —40) для 40 < к з 00 ' (836)
2$йп(1‹ — 60) для 60 < /с 5 80

Для решения задачи была построена сеть со структурой 11-10-1. Вход сети
образован одним истинным входным узлом и 10 контекстными узлами, так как

 

скрытый слой состоит из 10 нейронов. Каждый нейрон скрытого слоя
характеризуется сшмоидальной (биполярной) функцией активации, а выходной
нейрон является линейным. На рис. 8.10 представлены сигналы: ожидаемый
(сплошная линия) и фактически сгенерированный сетью (пунктирная линия)
после 1000 циклов обучения (верхний график), а также график погрешности рас-
познавания амплитуды конкретных выборок. Анализ графиков свидетельствует,

2,5

Амплитуда
Ё. „

 

Погрешность

 

0 10 20 30 40 50 60 70 80
Выборка

Рис. 8.10. Результаты обучения сети Эльмана распознаванию амплитуды двух сигналов

что эффективность отслеживания сетью входного сигнала может считаться
удовлетворительной. Среднее значение модуля погрешности за время проведения
эксперимента по результатам обучения составило 0,069. Для проверки кор-
ректности функционирования сети в случаях генерации последовательностей с
другими амплитудами, с зашумленными сигналами, а также при потерях
отдельных фрагментов данных и обработке сигналов с частотой, отличающейся
от использованной для обучения, была организована серия обобщающих тестов
натренированной сети.

В качестве зашумленных сигналов использовалась последовательность
данных, описываемых зависимостью х; = х‚‚ + в , где в — это шум из интервала
(-1\/, Н), а хд — сигнал, определенный выражением (836). На рис. 8.11 приведены
результаты тестирования сети для Н = 0,1 и Н = 0,5. Оказалось, что сеть неплохо
“справляется” с сигналами, имеющими небольшую зашумленность, например,
П = 0,1. Однако ее эффективность в распознавании амплитуды сигнала, сильно
искаженного шумом (например, Н=0,5), значительно ниже, хотя и в этом случае
наблюдается отслеживание изменений амплитуды входных сигналов.

Для проверки работы сети при другой амплитуде синусоидальных сигналов
натренированная ранее сеть тестировалась на последовательности сигналов,

' Редгеентная сеть Эльмана 217’

 

Ь’
ш

М

 

0 10 20 30 40 50 60 70 80
Выборка

Амплитуда для 50% шума Амппитуда для 10% шума

Рис. 8.11. Иллюстрашая влияния шума на распознавание сетью Эльмана
амплитуды двух сигналов

ГЦИСЫВЗСМЫХ ЗЗВИСИМОСТЬЮ

1,2 з1п(1‹) для 0 < 1с  20
1,6 з1п(1с - 20) для 20 < 1: 5 40
х =
 " 1,2з1п(1‹ —4о) для 40 < к 5 во '

1,6 $1п(1‹ — 60) для 60 < К 5 80

(8.37)

На рис. 8.12 представлены результаты функционирования сети в этом
‘щсперименте. Поскольку обучение проводилось только на амплитудах со
значениями 1 и 2, сеть сохранила определенные способности к обобщению,
юзволившие ей отслеживать значения других сигналов, хотя и со значительно
Ёатьшей погрешностью. Для проверки устойчивости натренированной сети к
пченениям частоты сигнала бьши проведены очередные тесты с данными,
шеющими характеристики

з1п(1\’7с)  для 0 < 1с 5 20

И 2$1п(1\/(1‹—29)) для 20<1с540 ‚„ —›

хе = ‚ (8.38)
з1п(1\/(1‹ — 40)) для 40 < К 5 60
2з1п(1\!(1‹ — 60)) для 60 < К 5 80

зря Н = 0,8 и Л = 1,5. Результаты „моделирования в виде соответствующих
‘рафиков амплитуд: ожидаемой (сплошная линия) и распознанной сетью (пунк-

218 8. Ре%еентные сети на базе пеесептеона

2, 5

  

Амплитуда

О, 5

Погрешность ›
О

 

й

10 20 30 40 50 60 70 50
Выборка

Рис. 8.12. Результаты тестирования сети Эльмана на данных с амплитудой,
измененной по сравнению с обучаюшими сигналами

Амплитуда

 

0 10 20 30 40 50 60 70 50

Амплитуда

 

0 10 20 30 40 50 60 70 80
Выборки на частоте 1,5

Рис. 8.13. Иллюстрация влияния изменения частоты на распознавание
сетью Эльмана амплитуды двух сигналов

тирная линия) представлены на рис. 8.13. Анализ этих графиков позволяет сде-
лать вывод, что сеть корректно распознает амплитуды сигналов с частотой, отли-
чающейся от частоты обучающих данных даже при изменении частоты на 20%
Неудовлетворительные результаты распознавания наблюдаются при значи-

$„4.СетьКТКП ‹‘ ‘=   ‚‚- 219

 

тельных огклонениях частоты от ожидаемой величины (результаты при 50%-ном
зтклонении частоты приведены на нижнем графике рис. 8.13). Во всех
эписываемых экспериментах структура данных была симметричной: 20 выборок
имели одну амплитуду, а 20 — другую, причем их последовательности повто-
рялись. Такое чередование тестовых сигналов наследовало структуру данных,
нспользованную на стадии обучения сети. Для проверки способности сети к
обобщению были также проведены тесты с данными другой длины и с иной
пропорцией распределения выборок. В первом тесте были удалены 10 первых
выборок с амплитудой 1, а во втором — еще дополнительно 10 первых выборок с
амплитудой 2. Результаты этих тестов представлены на рис. 8.14. Можно

З

   

Амплитуда

Амплитуда

 

0 10 20 30 40 50 60
Выборка

Рис. 8.14. Результаты тестирования сети Эльмана на данных
с несимметричной структурой

отметить, что удаление части сигналов не оказало существенного воздействия на
качество отклика. Система функционировала корректно, демонстрируя удов-
летворительное качество распознавания амплитуды.

8.4. Сеть КТКГЁ!

8.4.1. Структура сети и алгоритм обучения

‚р;

Среди рекуррентных сетей особого внимания заслуживает сеть типа КТКЫ (англ.:
Кеа! Пте Кесиггеп! Летит), предложенная Р. Вильямсом и Д. Зипсером в работе
[171] и предназначенная для обработки сигналов в реальном времени.
Обобщенная структура сети представлена на рис. 8.15. Сеть содержит М входных

220 8. Р е сети на базе МЁШ’ на

узлов, К скрытых нейронов и К соответствующих им узлов контекстного ‘слоя. Из
К скрытых нейронов только М составляют выход сети. Обозначим взвешенную
сумму д-го нейрона скрытого слоя щ, а выход этого нейрона — уд. Вектор х(1‹) и
смещенный (задержанный) на один цикл вектор у(1с - 1) образуют расширенный
вектор активации х(1‹), возбуждаюший нейроны сети:

х(1с) = [1, х1(1‹), х;(1‹)‚  , хд(1‹),у1(1‹—1),  , у;‹(1с-1)]Т. (839)

ПОСЛС ОПИСЗНИЯ ВХОДНОГО вектора ССТИ В МОМСНТ 1 МОЖНО ОПРСДСЛИТЬ
СОСТОЯНИС ВССХ НСЙРОНОВ СОГЛЗСНО ЗЗВИСИМОСТЯМС

Л+К
и! (15) = Ёбидх; (15) ‚ (8-40)
у‚(1‹›= 1‘ (“К”) ‚ (3-41)

причем Д ) обозначает непрерывную функцию активации нейрона (как правило,
сигмоидальную). На рис. 8.15 видно, что сеть КТКЫ представляет собой частный

Рис. 8.15. Структура сети КТКЫ ‘

случай сети Эльмана, в которой веса выходного слоя посгоянны и‘ равны дельте
Кронекера, т.е. шд =б д= 1 для 5=] или 0 для 1 чг 1. В этом случае можно при-
менять алгоритм обучения Вильямса-Зипсера, представленный в одном из
преды-дущих подразделов, поскольку обучение сети связано с уточнением весов
единственного существующего слоя. При модификации соответствующих
формул расчета вектора традиента, выведенных для сети Эльмана (при фик-

14. Сеть КТШУ 221

 

ации значений весов выходного слоя), получим следующий алгоритм обучения

сети КТКЫ, называемый алгоритмом Вильямса-Зипсера [171].

1. Выбрать случайные начальные значения весов сети, составляющих матрицу
Ж’ и равномерно распределенных в заданном интервале (обычно в диапазоне
от -1 до 1).

1. Рассчитать состояние всех К нейронов для очередного момента
к (к = 0,1,2‚...) с использованием зависимостей (8.40) и (8‚41). На этой основе
можно определить расширенный входной вектор х(1‹), возбуждающий
нейроны в момент 1.

д)’, (10 .‚
3. Рассчитать значения дш в соответствии с формулои
«а
‹1у—(’‹) ‘ИОН ‘‹ еу (1‹—1)
авф = аи „1 д“"х” +ЁГ`ЁБТИ”“" ` (Зм)
1

4. Уточнить значения весов по алгоритму наискорейшего спуска согласно
формуле

“ _ _ м ф’; (д)
».‚„‹‘‹+1›—»‚„„‹’‹›-п2гу,‹’‹›-а‚‹‘‹›1 ‚ т»
;=1 ат,

для а = 1, 2, ..., Х и В = 0, 1, 2, ..., 1Ч+ К. Циклы (2 — 4) повторять вплоть до
стабилизации значений всех весов сети.

Приведенный алгоритм обучения сети КТКЫ был реализован в программе,
названной также КТКМ В ней процесс обучения оптимизирован за счет
применения адаптивного коэффициента обучения и обучения с учетом момента,
аналогично тому, как это делалось в программе Е1тап.

8.4.2. Результаты вычислительных экспериментов

Как мы уже отмечали, сеть КТКЫ - это частный случай сети Эльмана, в которой
веса выходного слоя имеют бинарные значения, т.е. шд = б д= 1 для 1=] или О для
д: 1. Для изучения возможностей ее практического применения исследовалось
функционирование этой сети в качестве системы линейной идентификации
динамического объекта, описываемого матричным уравнением состояния [156]:

х(/‹ + 1) = Ах(1‹) + Ви(/‹)

(8.44)
У(’‹)=Сх(’‹)‚
где
ха Уп "х
х=Х2,у= 3Ё2‚и= 112 _
хк Ум "и

Вектор х называется вектором состояния, у - выходным вектором, а и - вектором
возбуждения. Квадратная матрица состояния А имеет размерность К х К матрица

222 8. Ре ентные сети на базе пе септ она

В - размерность Х йМ а матрица С — размерность М х К В этом приложении сеть
абсолютно линейна (в том числе и скрытые неироны). При сопоставлении

структуры сети (рис. 8.15) со схемой распространения сигналов, соответствую-
щей зависимости (8.44), видно, что матрицу А образуют веса шд для 1= 1, ..., К и
]=1\/+ 1, ...,1\!+К, матрицуВ-веса шд для 1= 1, ...,Ки]= 1, ...,1\!, аматрицу С
— единичные или нулевые веса выходного слоя (сеть КТЮЧ состоит из одного
слоя, поэтому ее выход могут определять только переменные состояния, а`в мат-
рице С ненулевыми, т.е. единичными, могут быть лишь диагональные элементы).

Результаты вычислительных экспериментов можно представить на примере
линейной динамической системы третьего порядка с одним входом и двумя

выходами, опиеьхваемой матрицами А, В и С вида

0,3 0,1 0,1 0,5
1 0 0
А= 0 0,4 0,3 , В= 0,2 , С=
0 1 0
0,5 0,1 0,5 0,1

Для определенных таким образом матриц состояния генерировались
обучающие данные в форме последовательности пар “вход —- выход” (рис. 8.16),
где входной сигнал и(1‹) был случайным, а заданный вектор (1 составлялся из
обоих компонентов выходного сигнала и рассчитывался по формуле
11 = С(з1—А)’1Ви. Таким образом, реализованная нейронная сеть КТЮЧ имела
структуру 4-3-2 (4 входных узла: один для внешнего сигнала и(1‹) и три

9
ы

д)

9
ю

9
ч

   

|
9
ч

Первый сигнал

   
 

 

ё

150 200 250 30 350 400 450 500
Выборка

З

9

М
О
ч
8

9
ч

(МВ)

О

Ь

    

Второй сигнал
Ь
М

50 100 150 200 250 300 350 400 450 500
Выборка

О

Рис. 8.16. Графики обучающих данных (заданные значения) для сети КТКМ для примера
идентификации матрицы переменных состояния:
а) сигналы первого контура; б) сигналы второго контура

9 д Сеть КТКН _ 223

 

фтекстньхх узла, 3 скрытых нейрона и 2 выходных нейрона с априори
пвестньхми весами шд =б д ). Сеть КТКЫ обучалась на множестве из 500 пар
пнных. Распределение входных данных, использованных для обучения сети,
федставлено на рис. 8.16. Верхний график представляет заданные значения
первого контура, а нижний график —- данные второго контура.

з

  
  

 

 

 

’)

Щ

Ф

Е

ё

о — — 1 2 2 2 : 5
0 50 100 150 200 250 300 350 400 450
Шаг обучения _—‚

б) 0,5

Е д‚4 .... ..

10,3

В

ёд’; ...... ..

ё 0,1’

о . — д 2 : — Х
0 50 100 150 200 250 300 350 400 450
Шва обучения
м
г)
0 50 100 150 200 250 30 350 400 450
Шаг обучения

г)

  

Значение А [3]

 

0 50 100 150 200 250 300 350 400 450
Швв обучения

Рис. 8.17. Графики изменения значений отдельных элементов матриц А и В в процессе
обучения сети КТКМ

224 8. Ре%еентные сети на базе пеесептшна

На рис. 8.17 показан процесс адаптации трех весов сети, составляющих
матрицу В (рис. 8.17а) и девяти весов, составляющих матрицу А (рис. 8.176, в, г‘
Для матрицы А каждый график относится к трем весам соответствую-
щей строки матрицы. Достигнутое состояние с фиксированнь1ми значениями
весов свидетельствует об успешной адаптации сети в качестве модели
динамической системы с заданной временной характеристикой, определен-
ной обучающими данными. Идентифицированные значения матриц А и В
имеют вид:

0,305 0,0в75 0,13 0,5
А= 0,012 0,286 0,404, а = 0,2
0,373 0,235 0,505 0,112

Они отличаются от оригинала, несмотря на то, что характеризуются
такими же временными реакциями (одинаковые временные характеристики
может иметь множество систем различной структуры — система идентификации
имеет много решений). После обучения сеть подверглась тестированию на
данных, основанных на синусоидальном возбуждающем сигнале. Проводимый
тест должен был проверить, насколько хорошо сеть отражает свойства дина-
мического объекта, в качестве модели которого она используется. Несмотря на то,
что полученные матрицы А и В отличались от значений, при которых
генерировались обучающие данные, идентифицированная система демонст-
рировала такие же свойства, что и оригинальньпй обьекп Временные реакции каь

 

0 50 100 150 200 250 300 350 400 450 500

Выборка

б)

я
8

сти
9
оЁ

  

Пёгрешно
ё.

|
9
о
м

0 50 100 150 200 250 300 350 400 450 500
Выборка

Рис. 8.18. Реакция натренированной сети КТКЫ на синусоидаххьное возбуждение‘
а) график значений, фактически полученных на двух выводах модели; б) трафш
соответствующих погрешиостей вычислений

8.4. Сеть КТКН 225

 

на пороговое, так и на синусоидальное возбуждение с высокой точностью
совпадали с ожидаемыми значениями. На рис. 8.18 в качестве примера пред-
сгавлена реакция системы на синусоидальное возбуждение. График на рис. 8.18 а
относится к реакции в обоих входных контурах, а график на рис. 8.186 - к
разностям по отношению к ожидаемым значениям. Минимальное отклонение
реакции модели от реакции объекта не превысило значения 0,005 в обоих
контурах, что с учетом амплитуды выходного сигнала, равной 1, может
считаться очень хорошим достижением. `

ЖС

‚ЗЦЁН.

1 5-2162

„Раздел 9

сети с САМООРГАНИЗАЦИЕЙ
НА основе конкуренции

Основу самоорганизации нейронных сетей составляет подмеченная
закономерность, что глобальное упорядочение сети становится возможным в
результате самоорганизующих операций, независимо друг от друга проводящихся
в различных локальных сегментах сети. В соответствии с поданными входными
сигналами осуществляется активация нейронов, которые вследствие изменения
значений синаптических весов адаптируются к поступающим обучающив
выборкам. В процессе обучения наблюдается тенденция к росту значений весов.
из-за которой создается своеобразная положительная обратная связь: боли
мощные возбуждающие импульсы - более высокие значения весов - большая
активность нейронов. При этом происходит естественное расслоение нейронов в:
различные группы. Отдельные нейроны или их труппы сотрудничают между
собой и активизируются в ответ на‘ возбуждение, создаваемое конкретншп
обучающими выборками, подавляя своей активностью другие нейроны. Про
этом можно говорить как о сотрудничестве между нейронами внутри труппы.
так и о конкуренции между нейронами внутри труппы и между различныщ
группами.

Среди механизмов самоорганизации можно выделить два основных класса
самоорганизация, основанная на ассоциативном правиле Хебба, и механизм
конкуренции между нейронами на базе обобщенното правила Кохонена.

Независимо от способов обучения самоорганизующихся сетей важное
значение имеет избыточность обучающих данных, без которой обучение прост’;
невозможно.

Широкий спектр обучающих данных, включающий многократные повторени:
похожих друг на друга выборок, образует “базу знаний” для обучениь
сети, из которой путем соответствующих сопоставлений выводятся реше
ния по формированию на входе сети определенного оггклассифицированноп
вектора.

9.1. Опшичительные особенности сетей с салюорганизацией на основе конкуренции 227

 

9.1. Отличительные особенности сетей
с самоорганизацией на основе конкуренции

В этом подразделе представлены сети с самоорганизацией, основу обучения
вторых составляет конкуренция между нейронами. Как правило, это однослой-
ные сети, в которых каждый нейрон соединен со всеми компонентами Н-мерного
входного вектора х так, как это схематически изображено для Н = 2 на рис. 9.1.

4—“——— НейроНЫ

 

Рис. 9.1. Структура самоорганизующейся сети Кохонена

Веса синаптических связей нейронов образуют вектор и’; = [шт шд, ..., шМТ.
После нормализации входных векторов при активации сети вектором х в
конкурентной борьбе побеждает тот нейрон, веса которого в наименьшей степени
отличаются от соответствующих компонентов этого вектора. Для ш-го нейрона-
победителя выполняется отношение

‹1‹‚‹,›‹›„)=ЁЁЗ‹1(‚‹,»,), (91)

где д (х, и’) обозначает расстояние (в смысле выбранной мстрики) между векто-
рами х и и’, а п —- количество нейронов. Вокруг нейрона-победителя образуется
юпологическая окрестность $„(1‹) с определенной энергетикой, уменьшаю-
щейся с течением времени. Нейрон-победитель и все нейроны, лежащие в
пределах его окрестности, подвергаются адаптации, в ходе которой их векторы
весов изменяются в направлении вектора х по правилу Кохонена [74]:

"’:(/‹+1) = МН‘) + п:(/‹) [Х — И’: (д) 1 (91)

15’

228 9. Сети с самоорганизации? на основе контениии

для 1 е $„(1‹), где ц;(1‹) обозначен коэффициент обучения т-го нейрона и?‘
окрестности $„‚(1с) в 1с-й момент времени. Значение 1110:) уменьшается с
увеличением расстояния между т-м нейроном и победителем. Веса нейронов,
находящихся за пределами $„‚(/с), не изменяются. Размер окрестности и
коэффициенты обучения нейронов являются функциями, значения которых
уменьшаютсястечением времени. Х.Риттер и К.Шультенв [134] доказали,что
адаптация по формуле (9.2) эквивалентна градиентному методу обучения.
основанному на минимизации целевой функции ф‘

го») = 1 2$‚‹х‹‘‹»тх,‹‘‹›— и›„‹‘‹›1‘ , ‹9.3‚
2т‚1,г‹

а $д(х(1с)) представляет собой функцию определения окрестности, изменяю-
щуюся в процессе обучения. Доказано [73, 74, 134], что при таком способе
обучения функция плотности распределения векторов и’; нейронов сводится к
дискретизированной плотности распределения вьптужденных векторов.

После предъявления двух различньтх векторов х, например х1 и х2‚ акти-
визируются два нейрона сети, веса которых наиболее близки к координатам
соответствующих векторов хд и х2. Эти веса, обозначенньте в векторной форме и»,
и щ, могут отображаться в пространстве как две точки. Сближение векторов х
и х; вызывает соответствующее изменение в расположении векторов щ и юг. В
пределе равенство щ = и’; выполняется тогда и только тогда, когда хд и х;

`совпадают или практически неотличимы друг от друга. Сеть, в которой эти

условия выполняются, называется топографической картой, или картой Кохонена

9.1.1. Меры расстояния между векторами

Процесс самоорганизации предполагает определение победителя каждого этапа
т.е. нейрона, вектор весов которого в наименьшей степени отличается от
поданного на вход сети вектора х. В этой ситуации важной проблемой становится
выбор метрики‚ в которой будет измеряться расстояние между векторами х и и»,
Чаще всего в качестве меры расстояния используются:

9 ЭВКЛИДОВЗ мера

 

‘1(х‚ т) =|| х — "и ||= (9.4ъ
’ скалярное произведение ""
‘1(х‚"’‚)=1—х—"›‚=1—||"Н|Н"’‚||с‹›э(х‚"’‚); 0.5»

’ ме а относительно но мы 1.1 Манхэттен
Р Р

‘их’ ют) = 3 (9-6

 

11. Отличительные особенности сетей с самоорганизацией на основе конкуренции 229

 

0 мера относительно нормы Ь“,

‘1(х‚ т) = гчах| и — “т! ‚ . (97)

При использовании эвклидовой меры разбиение’ пространства на зоны
ДОМИНИрОВЗНИЯ нейронов равносильно МОЗНИКС ВОРОНОГО, В КОГОрОЙ
пространство вокруг центральных точек образует окрестносгь домннирования
данного нейрона. Использование при самоорганизации любой другой меры
вызывает несколько иное разделение сфер влияния нейронов. Следует отме-
ТЯТЬ, ЧТО ССЛИ ВСКТОрЫ не нормализуются, ТО ИСПОЛЬЗОВЗНИО В КЗЧССТВС
меры скалярного произведения может привести к несвязному разделению
пространства, при КОТОРОМ В ОДНОМ рСГИОНС МОЖЕТ НЗХОДИТЬСЯ НЕСКОЛЬКО

нейронов, а в другом не будет ни одного [25].

9.1.2. Нормализация векторов

Доказано, что если хотя бы один из векторов х или и’ подвергается нормализации,
ю процесс самоорганизации всегда приводит к связному разделению прост-
ранства данных. При нормализованных обучающих векторах х стремящиеся к
ним векторы весов и’ нормализуются автоматически (норма вектора равна 1).
Однако нормализация вектора весов приводит к тому, что если || щ" = сопзг, то для
всех нейронов при фиксированном значении х произведение ||х||||юд|| также
становится постоянной величиной. Поэтому активация нейрона определяется
значением со$(х,ю;), которое становится общей мерой для всей сети. Следует
отметить, что при нормализации вектора весов эвклидова мера и скалярное
произведение равнозначны друг друг); поскольку ||х -ю;||2 = ||х||2+|| и’;||2 - 2хТш-.
Поэтому тйп||х—п’г||г“тах(хтюд) при ||юд||=сопзп

Экспериментальные исследования подтвердили необходимость применения
нормализации векторов при малой размерности пространства, например при
п = 2 или п = 3. Такая нормализация может проводиться двумя способами:

О переопределением компонентов вектора в соответствии с формулой

Х,  9 

А’
‘ж?
Е=1

о увеличением размерности пространства на одну координату Ш” -› КМ’) с
таким выбором значения (1\/+1)-го компонента вектора, чтобы

Н +1

2 х} =1 . (99)

1=1

При использовании этого способа нормализации, как правило, возникает
необходимость предварительного масштабирования компонентов вектора х
в пространстве К” для того, чтобы могло выполняться равенство (9.9).

230 9. Сети с саяёбдрёднизацЁей на основе коншениии

С увеличением размерности входного вектора эффект нормализации
становится все менее заметным, и при больших объемах сети (Н > 200) она
перестает оказывать влияние на процесс самоорганизации.

9.1.3. Проблема мертвых нейронов а 

При инициализации весов сети случайным способом часть нейронов может
оказаться в области пространства, в которой отсутствуют данные или их
количество ничтожно мало. Эти нейроны имеют мало шансов на победу и
адаптацию своих весов, поэтому они остаются мертвыми. Таким образом,
входные данные будут интерпрегироваться меньшим количеством нейронов
(мертвые нейроны не принимают участие в анализе), а погрешность интер-
претации данных, иначе называемая погрешностью квантования, увеличится.
Поэтому важной проблемой становится активация всех нейронов сети.

Такую активацию можно осуществить, если в алгоритме обучения
предусмотреть учет количества побед каждого нейрона, а процесс обучения
организовать так, чтобы дать шанс победить и менее активным нейронам. Идея
такого подхода к обучению возникла при наблюдении за поведением
биологических нейронов. Отмечен факт, что нейрон-победитель сразу после
победы на некоторое время теряет активность, “отдыхал” перед следующим
этапом конкурентной борьбы [143]. Такой способ учета активности нейронов
будет называться в дальнейшем механизмом утомления’.

Существуют различные механизмы учета активности нейронов в процессе
обучения. Часто используется метод подсчета потенциала р; каждого нейрона.
значение которого модифицируется всякий раз после представления очередной
реализации входного вектора х в соответствии со следующей формулой (в ней
предполагается, что победителем стал ш-й нейрон):

1 .
р‚(/‹+1)= Р‘(")+’;(""’) . (940)
Р:(’‹)— рпйп (1 = И’)

Значение коэффициента ршдп определяет минимальный потенциал,
разрешающий участие в конкурентной борьбе. Если фактическое значение
потенциала р; падает ниже ршдд, 1-й нейрон “отдыхает”, а победитель ищется
среди нейронов, для которых выполняется отношение

‹1(х, вы) = ш1п{‹1 (х, юд}, "”"’"(9.1 1)

для 1313 Ы и р; 2 ртдп. Максимальное значение потенциала ограничивается на
уровне, равном 1. Выбор конкретного значения ртдп позволяет установить порог
готовности нейрона к конкурентной борьбе. При ршдп = 0 утомляемость нейронов
не возникает, и каждьпй из них сразу после победы будет готов к продолжению

 

1 Оригинальное название сопвсйепсе тесйапёзт иногда переводится как механизм
совести.

22. Алгоритмы обучегшееоггей с самоорганизации? 231

 

сбперничества (стандартный алгоритм Кохонена). При Ртйп = 1 возникает дРУГая
крайность, вследствие которой нейроны побеждают по очереди, так как в каждый
момент только один из них оказывается готовым к соперничеству. На практике
хорошие результаты достигаются, когда Ртйп = 0,75. ‘

В другом очень удачном алгоритме обучения количество побед нейрона
учитывается при подсчете эффективного расстояния между вектором весов и
реализацией обучающего вектора х. Это расстояние модифицируется про-
порционально количеству побед данного нейрона в прошлом. Если обозначить
количество побед Ё-го нейрона М, такую модификацию можно представить
в виде

‹1(х, шд)‹—1\/дс1(х, „д. ' (912)

Активные нейроны с большим значением М штрафуются искусственным
завышением этого расстояния. Следует обратить внимание, что модификация
расстояния производится только при выявлении победителя. В момент уточнения
весов учитывается фактическое расстояние. Модификация этой характеристики
имеет целью активизировать все нейроны путем введения их в область с большим
количеством данных. После решения этой задачи (обычно после двух или трех
циклов обучения) модификация прекращается, что позволяет продолжить

“честную” конкуренцию нейронов [139].

9.2. Алгоритмы обучения сетей
с самоорганизацией

„г.

Целью обучения сети с самоорганизацией на основе конкуренции нейронов
считается такое упорядочение нейронов (подбор значений их весов), которое
минимизирует значение ожидаемого искажения, оцениваемого погрешностью
аппроксимации входного вектора х, значениями весов нейрона-победителя в
конкурентной борьбе. При р входных векторах х и применении эвклидовой
метрики эта погрешность, называемая также погргшностью квантования, может
быть выражена в виде

2
 Е, =—ЁН "‚—“’„‹‚›|| , (913)

где мы“) - это вес нейрона-победителя при предъявлении вектора щ. ’ ’ 

 Этот подход также называется векторным квантованием (англ.: Игсюг
Ёиапйгайоп - У@). Номера нейронов-победителей при последовательном
предъявлении векторов х образуют так называемую кодовую таблицу. При
классическом решении задачи кодирования применяется алгоритм К-усредне-
ний (англ.: К-теапв), представленный в разделе 5 и носящий имя обобщенного
алгоритма Ллойда [89].

232 9 Семи с самооёаншатшей на основе пришли

Для нейронных сетей аналогом алгоритма Ллойда считается алгоритм ШТА
(англ.: Иёппег Та1сев АЛ - Победитель получает все). В соответствии с ним после
предъявления вектора х рассчитывается активность каждого нейрона.
Победителем признается нейрон с самым сильным выходным сигналом, т.е. тот,
"для которого скалярное произведение (хТш) оказывается наибольшим. В
предыдущем разделе было показано, что при использовании нормализованных
векторов это равнозначно наименьшему эвклидовому расстоянию между
входным вектором и вектором весов нейронов. Победитель получает право
уточнить свои веса в направлении вектора х согласно правилу

щ ‹— "ы +11(х—“‘„) . (914)

Веса остальных нейронов уточнению не подлежат. Алгоритм позволяет

учитывать усталость нейронов путем подсчета количества побед каждого из них

и поощрять элементы с наименьшей активностью для выравнивания их шансов.
Как уже отмечалось ранее, такая модификация применяется чаще всего на
начальной стадии обучения с последующим отключением после активизации
всех нейронов. Подобный способ обучения реализован в программе КоИоп в виде
режима СЩТА‘ и считается одним из наилучших и наиболее быстрых алгоритмов
самоорганизации.

Помимо алгоритмов ЧУТА, в которых в каждой итерации может обучаться
только один нейрон, для обучения сетей с самоорганизацией широко
применяются алгоритмы типа ЧУТМ (англ.: Ибппег Та/сез Мозг - Победитель
получает больше), в которых, кроме победителя, уточняют значения своих весов
и нейроны из его ближайшего окружения. При этом чем дальше какой-либо
нейрон находится от победителя, тем меньше изменяются его веса. Процесс

‚уточнения вектора весов может быть определен обобщенной зависимостью (9.2),

которая ЗДССЬ ПРСДСТЗВЛЯЁТСЯ В ВИДЕ

и’, ‹— и’, +11,С(1‚х)[х - щ] (915)

для всех Е нейронов, расположенных в окрестности победителя. В приведенной
формуле коэффициент обучения 11; каждого нейрона отделен от его расстояния до
предъявленного вектора х функцией С(1,х). Если С(!‚х) определяется в форме

1 для 1=и’
6(г‚х)= , (9.1в)
0 для даем’
где и’ обозначает’ номер победителя, то мы получаем классический
алгоритм ШТА. Существует множество вариантов алгоритма ЩТМ, отли-
чающихся прежде всего формой функции 6(1,х). Для дальнейшего изучеъшя
выберем два из них: классический алгоритм Кохонена и алгоритм нейрон-
ного газа.

 

1 Название СЩТА происходит от английского названия алгоритма Сопзсдепсе 
ТаКез А11_

12. Алгоритмы обучения сетей с сдмоорганизацией 233

 

9.2.1. Алгоритм Кохонена

Алгоритм Кохонена относится к наиболее старым алгоритмам обучения
сетей с самоорганизацией на основе конкуренции, и в настоящее время
существуют различные его версии. В классическом алгоритме Кохоне-
на сеть инициализируется путем приписывания нейронам опреде-
ценных позиций в пространстве и связывания их с соседями на постоян-
ной основе. В момент выбора победителя уточняются не только его веса,
но также и веса его соседей, находящихся в ближайшей окрестности.
Таким образом, нейрон-победитель подвергается адаптации вместе со своими
соседями. В классическом алгоритме Кохонена функция соседства 66, х)
определяется в виде
1 для 1=и’
6(1, х) = . (9.17)
0 для Ёаги’

В этом выражении с1(1,и’) может обозначать как эвклидово расстояние между
векгорами весов нейрона-победителя и’ и Е-го нейрона, так и расстояние,
нзмеряемое количеством нейронов. Коэффициент 1 выступает в роли уровня
соседства, его значение уменьшается в процессе обучения до нуля. Соседство

такого рода называется прямоугольным.
Другой тип соседства, часто применяемый в картах Кохонена, — это соседство
гауссовского типа, при котором функция С(1, х) определяется формулой

‚ с12 Е и’

болот‘ —%Ё2 . (9.18)
Степень адаптации нейронов-соседей определяется не только эвкли-
довым расстоянием между Е-м нейроном и победителем (ш-м нейроном), но
также и уровнем соседства Я. В отличие от соседства прямоугольного типа,
где каждый нейрон, находящийся в окрестности победителя, адаптировался в
равной степени, при соседстве гауссовского типа уровень адаптации
отличается и зависит от значения функции Гаусса. Как правило, гауссовское
соседство дает лучшие результаты обучения и обеспечивает лучшую

организацию сети, чем прямоугольное соседство.

9.2.2. Алгоритм нейронного газа

4 е‘: ‘д,

Значительно лучшую самоорганизацию сети н ускорение сходимости
алгоритма Ч/ТМ можно получить применением метода, предложенного
М. Мартинесом, С. Берковичем и К. Шультеном в работе [94] и названного
авторами алгоритмом нейронного газа из-за подобия его динамики движению
молекул газа.

234 9. Сети с самоорганизаиией на основе коншрениии

В этом алгоритме на каждой итерации все нейроны сортируются в
зависимости от их расстояния до вектора х. После сортировки нейроны
размечаются в последовательности, соответствующей увеличению удаленности

с10<с1,<‹12<...<с1„_1,_1 (9.19)

где дд=||х - и’‚„«)|| обозначает удаленность й-го нейрона, занимающего в результате
сортировки т-ю позицию в последовательности, возглавляемой нейроном-
победителем, которому сопоставлена удаленность до. Значение функции
соседства для г-го нейрона С(1‚х) определяется по формуле

С(1, х) = ехр[-%] ‚ (910)
в которой т(!) обозначает очередность, полученную в результате сортировки
(т(1) = 0, 1, 2, ..., п - 1), а Я. — параметр, аналогичный уровню соседства в

алгоритме Кохонена‚ уменьшающийся с течением времени. При Я = 0 адаптации
подвергается только нейрон-победитель, и алгоритм превращается в обычный
алгоритм ШТА, но при Я $ 0 уточнению подлежат веса многих нейронов,
причем уровень уточнения зависит от величины С(ё,х). Алгоритм нейронного
газа напоминает стратегию нечетких множеств, в соответствии с которой
каждому нейрону приписывается значение функции принадлежности к
окрестности, определенной соотношением (920).

Для достижения хороших результатов самоорганизации процесс обучения
должен начинаться с большого значения Я, однако с течением времени его величи-
на уменьшается до нуля. Изменение М/с) может быть линейным или показатель-
ным. В работе [134] предложено нзменять значение Д/с) в соответствии с

выражением
— я ниш

).(‘‹)=я.„„‚х т“ , (921)
дн

ЗХ

где Я‚(1‹) обозначает значение А на К-й итерации, а Ятй, и Ашах - принятые
минимальное и максимальное значения Ж соответственно. Коэффициент Кшд
определяет максимальное заданное количество итераций.

Коэффициент обучения ё-го нейрона 11;(/‹) тоже может изменяться как
линейно, так и показательно, причем его степенная изменчивость определяется

Фгрмутй

мы,

11 .
п‚(1‹)= п‚(‹›) “ш ‚ (912)

 1110) Ё
в которой ТМО) обозначает начальное значение коэффициента обучения, а“11„11„ -

априорно заданное минимальное значение, соответствующее 1: = Ктах. На
практике наилучшие результаты самоорганизации достигаются при линейном
изменении 11;(/‹), и именно эта стратегия реализована в режиме ЪЮАЗ’

программы КоИоп.

1 Название ЪЮАЗ происходит от аъплийского названия нейронного газа Леша! газ.

В 2. Алгоритмы обучения сетей с самоорганизации? 235

 

Для сокращения объема вычислений," необходимых для реализации
алгоритма нейронного газа, можно применить определенное упрощение,
состоящее в учете при сортировке только нейронов с наиболее значимой
величиной функции СИ, х). При этом используется зависимость (9.20)‚ в
юответствии с которой если т(1) >> 1, то значение С(1,х) ё 0, Например, если
принять К = 3 Я, то при сортировке нейронов, а в последующем - и при их
адаптации можно ограничиться только первыми К элементами.

Алгоритм нейроннопо газа наряду с алгоритмом ЧЧТА, учитывающим актив-
ность нейронов (в режиме СЧ/ТА), считается одним из наиболее эффективных
средств самоорганизации нейронов в сети Кохонена. При соответствующем
подборе параметров управления процессом можно добиться очень хорошей
организации сети при скорости функционирования, превышающей достижимую
в классическом алгоритме Кохонена.

9.2.3. Сравнение алгоритмов самоорганизации

Приведенные выше алгоритмы сравнивались при решении задачи восстановления
двухмерных обучающих данных сложной струнсгурьт, представленной на рис. 9.2.
Для восстановления данных использовались два множества нейронов,
включающих 20 и 400 элементов, которые при идеальном упорядочении позиции
нейронов будут отражать распределение обучающих данных. Они должны
группировагься в областях максимальной концентрации данных. На рис. 9.3
приведены результаты самоорганизации 40 нейронов при использовании трех
алгоритмов, представленных в настоящем разделе: СШТА (рис. 9.3а), нейронного
газа (рис. 9.36) и алгоритма Кохонена (рис. 9.3в). Для сравнения на рис. 9.4
приведены те же самые отображения сетью, состоящей из 200 нейронов.

0, 7
0,65
0,6
0,55
0,5
0, 45
0,4
0, 35
0,3
0,25

0,2
0,25 0,3 0,35 0,4 0,45 0,5 0,55 0,6 0,65

 

Рис. 9.2. Распределение двухмерных данных, использованных для тестирования

236 9. Сети с самооеганизацией на основе квитанции

а) ‘ "Апворйтм И/ТА с механизмом утомления
при 40 нвйронах
0,7  ‚..____ _ 
0,65
0.6
0,55
0,5
0,45
0,4
0,35
0,3
0,25

   
 
 

 

0,2
0,25 0,3 0,35 0,4 0,45 0,5 0,55 0,6 0,65
б) 07 Алгоритм нейронново ваза при 40 нейронах

1

 

0,65
0 6
0,55
0, 5
0,45
0,4
0,35
0,3
0,25

0,2
0,25 0,3 0,35 0,4 0,45 0,5 0.55 0,6 0,65

в) Стандартный алгоритм Кохонана при 40нейронах

 

0,65
0.6
0,55
0,5
0,45
0,4
0,35
0,3
0,25
0,2
0,25 0,3 0,35 0,4 0,45 0,5 0,55 0,6 0,65

Рис. 9.3. Восстановление данных с рис. 9.2 самоорганизующейся сетью Кохонена,
состоящей из 40 нейронов, при использовании:
а) алгоритма СЧ/ТА; б) алгоритма нейронного газа; в) классического алгоритма Кохонена

9. 2. Алгоритмы обучения сетей с самоорганизации? _ 137

 

Алгоритм УУТА с механизмом утомления
в) при 200 нейронах

0,7 . . .   ____  ..
0,65
0,6
0,55
0,5
0,45
0,4
0,35
0,3
0,25

0,2
0,25 0,3 0.35 0,4 0,45 0,5 0.55 0,6 0,65

б) 7 Апворитм

‘в

г.

   
 

нейронноао ваз

—в

а при 200 нейронах

‹,.

    

    

 

0,3
0, 25

0,2
0,25 0,3 0.35 0,4 0,45 0,5 0,55 0,6 0,65

в) Стандартный алгоритм Кохонена при 200нейронах

0,65
0,6
0,55
0,5
0,45
0,4
0,35
0,3
`0,25
0,2

0,25 0,3 0,35 0,4 0,45 0,5 0,55 0,6 0,65

Рис. 9.4. Восстановление данных с рис. 9.2 самоорганизующейся сетью Кохонена,
состоящей из 200 нейронов, при использовании:
а) алгоритма СШТА; б) алгоритма нейронного газа; в) классического алгоритма Кохонена

238 9. Сети с сдмооеганизаиией на основе конШенЕии

Независимо от количества нейронов наилучшие результаты самоорганизации
бьши получены с использованием алгоритмов СЩТА и нейронного газа, причем
последний из-за необходимости сортировки оказался значительно более медлен-
ным, чем СЧЧТА. Оригинальный алгоритм Кохонена в обоих случаях оставался
наихудшим, не обеспечивая хорошего восстановления данных (определенное
количество нейронов размещалось в областях, свободных от данных).

Объективное количественное сравнение результатов самоорганизации можно
получить при сопоставлении расчетной погрешности квантования Ед (формула
(9.13)) для каждого случая. При 200 нейронах получены значения Ед = 0,007139 -
для СШТА, Ед = 0,007050 —— для нейронного газа и Ед = 0,0!0763 - для алго-
ритма Кохонена. При 40 нейронах результаты следующие: Ед = 0,017416 (СЧУТА),
Ед = 0,017599 (нейронный газ) и Е,‘ = 0,02539 (алгоритм Кохонена). Численные
показатели подтверждают зрительное восприятие качества восстановления
данных, согласно которому алгоритмы СП/ТА и нейронного газа дают сходные (и
наилучшие) результаты, а алгоритм Кохонена наименее эффективен.

9.3. Сеть восстановления одно-
и двухмерных данных

Для хорошего восстановления данных нейронной сетью требуется, чтобы
нейроны группировались в областях наибольшей концентрации данных, а не там,
где они отсутствуют. При оценке качества нейронной самоорганизующейся сети
важное значение имеет восстановление одно- и двухмерных данных, с учетом
четкости и очевидности интерпретации результатов на плоскости (х, у). Если
принять во внимание, что веса нейронов соответствуют координатам центров
кластеров, на которые подразделяется множество данных, то каждому векгору
весов можно приписать соответствующую точку на плоскости. Объединяя эти
точки с ближайшими соседями, можно получить регулярную сетку, отобра-
жающую топографическое распределение данных.

При равномерном распределении обучающих векторов х на плоскости
ожидаемое распределение восстановленных весов конкретных нейронов,
спроецированное на эту плоскость, также будет равномерным. Если же данные
распределены неравномерно, то концентрация будет наблюдаться в тех областях,
для которых вероятность предъявления обучающих векторов оказалась
наибольшей.

На рис. 9.5 представлены примеры восстановления данных, образующих
фигуры различной формы: эллиптическую, треугольную, прямоугольную и
нерегулярную. Сеть обучалась программой КоИоп по алгоритму СЧ/ТА.
Нейроны группировались в областях с наибольшей концентрацией данных.
О качестве самоорганизации свидетельствует равномерное распределение
нейронов в пространстве при отображении равномерного распределения
обучающих данных.

239

9 3. Сеть восстановления одно- и двухмернььх данных

мдгёё „Зшммьооо дм „МЁЕАФ ымшщчёодпдп Ё „ыцъьшд. ИЫЩЁОЫЪФЕ Ё „мёд. ымиооЁЁ=Ёо Ё
„ЁЁмц „Ёшаовкиыц Ещшшопоцоапомц ошаывошшыц «потоках 03.50 НЕЩФЦШОЩФНОООЩ ЁЁЕЬЕЁ .т.а ‚они

З Ё мы Ё Ё «в

  

мб 8. е ‘б 93. мб „Ё Чмб

ьб 86 об ююб юб Её ‘б 86 тб „Ё

86

ююб

36
„ в 6

 

 

8 ‚о

240 9. Сети с самоорганизации? на основе конёёш

8) 1
0, 8
0,6

0,4

 
    

0 0,2 0,4 0,6 0,8 00 0,2 0,4 0,6 0,8

Рис. 9.6. Иллюстрация последовательности обучения самоорганизуюшейся сети
Кохонена при использовании алгоритма нейронного газа

   

а) 0,7 а) 0,в
0,6
0,0
0,5
0,4
0,4
0,з
0,2 0,2 —’
0,2 0,4 0,з 0,в 0,2 0,4 0,6 0,0

0,8
0.6
0,4

0,2

 

0

 

0 0,5 1

Рис. 9.7. Восстановление сложных кривых самоорганизуюпшмися нейронами Кохонена

а 4. Восстановление Саммона 241

 

Также хорошие результаты получаются при восстановлении самоор-
‘зиизующейся сетью одномерных данных. На рис. 9.6 для примера проил-
вострирован процесс самоорганизации 40 нейронов, отображающих
цлипсовидную структуру (позиции нейронов обозначены окружностями).
’вс. 9.6а представляет начальное состояние весов нейронов, рис. 9.66 — состояние

юсле двух циклов обучения, рис. 9.6в - состояние после пяти циклов
гбучения, рис. 9.62 - конечное состояние (после десяти циклов) весов
в: фоне обучающих данных, образующих эллипсовидную структуру. Сеть
гбучалась программой КоИоп по алгоритму нейронного газа. На рис. 9.7
шриведены результаты упорядочения нейронов ‘при восстановлении
фигур различной структуры, образованных данными на плоскости (х, у). В
каждом случае веса нейронов группировались в областях присутствия
данных таким образом, чтобы погрешность квантования была мини-
нальной.

Главное достоинство сетей с самоорганизацией становится заметным
только при обработке многомерных данных, пространственное размещение
поторых человек уже не в состоянии себе представить. Механизмы
гамоорганизации, встроенные в алгоритмы обучения таких сетей,
функционируют независимо от размерности задачи. Важнейшая функция,
реализуемая при этом сетью, —- векторное квантование, состоящее в том,
‘по огромное количество данных, образующих кластер, отображается вектором
весов нейрона, представляющего центр кластера. Поэтому пространственное
размещение нейронов позволяет определить зоны концентрации данных в
иногомерном пространстве и основные характеристики их распределения,
существенные с точки зрения пользователя.

9.4. Восстановление Сэммона

При обработке многомерных данных возникает задача такой графической
визуализации расположения нейронов, которая была бы четкой и понятной для
пользователя. Это предполагает проекцию распределения данных из
иногомерного пространства в двух- или в крайнем случае трехмерное
пространство при сохранении основных характеристик распределения в много-
мерном пространстве.

Пусть имеется п Н-мерных векторов х; (1 = 1, 2, ..., п). В соответствии
с ними определяются п векторов в М-мерном пространстве (М = 2, 3),
обозначаемых уд. Расстояния между векторами в Н-мерном пространстве
будем обозначать ф; =(у;, И), а в Ммерном пространстве ф; = (уд, И). Для
определения расстояния между векторами можно использовать'_ любую
метрику, в частности эвклидову. Задача’ нелинейного восстановления
Сэммона состоит в таком подборе векторов у, чтобы минимизировать функцию

16-2162

242 ' ЯСети с самоо ганиз ей на основе кон ёнции

 

погрешности Е, определяемую по формуле

1 „ и‘; — М
Е = - 24%- , (923)
С к; да
ГДЕ
с= и 41% ‚ (914)

М 2
д„= Шугум ‚ (915)
1с=1

а уд обозначает 1-й компонент вектора уд.
Для минимизации функции погрешности Е Сэммон применил метод
минимизации Ньютона, упрощенный до вида

Ур‹1(]‹+1) = ‚Ура — ЦАРЧОФ’ (916)
где дЕ
А (д) = э}; (9 27)
И 3215 ’
дУЁ

представляет частное от деления соответствующего компонента градиента на
диагональный элемент гессиана, определенный на 1с-й итерации. Коэффициент ц
аналогичен константе обучения, выбираемой из интервала [0,3, 0,4]. При
определении функции погрешности в виде (9.23) соответствующие компоненты
градиента и гессиана описываются выражениями:

дЕ 2 " "Ё; —дп'

____ 1 _ _
душ „дар думу [ут у‚‚,1, (923)
1 п
дръ; 2 _1 х
душ с Йдя/‘Ч’ ‘(Иди
_ _ . 1 дЁ-д.
›‹ ‹а„—а„‚)—9д“%д1— н-дд-Ё . (929)
р! И

9.5. Применение сетей с самоорганизацией

Главным свойством сети Кохонена считается компрессия данных, состоящая в
том, что образующие кластер большие группы данных представляются
единственным вектором весов нейрона-победителя. При разделении р данных иа
Р кластеров и представлении каждого кластера одним из п нейронов достигается
значительное сокращение количества информации, которое и называется

1 5 Применение сетей с самоорганизацией 243

 

юмпрессией. Это компрессия с потерями, которая сопровождается определенной
грешностью квантования, описываемой зависимостью (9.13).

9.5.1. Компрессия данных "

Примером использования компрессионных свойств сети Кохонена может
считаться сжатие изображений, предназначенное для уменьшения количества
информации, представляющей конкретный образ, при сохранении погрешности
восстановления на заданном уровне (обеспечении достаточно большого значения
юэффициента РЗЫК).

Предположим, что изображение размером Нххду пикселов разделяется на
одинаковые кадры размером пххпу пикселов. Образующие кадр пикселы
представляют собой компоненты входных векторов х. Каждый вектор состоит из
щхпу компонентов, определяющих интенсивность конкретного пиксела в кадре.
Соотнесение пикселам вектора может проводиться либо объединением
соответствующих строк кадра в единую последовательность, либо растровым
способом. Сеть с самоорганизацией содержит п нейронов, каждый из которых
связан синаптическими дутами со всеми компонентами входного вектора х.
Обучение сети при помощи одного из алгоритмов самоорганизации состоит в
подборе таких весов конкретных нейронов, при которых минимизируется
погрешность квантования (9.13). В результате обучения формируется структура
сети, при которой вектору х каждого кадра соответствует вектор весов нейрона-
победителя. При аналогичных структурах вектора х для разных кадров побеждать
будет один и тот же нейрон либо их группа с похожими векгорами весов. В
процессе предъявления очередного кадра выбирается номер нейрона-победителя,
например, 1, 1, 3, 80 и т.д. Номера нейронов-победителей образуют кодовую
таблицу, а веса зггих нейронов представляют средние значения, соответствующие
конкретным компонентам вектора х (т.е. уровням интенсивности пикселов,
составляющих кадр). Если принять во внимание, что количество нейронов п
обычно намного меньше количества кадров М, то можно получить существенное
сокращение объема информации, описывающей исходное изображение. При
определении степени компрессии следует учитывать также и конечное число
битов, необходнмых для кодирования номеров нейронов-победителей конк-
ретного кадра. В итоге коэффициент компрессии изображения определяется в

виде [46, 114]

м т
 "  к = ’"""’ , (930)

1
П7132 п + ппхпуг

 

где п, и п, обозначают размеры кадра в осях х и у, Н, — количество кадров;
п —- количество нейронов, а Т и 1 - количество битов, используемых для
представления соответственно градаций интенсивности пиксела и значений
весов. Этот подход позволяет получить степень компрессии изображений
порядка 16 при значениях коэффициента РЗЫК около 26-28 дБ.

|б"

244 9. Сети с самоорганизации? на основе канкшентв

На рис. 9.8а представлены результаты обучения сети Кохонена для образа
“Барбара” размером 512 х 512 пикселов, разделенного на 16-элементные кадры
(4 х 4 пиксела). Сеть Кохонена состояла из 512 нейронов. При 8—битовои
представлении данных достигнута степень компрессии К, а 9.8. На рис. 9.5’
приведено изображение, восстановленное по весам нейронов, побеждавших пр
предъявлении очередных кадров. Коэффициент РЗЫК для восстановленног
изображения составил 26,2 дБ. Различия в качестве оригинального (рис. 9.8а) ‚
восстановленного (рис. 9.8@ изображений относительно невелики. Это замегн
на рис. 9.8в, представляющего собой графическую интерпретацию погрешносъ
в виде разности между оригинальным и восстановленным после компресснэ»
изображениями.

Рис. 9.8. Образ “Барбара”, использованный для компрессии сетью Кохонена:
а) оригинальное изображение; б) восстановленное изображение; в) разностное
изображение

Важнейшее свойство нейронных сетей, со всей очевидностью проявляющееся
при компрессии изображений, —- это способность к обобщению и, следовательно.
возможность сжатия (путем сопоставления отдельным кадрам нового образа в

9. 5. Применение сетей с самоорганизации? , 245

 

виде номеров нейронов-победителей, входящих в натренированную ранее сеть)
и декомпрессии (сопоставления векторов весов нейронов-победнтелей
соответствующим кадрам) информации. Качество восстановленного изобра—
жения, которое не использовалось ранее для обучения, не сильно отличается от
качества образа, участвовавшего в обучении, при условии, что степень сложности
обоих изображений примерно одинакова. Для примера на рис. 9.9 представлено
изображение папиллярных линий, подвергнутое сжатию и декомпрессии с
помощью сети Кохонена, натренированной на изображении, приведенном на
рис. 9.8. Рисунок 9.9а —- это оригинальное изображение, рис. 9.96 —- образ,
восстановленный после сжатия, а рис. 9.9в иллюстрирует погрешность
декомпрессии. Степень искажения восстановленного изображения сопоста-
вима с искажением образа, на котором проводилось обучение сети, а
коэффициент искажения РЗЫК г 26,4 дБ.

‚— '.' . ›— .‹‚' `.._’.‹.‘__ ›1”`\; ‚н‘

Рис. 9.9. Изображение папиллярньтх линий, использованных для тестирования сети
Кохонена при сжатии данных: а) оригинальное изображение; б) восстановленное
изображение; в) разностное изображение

246 „ш д п" ‚ _ 9. Сети с самоорганизаиией на основе конжентш
9.5.2. Диагностирование неисправностей оборудования

Сети с самоорганизацией также находят применение для диагностирования
неисправностей различного оборудования. При этом используется их
способность к компрессии, те. к представлению множества точек вектором весов
единственного нейрона. Множество контрольных точек устройства, в которых
снимаются его характеристики в различных режимах работы, может считаться
вектором х (каждый вектор соответствует определенному режиму работы),
подаваемым на вход сети. В зависимости от условий работы, вида неисправного
элемента и степени повреждения получаются различные характеристики одного и
того же устройства. Как правило, неисправность каждого вида связана со
специфическим изменением характеристик устройства, свойственным только

этой неисправности. Нейрон, побеждающий в конкуренции при определенной
комбинации характеристик устройства, представляет впоследствии либо
нормальный режим работы, либо определенную неисправность, позволяя тем
самым локализовать ее. Типовая схема обнаружения неисправностей пред-
ставлена на рис. 9.10. База данных состоит из множества характеристик.

Кохонена 

База данных Победитель

  

Нормальное
состояние

        
 

Ребочее состояние
устройства

Рис. 9.10. Схема применения сети Кохонена для обнаружения неисправностей в системе

отвечающих различным нормальным и аварийным состояниям в определенных
режимах работы, в которых, как правило, устройство подвергается
диагностированию. Главное условие корректного функциоштрования системы -
дифференциация характеристик при различных аварийных состояниях. Если две
разные аварии имеют идентичные признаки, их различение будет невозможным.
Подготовка соответствующей базы данных, по которой будет проводиться

 обучение, а в последующем эксплуатация сети (собственно диагностирование

неисправностей) требуют проведения таких измерений, которые будут
однозначно свидетельствовать о фактическом состоянии устройства. При этом
следует выделять те фрагменты характеристик, которые отличаются друг от

Б 5 Применение сетей с самоорганизации? 247

 

фут. Для достижения этой цели могут выполняться любые операции (как
швейные, так и нелинейные) на всей базе данных. Подобный подход был
реализован для диагностирования типовых неисправностей, возникающих в
силовых электрических трансформаторах на основе измерений характеристик
дтводимости |у | =/(“‚„‹)-

В работах [121, 125] рассмотрен пример использования сети Кохонена для
диагностирования неисправностей активного электрического фильтра КС на
основе частотной характеристики двух функций цепи: падения напряжения и
входной проводимости. Сеть, обученная на характеристиках идеальных
состояний короткого замыкания и разрыва цепи, оказалась способной определять
неисправности при частичных повреждениях (например, значение сопро-
тивления, равное 10% номинала, распознавалось как короткое замыкание).

Способность сети Кохонена активизировать единственный нейрон,
ответственный за целый кластер данных, можно использовать для локализации
поврежденного элемента независимо от состояния остальных. Для примера про-
демонстрируем применение сети для диагностирования коротких замыканий в
линиях электропередач на основе измерений амплитуды напряжения в
определенных точках этой линии [125]. Предполагается, что доступно посек-
ционное измерение напряжения. В этом случае можно определить место аварии
с точностью до секции.

Входная информация для сети — это векторы измеренных напряжений. Номер
акгивизированного нейрона указывает на локализацию короткого замыкания. Для
линии, на которой доступно большое количество контрольных точек, во

НОРМЗЛЦЗОЗЭНН ЫЭ СЭКЦЦОННЫЭ НЭПРЯЖЭНЦЯ

 

Номер секции

Рис. 9.11. Примерные нормализованные характеристики линии электропередач при
различных ЗЗМЬККЗНИЯХ В СИСТСМС

„Ч

 

248    ‚   ‚‚ 9.Сетиссамоа аниз

входных векторах можно ограничиться информацией об амплитуде измеренных
напряжений, причем условием корректного функционирования системы
считается как можно большее различие входных векторов, соответствующих
разным аварийным ситуациям. Для проявления эти‘х различий применяются
многочисленные приемы предварительной обработки измерительных данных,
отдаляющие эти векторы друг от друга. Из аналнза снятой с линий
электропередач измерительной информации следует, что эффективным решением
может считаться нормализация истинных значений напряжения в контрольных
точках, отражающая только разницу между напряжениями в соседних секциях.
В работе [125] предложено проводить нормализацию согласно формуле

х, =ЩЩ1 , (931)
Е

где у; обозначает измерение в контрольной точке 1-й секции, а Е - входное
напряжение линии. На рис. 9.11 представлены характеристики распределения
нормализованных таким образом измеренных значений для шести секций линии
при трех различных закорачивающих резисторах, включенных в узловых точках
секций. Они образуют обучающие векторы для сети Кохонена, использован-
ной при решении задачи. Исследовалась секционная модель кабельной
линии со следующими параметрами на 1 км длины: К = 70 (2, Ь = 80 тН.
С = 47 пР, С = 0,01 3. Эксперименты проводились для частоты 3825 Гц с
возможностью неполного закорачивания в секциях (путем подключения к
соответствующим участкам линии резистора с сопротивлением от 0 (2 при
идеальном коротком замыкании до 1/3 значения модуля волновой импедант-
ности). При исследовании замыканий (одиночных) предполагалась относи-
тельная нечувствительность к ним (до 10%) значений других характеристик
неповрежденных элементов линии. Анализ характеристик линии при изменении
сопротивления перемычки свидетельствует о близости (в пространстве парамет-
ров) точек, соответствующих нормализованным характеристикам аварий одного
типа, труппирующихся в виде кластеров. Они с успехом могут представляться
одиночными нейронами Кохонена либо выходными нейронами персептронной
сети. Оба метода проверялись в работе [125], показавшей высокую эффек-
тивность их применения для локализации места замыкания. При 10%-ной
нечувствительности неповрежденных элементов 100%-ная результативность
диагностирования и локализации замыкания обеспечивается обеими сетями при
сопротивлении перемычки, доходящем до 0,2 значения волновой импедант-
ности. При большей неидеальности замыкания (до 0,4 значения волновой
импедантности) эффективность диагностирования начинает изменяться. При
10%-ной нечувствительности неповрежденных элементов обеспечивается
98%-ная результативность локализации места замыкания многослойным
персептроном и только 85%-ная —— сетью Кохонена. Причина этого скорее всего
кроется в существенной нечеткости признаков замыкания, связанных с его
неидеальностью, поэтому обучение с учителем, которому подвергается
многослойный персептрон, дает лучшие результаты.

 

249

9 ‹ Применегшгоетей с самоорганизацией ‚

9.5.3. Краткосрочное прогнозирование нагрузок
энергетической системы

Сеть с самоорганизацией также с успехом может использоваться для прогно-
зирования, например, нагрузок в элекгроэнергетической системе. В настоящем
подразделе будут представлены подробности решения задачи прогнозирования
часовых нагрузок в элекгроэнергетической системе на 24-часовом интервале.
Использованный подход во многом совпадает с методикой распознавания
образов, представленной в предыдущих подразделах. Сеть обучается
распознавать параметры часовых нагрузок, характерные для различных дней
года. В разделе 4 было показано, что каждый день года имеет свою
специфику распределения часовых нагрузок, которая от года к году меняется
лишь в незначительной степени. Некоторые дни, относящиеся к одной
поре года и имеющие один и тот же тип, различаются минимально. В
многомерном пространстве они образуют компактные группы данных,
каждая из которых может отображаться весами единственного нейрона-
победителя. Чтобы отстроиться от определенного общего тренда,
обусловленного ежегодным промышленным ростом страны, принимаются
во внимание только переменные части характеристик, остающиеся после
вычитания среднего значения. Если обозначить среднее значение нагрузки
системы в 1-й день Р‚„(1), а его вариацию - о (1), то можно определить часовой
профиль ]-го дня в виде

_  ‚ (932)

для 11= 1, 2, ..., 24, где Р(],11) обозначает фактический отбор мощности в
элекгроэнергетической системе в И-й час ]-го дня. Значения р(],11) состав-
ляют вектор профильных нагрузок дня, р; = [р(], 1), р(/, 2), ..., р(], 24)]. За
начальную точку отсчета времени можно выбрать часы с наиболее стабильной
нагрузкой в масштабах всего года. Это, как правило, ночное время
(между 3 и 5 часами). В этом случае компонент р(], 1) будет соответ-
ствовать действительной нагрузке в первый час этого интервала, р(/, 2) - во
второй час и т.д. Для каждого дня года, представленного в базе данных, форми-
руется профильный вектор в соответствии с формулой (9.32). Для уменьшения
влияния случайных нагрузок база данных должна охватывать несколько
последних лет. Множество профильных векторов подается на вход сети
Кохонена, состоящей из п нейронов. Процесс самоорганизации сети
приводит к автоматической кластеризации данных и к сопоставлению
каждому кластеру одного из нейронов сети. Этот нейрон считается
победителем, а его веса наилучшим образом адаптируются к усредненным
весам профильных векторов, составляющих кластер. Характерная особенность
состоит в том, что соседние векторы имеют сходные профильные характе-
ристики.

250 9. Сети с самоорганизацией на основе кон%ен!ш.

Близость весов нейронов, расположенных недалеко друг от друга, легкс
объяснить, если принять во внимание механизм соседства в алгоритма‘
самоорганизации. Это означает, что один и тот же день в разные годы пр;-
небольших отличиях в часовых нагрузках может возбуждать различные нейроны.
расположенные недалеко друг от друга и образующие своего рода кластеры.
группирующие данные сходных классов. Если нанести веса нейронов на
плоскость (х, у) и приписать каждому из них виды дней, в которые они
становились победителями, можно наглядно выделить обширные области.
характерные для праздничных и для рабочих дней. Это подтверждает известный
в энергетике факт подобия профилей нагрузок для рабочих дней и близости
профилей для праздничных дней.

Знание таблицы распределения побед конкретных нейронов сети позволяет
относительно легко предвидеть профили часовых нагрузок для произ-
вольного дня года. С этой целью создаются таблицы принадлежности каждого дня
года к области доминирования определенного нейрона с обозначением количества
его побед для всех дней в прошлом. Для примера в табл. 9.1 представлены
данные, касающиеся июльских вторников на протяжении последних пяти
лет (для моделирования использовалось 100 нейронов, упорядоченных в
табл. 10 х 10).

Таблица 9.1
Распределение побед нейронов при прогнозе
нагрузок в нюльскне вторннкн

В

Вторник 34
35
43
44

Вторник
Вторник
Вторник
Для выбора прогнозируемого профиля нагрузок актуального дня (например.
вторника) в требуемом месяце (например, в июле) рассчитываются усредненннс
значения весов нейронов-победителей, которые указывали в прошлом на
требуемый день. Если количество побед Е-го нейрона, соответствующее ]-му дню.
обозначить 19„ а соответствующие векторы весов класса — щ, то прогнозн-
руемый профильный вектор ]-го дня рассчитывается по формуле

   
          
   

И
Хаки”:
А _ Е= ‘
И—Т—-— ‚ (9.33‘
2,9‘
1=
где Ку; = О, если соответствующий нейрон никогда не побеждал в данной
классификации. На рис. 9.12 в качестве примера представлены профильные
характеристики, полученные этим методом для четырех дней: 18.02.1994.

251

моЁоы: | ЁЁЦ ёшыкгЁЁ .ы==8‚м=„ ояыыогёме
| ц==== ёщёоппо „ЁЁ «БЁ „Ёшшмцюм: 53 1=20НО=0 що„_„бг=но‚_цо=„ щомоЁоП „БЁЁЁ шоёеоа: Ёыноёцоёзцмх ‚ыйа ‚З-щ

„ы 8 г Э щ ь а Я В Э щ а

Е .„

. а:
. „ч.

 
 

3..2...“ Ъ? ‚чоыйнп . Ъ?

.. Е;

..... .. ФЁ

 8..
. 3

й С СЦМООРЗДНИЗПЦИСИ

.....%..::.. .:..... щеь“
.  ЁП

 

9‚ 5. Применение сете

ёыьё ъ?

 

252 9. Сетйс самошацией" на основе шкаф Е

15.05.1994, 31.12.1994 и 24.12.1994. Сплошная линия соответствует фактичес-
ким значениям, а пунктирная — прогнозу. Для типичных дней эти кривые с
высокой точностью совпадают (два верхних трафика). Значительные отличия
наблюдаются для нетипичных дней, например последнего дня года и Сочельника‘
(два нижних трафика). Обычная методика применения сети Кохонена в таких
случаях оказывается недостаточной. Возникает необходимость введения для
особенного дня отдельной категории, по которой прогноз строится на основе
таких же дней в прошлом.

После определения профильного вектора фактические нагрузки, соот-
ветствующие конкретным часам данного дня, рассчитываются на основе
формулы (9.32) как

ё“) = «(да +Р„‚(;) . ь (934)

Комплексный прогноз нагрузок требует дополнительного предсказания сред-
него значения и вариации для каждого дня, на который этот прогноз составляется.
Такое предсказание может быть выполнено с использованием статистического
анализа прошлых средних значений и их вариаций либо путем применения
специальной персептронной сети, обученной решению только згтой задачи (см.
раздел 4).

Благодаря использованию для предсказания средних значений и их вариаций
отлаженной нейронной технологии, реализованной в корректно спроектирован-
ной и обученной сети с самоорганизацией, стало возможным обеспечить в
польских условиях точность прогнозирования нагрузок, характеризующуюся
погрешностью МАРЕ порядка 2,5%.

9.6. Гибридная сеть

Главная особенность сети с самоорганизацией на основе конкуренции — это очень
высокая скорость обучения, многократно большая, чем у сетей, тренируемых с
учителем. Их недостатком считается сложность отображения пар обучающих
данных (х, а’), поскольку сеть с самоорганизацией, выполняющая обработку
только входного вектора х, не обладает свойствами хорошего аппроксиматора.
присущими многослойному персептрону или радиальной сети КВР. Очень
хорошие результаты удается получить при объединении самоорганизующегося
слоя и персептронной сети, что позволяет совместить способности сети Кохонена
к локализации и возможности аппроксимации, свойственные многослойному
персептрону Подобная структура, которая в последующем будет называться
гибридной сетью, изображена на рис. 9.13. Она представляет собой каскадное
подключение слоя Кохонена и персептронной сети (часто оказывается доста-

точным один персептронный слой). Самоорганизующийся слой улавливает

1 В католической Польше Рождество Христово отмечается 25 декабря — Примеч. перец

9.6. Гибридкая сеть р а 253

 

значимые признаки процесса (локализует их на основе входных данных х), после
чего им приписывается входной вектор в персептронном слое. Вследствие
хорошей локализации признаков процесса первым слоем сети в большинстве
приложений бывает достаточным применение персептрона, содержащего только
один слой нейронов (зачастую линейных). Обучение гибридной сети состоит из
двух отдельных этапов, следующих друг за другом.

Слой Кохонена Персептронный слой

 

Рис. 9.13. Структура гибридной сети

Вначале на множестве входных векторов х обучается слой Кохонена. В резуль-
тате нейроны этого слоя организуются таким образом, что векторы их весов
наилучшим образом (с минимальной потрешностью квантования) отобра-
жают распределение данных обучающих векторов х. Тренинг слоя Кохонена
проводится по одному из реализованных в программе КоИоп алгоритмов
обучения сети с самоорганизацией (например, нейронного газа или ЩТА с
механизмом учета усталости), По завершении обучения слоя Кохонена веса
его нейронов эаморажийаются и проводится анализ их выходных сигналов
при подаче на вход сети последовательности сигналов х из обучающего
множества. Победитель (нейрон с наибольшим значением суммарного
сигнала итш) переводится в единичное состояние, а остальным нейронам
приписываются состояния из интервала (0—1). Переход от фактических
суммарных сигналов и; этих нейронов к выходным нормализованным
сигналам может проводиться по различным формулам. Опыт показывает, что
хорошие результаты можно получить с использованием выражения

у; = ехр (————‘ТШ—), (9.35)

при значениях о’, индивидуально подбираемых для каждой решаемой задачи.

254 9. Сети с самоо " на основе конШЁши

’ Персептронная сеть обучается с учителем по завершении тренинга
самоорганизующегося слоя. Обучающими сигналами для нее является
множество пар (уд, ф), где у; - это вектор, составленный из выходных сигналов
нейронов слоя Кохонена, а 11; - вектор ожидаемых значений оригинального
отображения (хд, ф), которому соответствует вектор уд. Сеть обучается как по
алгоритму обратного распространения, так и градиентным методом (прог-
рамма ПепеасИ применяется так же, как и для обычной персептронной сети).
Процесс обучения в этом случае может протекать во много раз быстрее, чем
для одиночной персептронной сети, благодаря хорошей локализации данных,
обеспеченной первым слоем Кохонена. Это особенно заметно на сети с одним
персептронным слоем. Если принять во внимание, что каждому возбуждению
х соответствует конкретный доминирующий нейрон (победитель), то можно
осуществить предварительную инициализацию весов персептронного слоя
таким образом, что значения весов, соединяющих нейрон-победитель с
выходными нейронами гибридной сети, будут усредняться по тем векторам д,
на которых были одержаны победы. При такой предварительной
инициализации весов обучение персептронного слоя сводится к незначи-
тельной корректировке их значений, отражающей влияние проигравших
нейронов Кохонена на окончательный результат. Эта корректировка, как
правило, требует небольшого количества итераций и ведет к достижению
глобального минимума функции погрешности.

Следует отметить, что представленная гибридная сеть может считаться
обобщением сети обратного распространения Хехта-Нильсена [50, 113, 118]. В
отличие от нее в гибридной сети допускается дробная активность нейронов в
слое Кохонена от значения 1 для победителя до 0 5 у; < 1 для остальных нейронов.
Активность нейронов, проигравших в коъшурентной борьбе, рассчитывается
согласно формуле (9.35). Учет активности многих нейронов при функ-
ционировании персептронной сети позволяет лучше локализовать вектор х в
многомерном пространстве и получить лучшее отображение данных нейронной

сетью в целом.

Это оригинальное свойство гибридной сети может иметь различные
практические приложения. Например, ее применение для предсказания
профилей нагрузок в электроэнергетической системе позволило значительно
уменьшить как погрешность МАРЕ, так и максимальную погрешность самого
прогноза.

В табл. 9.2 приведены результаты сравнения точности прогиозов
нагрузок для Польской электроэнергетической системы, полученных на основе
классической сети Кохонена и гибридной сети [124]. Во втором случае
результаты бьши получены при подкреплении прогнозирования персепт-
ронной сетью на этапе расчета средних значений и их вариаций, исполь-
зуемых в формуле (934). Из приведенных данных следует, что гибридная сеть
позволила уменьшить как погрешность МАРЕ, так и максимальную погрешность
прогноза.

9.6. Гибридная сеть —‹ „ 255

 

Таблица 9.2
Погрешности МАРЕ и МАХ прогноза нагрузок при
использовании сети Кохонена и гибридной сети

-
2о‚о2% 17,19%
21,о7% 1в,1в%
19‚79% 14‚оз%
2о‚оз% 14,9з%
1в,з5% 1з,97%

     
    
    
  
   

     
   
 
 
 

   
 
 

Хорошие результаты получаются при применении гибридной сети для
анализа состава газовых смесей и оценивания концентрации отдельных
компонентов по показаниям полупроводниковых датчиков (так называемый
искусственный нос) [118]. Полупроводниковые датчики характеризуются
относительно слабой селекгивностью; они в разной степени реагируют на
присутствие в смеси различных газов. В технических решениях применяются
матрицы датчиков, по-разному реагирующих на присутствие конкретного газа. В
этой ситуации задача нейронной сети состояла в калибровке прибора, т.е. в

   
   

‘Ч Газ 1 ’—- Газ 2

ё‘ ё

Ё А

ё ё

Ё — 8

51 Е

_‚ . . . в . .

Ё 0 5 10 15 20 Ё 0 5 10 15 20
< Тестовые выборки <

‘Ё Газ З ‘Ё

" ‘Б

ё з

Ё 2

а ё

„ %

Е Ё

я . . 9 . . .

ё 0 5 10 15 20 Ё 0 5 10 15 20
‘д Тестовые выборки Ч Тестовые выборки

Рис. 9.14. Сопоставление абсолютных погрешностей оценки состава смесей из
четырех газов (количество измерений равно 20), полученных в результате
применения гибридной сети

256 9. Сети с самоорганизашей на основе конттниии

сопоставлении показаниям каждого датчика соответствующих значений
концентрации конкретных компонентов газовой смеси. Для достижения
поставленной цели была создана гибридная нейронная сеть, в которой слой
Кохонена определял тип газовых компонентов, а персептронный слой оцеъшвал
их концентрацию.

На рис. 9.14 представлены графики погрешностей оценок присутствия
четырех газов (в ррш): углекислого газа, метана, метанола и пропана/бутана,
полученных при использовании гибридной нейронной сети [118]. Обучение сети
проводилось на 400 обучающих выборках, а ее тестирование - на 20 других
выборках.

Максимальная погрешность для тестовых примеров не превышала 12 ррт, а
средняя абсолютная погрешность оставалась на уровне 2,59 ррт. На рис. 9.15
представлены графики относительных погрешностей оценок по 20 тестовым

   

Газ 1 Г а: 2
8
6 С
4 
2  ‘
о . — -  _ _ _ ' __ '
| || В | '
-2
" 0 5 10 15 20 0 5 10 15 20
Тестоаые выборки Тестовые выборки
Г а: З Г а: 4

 

0 5 10 15 20
Тестовые выборки

 

Относительная погрешность (96) Относительнея погрешность ( Х)
Относительная погрешность (96) Относительная погрешность (96)

Тестовые выборки

Рис. 9.15. Сопоставление относительных погрешностей оценки состава смесей из
четырех газов (количество измерений равно 20), полученных в результате применения
гибридной сети

выборкам, соответствующие результатам, представленным на рис. 9.14. Значение
максимальной относительной погрешности не превысило 7%, а абсолютное
среднее значение относительной погрешности распознавания всех компонентов
исследованных газовых смесей составило 0,78%.

Раздел 1 0

СЕТИ С САМООРГАНИЗАЦИЕЙ
КОРРЕЛЯЦИОННОГО ТИПА

Другой важный класс сетей с самоорганизацией составляют сети, в процессе
обучения которых используется информация о зависимостях между сигналами.
Эти сети называются корреляционными, или хеббовскшии. В процессе обучения
они выявляют значимые корреляционные зависимости между сигналами,
подстраиваясь под них путем адаптации значений синаптических весов.

В этом разделе будут обсуждаться различные аспекты самоорганизации на
основе обобщенных правил Хебба. Мы представим два вида хеббовских сетей:
сеть, выполняющую декомпозицию данных по главным компонентам,
называемую сетью РСА (англ.: Ргёпсфа! Сотропеп! АпаЬ/вйз - анализ главных
компонентов), и сеть, декомпозирующую обучающие данные на независимые
компоненты, называемую сетью [СА (англ.: [пдерепдепг Сотропет‘ Апа1у$1$ -
анализ независимых компонентов) Обе сети по своей природе линейны (линейны
как сами нейроны, так и межнейронные связи), хотя алгоритмы обучения имеют

нелинейный характер.

10.1. Энергетическая функция
корреляционных сетей

Применение основного правила Хебба связано с использованием модели
линейного нейрона, в соответствии с которой выходной сигнал у; нейрона равен
взвешенной сумме входных сигналов:

Н
и = Ещщ . (10.1)

Ё=О

В этой модели используется вектор х = [х‹‚, хд, ..., хм], дополненный нулевым
компонентом хо = 1, обозначающим поляризацию. В соответствии с постулатом
Хебба изменение веса нейрона после предъявления вектора х производится по

формуле

Мд =п(у‚ —‘у$°’)("‚; #53’) , (102)

17-2162

258 10. Сети с самооеганизацией ковееляиионного типа

где хр), у?) являются определенными константами, а п — коэффициент обучения.
С учетом всего множества обучающих выборок изменение значений весов сети во
времени может быть выражено обобщенной формулой [46]
дил А" д; А"
11‘ _ 4

ф, — Ешдстк +Ё1+ Ы ЕИд ‚ (103)
в которой Кд и К; — это определенные константы, связанные с хдф), уЁО) и с п,
тогда как Сдд — это усредненная ковариация активности 1-го и К-го нейронов,
определяемая в виде

с‚‚‹=1>'й(›ё"—›ч)(›‹‚ё"—г‚)‚ «о.»
1’ 1=1

Константой Е; обозначено усредненное значение входных выборок по Я-му

_ _ Р
компоненту усредненного вектора х, где х = Ё): ха‘). Если принять, что из-
1с=1

менетшя весов производятся в соответствии с правилом максимального умень-
шения значения энергетической функции Е сети, получаем
дЕ _е1ш]‚‚ и [И и

„к, „‚‚  «О»
1 |= 1=

После решения этого дифференциального уравнения получаем энергети-
ческую функцию в виде [46]

Е= Е‚‚ + Ед, (106)
Где
1 и Ы
Е» =“'ЗЕЬЗИ;:СЖИИ ‚ (10-7)
Е ——1с%и’ -& Ёи’ 2 1
‚с 11=1 Л 217 1=1 Л ц (0-8‘

.Энергетическая функция содержит два слагаемых: Е‚‚ и Ед. Первый
элемент определяет вариацию о? активности ]-го нейрона; так каъ

П 17
2 ___ __ — 2 _
о’ ‚ —‹(у‚ у) ›—ЕёшдСдш] . Второе слагаемое можно отождествить со
штрафной компонентой энергетической функции, иначе называемой в теории

оптимизации стоимостной или целевой функцией. При зафиксированны‘
значениях весов функция Е будет принимать минимальные значения тогда, КОГД;
вариация 012 будет максимальной. В связи с этим обучение по Хеббу приводит ь
такой организации нейронов (подбором их весов), которая максимизируе:

102. Нет‘ онные сети РСА 259

вариацию активности нейронов при определенном ограничении значений их
весов. Поскольку в общем случае эти весовые ограничения не уточняются,
ФУНКЦИЯ МОЖЕТ ИМЕТЬ НЕСКОЛЬКО ЛОКЗЛЬНЫХ МЗКСИМУМОВ.

10.2. Нейронные сети РСА

10.2.1. Математическое введение

Анализ главных компонентов (РСА) - это статистический метод, определяющий
линейное преобразование у = ЧУх. Оно трансформирует описание стационарного
стохастического процесса, представленного вектором хе К”, в вектор уе КК
посредством матрицы УУе ККХ” при К <1\/ таким образом, что выходное
пространство редуцированного размера сохраняет наиболее важную информацию
об исходном процессе. Другими словами, преобразование по методу РСА
позволяет заменить большое количество информации, основанной на взаимно
коррелирующих входных данных, множеством статистически независимых
компонентов с учетом их важности. Поэтому оно считается одной из форм
компрессии с потерей информации, известной в теории связи как преобразование
Карьюнена-Лёве [29‚ 82].

Пусть х =[х1, х2, ..., х„]Т обозначает случайный вектор с нулевым средним
значением, а В„=Е[ххТ]=‹ххТ› обозначает ожидаемое (среднее) значение

матрицы автокорреляции по всем векторам х. Эту матрицу при конечном
количестве р векторов х можно описать зависимостью

1 Ё т 1 т
Р ’‹=1 Р
где матрица данных Х образована последовательностью обучающих векторов
Х= [х1,х;, ...,хр].
Обозначим Я; собственные значения матрицы автокорреляции Кхх, а и’; -
сопряженные с ними ортогональные векторы собственных значений, где
и’; = [шт шд, ..., ш;„]Т. Собственные значения и собственные векторы связаны

ЗНВИСИМОСТЬЮ
К,“ Ю1=Й; „д, (1010)

где 1= 1, 2, ..., П. Собственные значения симметричной неотрицательной мат-
рицы корреляции являются рациональными и неотрицательными. Упорядочим их
в порядке убывания: М > Ж; >  > М: 2 0. В аналогичной последовательности
расположим собственные векторы щ, сопряженные с Д. Если ограничиться К
максимальными собственными значениями, матрица Ж’ преобразования РСА
может быть определена в форме 95’ = [юь шд, ..., юК]Т, при УУе ККХ”. Эта матрица
определяет преобразование РСА как линейное преобразование

у=\’\’х. (1О.11)
17’

260 10 Сети с сам  тршоннаго там

Вектор у = [уд, у2, ..., уК]Т представляет собой вектор главных компонентов
РСА, имеющих наибольшее влияние на реконструкцию вектора данных
х = [х1, хд, ..., х„]7'.

Таким образом, преобразование РСА тесно связано с разложением матрицы
корреляции в соответствии с собственными значениями. Если обозначить 1.
диагональную матрицу, сформированную из использованных в отображении
собственных значений Яд, т.е. Ь = [ЛЬ 12, ..., ЯК], то матрицу корреляции можно
представить в виде следующей декомпозиции: _

в,“ = тТтм‘. 00.12)

С позиций статистики преобразование РСА определяет множество К
ортогональных векторов (строк матрицы И’), имеющих наибольшее влия-
ние на вариацию входных данных. Первый главный компонент у1=и’ {х
определяет нормализованную линейную комбинацию тех компонентов
входных векторов, которые дают наибольшее среднее значение ва-
риации, равное М: уаг(ш{х)=Е[||ш{х||2]=Е[ю{К„ш1]=А‚. Задача алгоритмов
РСА состоит в определении направлений щ, щ, ..., шк (называемых
главными собственными векторами) таким образом, чтобы максимизиро-
вать значение Е (||ш1гх||2) при выполнении условия ортогональноста

шгиу=0 для]2Ё(1=1,2,...,К) и идгиу =1.

Реконструкция х на основе вектора у и ортогональной матрицы ЧУ проводится
в соответствш с выражением [29]

З = и/Ту. (1о.1з)

Матрица разложения РСА (УУ) и матрица реконструкции (УУТ) составляют
взаимную транспозицию. РСА минимизирует значение ожидаемой погрешности

реконструкции данных, которая описывается формулой
Е, =Е[||х —2||11. (1014)

Из практики известно [29], что при ограничении К наибольшими
собственными значениями (К главными компонентами) эту погрешность можно

ВЫРЗЗИТЬ ЗНВИСИМОСТЬЮ

и
Е, = 21,. (1015)

Ё=К +1

Минимизация погрешности реконструкции данных равнозначна максим!-
зации вариации проекции

тахЕ‚, = ЁЛ. (10.16\
ы
Как Е‚‚ так и Е‚‚ являются неотрицательными, поскольку все собственшя:
значения матрицы корреляции, как матрицы симметричной и неотрицательн:
определенной, являются положительными или нулевыми.

`0_2. Нейронньхе сети РСА 261

Представление вектора х наибольшими главными компонентами у], уг, ‚.., ук,
зоставляющими вектор у, равнозначно сохранению информации о наибольшей
части энергии, содержащейся во множестве данных. Первый (наибольший)
‘гтавный компонент, сопряженный с Я; своим собственным вектором щ,
эпределяет направление в многомерном пространстве, в котором вариация
данных максимальна. Последний наименьший главный компонент (англ; Мпог
Ргтпсхра! Сотропеп!) указывает направление, в котором вариация минимальна.

На рис. 10.1 представлена геометрическая интерпретация наиболее значимого
я наименее значимого главных компонентов преобразования РСА. Первый
главный компонент соответствует направлению наибольшей вариации (энергии)
жгналов. При представлении данных только с помощью единственного главного
компонента и сопряженного с ним собственного вектора с последующим выбором
в качестве результата наибольшего из главных компонентов (щ) допускается
наименьшая погрешность реконструкции и одновременно максимизируется
вариация преобразования. Наименее значимый главный компонент оказывает
наименьшее влияние на точность восстановления данных. Поэтому для сжатия
данных (уменьшения количества информашш с минимальными потерями для ее
реконструкции) необходимо их представление множеством наибольших главных
помпонентов. игнорирование наименьших компонентов оказывает минимальное
воздействие на точность реконструкции данных.

Ось наименее '\` ‚‚” Ось первого
значимого \ . 9’ главного
компонента \ О. 9" О компонента

 

Рис. 10.1. Иллюстрация главных компонентов для группы результатов измерений

Преобразование РСА позволяет определить корреляцию, возникающую
между различными переменными, составляющими множество данных. Если эти
переменные коррелируют между собой, то знание только части из них будет
достаточным для определения остальных. Поэтому такое множество данных
может представляться меньшим количеством переменных. В случае, когда
переменные не коррелируются‚ восстановление части из них на основании
знания других данных становнтся невозможным.

262 10. Сети с саможанизацией; штяционного типа

В качестве примера, иллюстрирующего разложение на главньте компоненты,
рассмотрим фактическую корреляцию, существующую между длиной, шириной
и высотой особей, составляющих популяцию черепах [29]. Вектор измерений
х в этой ситуации образуют три компонента: длина‘с1, ширина з и высота и’:
х = [с1, в, ш]. Т. П.Ж0ликур и Ж.Мосманн [29] провели измерения этих параметров
для популяции размером р = 24 особи. Была получена матрица корреляции
К,“ в виде

451,3 271,2 168,7
К,“ = 271,2 171,7 103,3
168,7 103,3 66,65

Декомпозируя эту матрицу по собственным значениям, получаем Я 1 = 680,37,
Я 2 = 6,43, А 3 = 2,81, а также сопряженные с ними собственные векторы:

0,8126 —0‚5454 0‚2056
и’‚= 0‚4955 ‚ и’2= 0,8322 ‚„‚‚= 0,24зз
0‚3068 0‚1оо3 —о,94в5

На их основе определяется матрица Ж’ = [и’|, шд, и’3]Т преобразования РСА в
виде
0,8126 0‚4955 0,3068
Ж’ = — 0,5454 0,8322 0,1003
0‚2056 0,2488 - 0,9465

9

а также диагональная матрица Ь, образованная собственными значениями Я 1,1 2,
Я 3 матрицы Вт Ь = ‹11а‹‘;[680,37, 6,43, 2,81].

Наибольшее собственное значение Я 1 = 680,37 определяет первый глав-
ный компонент, сопряженный с собственным вектором иц, составляющим первую
строку матрицы “С Этот компонент при входном векторе х, сосгоящем из трех
элементов (длина д, ширина в и высота и’), описывается выражением у1 = и’? х.
которое в нашем случае приобретает конкретный вид: у; = 0,8126д + 0,4955в +
+ 0,3068и’. Каждое из собственных значений Я; соответствует вариации, которую
представляет Я-й главный компонент. Относительный вклад каждого главного

компонента в общую вариацию данных (энергию) можно определить

з

выражением т, = Я, / ЕЖ] . В рассматриваемом примере этот вклад составляет:
;=1

т; = 0,9866, т; = 0,0093, т3 = 0,0041. Анализ полученных значений говорит о

том, что доля первого главного компонента в суммарной вариации данных
составляет 98,66%. При восстановлении длины, ширины и высоты черепахи на
основании вектора у можно ограничиться его наибольшей составляющей у1 и
проигнорировать остальные, так как они не несут существенной информа-
ционной нат‘рузки. Это означает возможность трехкратного уменьшения
количества обрабатываемой информации.

10.2. Нейтг сети РСА 263

При обсуждении преобразования РСА следует подчеркнуть связь между
собственными значениями матрицы автокорреляции В,“ и особенными значения-

ми з; матрицы Х, составляющими матрицу К,“ (Ёх, =‘——ХХТ ). Особенные зна-

чения з; образуют псевдодиагональную матрицу 5, которая является одной из
составляющих ЗУВ-разложения матрицы Х. ЗУВ-разложение этой матрицы
определяется формулой

х=п$уТ. (1047)

Матрицы Не КМ“ и Уе КР” являются ортогональными, а псевдодиаго-
нальная матрица Зе КМ!’ содержит неотрицательные диагональные элементы.
Разложение К,“ на К главных компонентов соответствует выделению при ЗУБ-
разложении матрицы Х только К наибольших особенных значений и сопря-
женных с ними К столбцов матриц И и У. ‚

Кроме того, существует тесная связь между собственными значениями
матрицы К,“ и особенньпии значениями матрицы Х. Если определить ЗУБ-
разложение матрицы Х в форме Х = И 5 УТ при правостороннем умноженшт Х
на ХТ, то получим:

а!‘ ххТ=п$уТу вТпТ=пввТпд (10.18)

Вследствие псевдодиагональности матрицы 8 произведение этой матрицы на
57 дает диагональную матрицу 1) с элементами, равными квадратам элементов з;
матрицы 8, т.е.

в=а1а‚‹;[_‹3 ‚з;  з; 1.

В результате получаем:
ххТ= пппТ. (1019)

1
Принимая во внимание, что Вд = Е ХХТ, ЗУВ-разложение матрицы Х
точно соответствует разложению РСА матрицы корреляции, определенному
выражением (10.12) при Ь = Ё!) и “1 = ПТ. Главные векторы и’; отождествляются

со столбцами ортогональной матрицы П, полученной в результате ЗУБ-
разложения матрицы данных Х.

Аналогичным образом можно доказать, что при левостороннем умножении
матрицы Х на матрицу ХТ получаем:

хТх = увуТ. (10.20)

В этом случае роль матрицы П‘ принимает на себя матрица У, также
полученная в результате ЗУП-разложения матрицы Х.

Стандартные методы определения собственных векторов (продолжение
декомпозиции ОК [42]) матрицы В,“ при больших размерностях векторов х имеют
значительную вычислительную сложность, поэтому на практике более
эффективными оказываются адаптивные методы, основанные на обобщенном

264 10. Сети с самоовганизацией коеегляционного типа

правиле Хебба и непосредственно преобразуюшие входные векторы Дж: без явного
определения матрицы Кхх. Адаптивные методы особенно незаменимы при пос-
туплении данных в режиме “онлайн”, когда создание явной формы матрицы
корреляции просто невозможно.

В развитии метода РСА важную роль играют хеббовские искусственные
нейронные сети, выполняющие это преобразование в режиме онлайн
непосредственно на последовательности векторов х. Это преобразование
является адаптивным и производится однослойной нейронной сетью,
линейной при использовании обобщенного алгоритма Хебба. Созданы
различные варианты алгоритмов, в каждом из которых учитывается
корреляция между векгорами, представляющими входные данные. Значитель-
ное упрощение вычислений достигается в результате определения только
одного (наибольшего) главного компонента. Поэтому первым будет представлен
алгоритм РСА именно для этого случая.

10.2.2. Определение первого главного компонента

Для определения первого главного компонента уд и связанного с ним век-
тора м, соответствующего матрице Кц, Е. Ойя предложил систему, состоящую
из одного линейного нейрона (рис. 10.2)‚ для

д, которого
П“) т П
у‘ =шд х: Еошцхг 
‚=
д, #11
‚ Ут Веса вектора и’; подбираются согласио
‚ нормализованному правилу Хебба, называемому
’ ш правилом Ойя, которое может быть записано в
‚д ш скалярной форме как

Рис. 10.2. Нейронная сетъ РСА „и“ +1) = „и“? +

для определения одного (важ- + 77 У1[’Ч‘("7)'“’11("7)у1 (КЛ (1012)
нейшего) главного компонента или в векторной форме:
М“? +1) = м(1‹) + ПОЙУКЁ) [х(1‹) — "Чад Угад], (1013)

где 11(1‹) обозначает коэффициент обучения. Первое спагаемое формулы
соответствует обычному правилу Хебба, а второе обеспечивает самонор-
мализацию векторов весов, т.е. || И’1||2 = 1 [51, 111]. Подбор значения ц оказы-
вает существенное влияние на сходимость алгоритма. Хорошие результаты
достигаются, когда значение т] (К) уменьшается с течением времени обучения.

Широко применяется методика изменения 11(1с) = у), где 11 (0) = 0,5[ХТ/\’];
0,5 5 7< 1. В процессе обучения одни и те же обучающие выборки предъявляются

многократно ВПЛОТЬ ДО стабилизации ВССОВ ССТИ.

10.3. Н ' нные сети ЁСА — „ ‚ _ 265

 

10.2.3. Алгоритмы определения множества
ГЛЗВНЫХ КОМПОНЭНТОВ

Определение следующих компонентов РСА предполагает использование в
выходном слое большого количества нейронов. Сеть содержит столько нейронов,
сколько должно учитываться главных
компонентов разложения. Они располага-
ются в одном слое, поэтому сеть РСА
считается однослойной с линейными
функциями активации нейронов (рис.
10.3). Обобщенное правило Ойя для такой
сети становится нелокальным и мало-
привлекательным с вычислительной точ-
ки зрения. Лучшие результаты дает приме-
нение правила Сенгера [141]. Если К
линейных нейронов выходного слоя
генерируют выходные сигналы согласно
выражению

 

у‚‹‘‹)=дёш„‹‘‹)х‚(’‹)‚ (1014) ‚„ ’

то Уючнение весов сети производится по Рис. 10.3. Линейная нейронная сеть РСА

формуле  ДЛЯ Определения К ГПЗВНЫХ КОМПОЁЁНТОВ
„д ‹‘‹ +1) = ш„(1‹)+11у‚(1‹)[х‚(1‹)— и„‚(1‹)у‚‚(1‹)1 (1025)

для 1 = 0, 1, 2, ..., А’, 1= 1, 2, ..., К. Если принять обозначение

5-1

х;(1‹) = х‚(1с)- ‚Бит (1с)у,‚ (К) , (10.26)

то выражение (10.25) можно представить в форме

„у (‘с +1): „у (к) +71)’: х; (д) — „у (‘дуг › (1027)

аналогичной формуле Ойя (10.22), соответствующей только одному нейрону
Поэтому даже при наличии в выходном слое К нейронов правило обучения все
равно остается локальным при условии модификации значения входного
сигнала х}. Скалярные зависимости (10.26) и (10.27) можно записать в век-

торной форме
ы

Хи’) = ХО‘) — Ё “’)‚(’‹)У)‚ (ЁЪ (1018)

И=1

’ м‘ +1) = м‘) +пу‚(1‹)[х’(1‹) — у‚(1‹)"’‚ ‹‘‹)1 (1029)

266 10. Сети с самооеганизацией коеееляиионного типа

для Е = 1, 2, ..., К. Правило имеет локальный характер, поскольку для уточнения
весов одного нейрона не требуется решать уравнения, описывающие всю сетъ.
Следует заметить, что для первого нейрона (первого главного компонента РСА)
х'(/с) = х(/с). Для второго нейрона получаем: х'(/с) ==х(/с) — ш1(/с)у1(/с) - в этой
формуле присутствуют только уже известные веса первого нейрона. Аналогично
для третьего нейрона: х'(1с) = х(/с) — ш|(1с)у1(1‹) — ш2(/с)у2(/с) и т.д. — модифгшация
вектора х выражается через ранее определенные ветшчиньт, и процесс обучения
осуществляется, подобно алгоритму Ойи, с самонормализующимися векторами
“ъ || И’; Н = 1 [1411-

Рис. 10.4. Образ "Лена", восстановленный сетью РСА при использовании различного
количества главных компонентов:
а) один главный компонент; б) три главных компонента; в) пять главных компонентов

В настоящее время существует много различных нейронных алгоритмов,
позволяющих осуществить преобразование РСА. К наиболее серьезным, по-
мимо алгоритма Сенгера, относятся алгоритмы Фолдяка, Рабнера, а также АРЕХ

10. 3. Нейдонньте 1СА-сети Хедольта-Дщуттена 157

(англ.: Адаргбуе Ргёпсфа! сотропепг ЕХггасгёоп). Подробности их- реализации
можно найти в книге Диамантараса и Кунга [29].

Преобразование РСА чаще всего применяется для компрессии данных, при
котором большое количество входной информации заменяется уменьшенной
дозой‚ содержащейся в векюрах у и щ. В зависшиости от степени сжатия
(количества главных компонентов РСА) можно получить различное качество
восстановления данных.

Для примера на рис. 10.4 представлены три изображения "Лена", реконст-
руированные на основе 1, 3 и 5 главных компонентов РСА [92]. Образ, подверг-
нутый компрессии, имел размер 512›<512 пикселов и был разделен на кадры
размером 8х8. Качество восстановленного изображения сильно зависит от
количества К главных компонентов, учитываемых при восстановлении. Чем
больше этих компонентов, тем выше качество изображения и одновременно тем
меньше коэффициент компрессии. Изображение на рис. 10.4а соответствует
коэффициенту компрессии около 64, на рис. 10.46 - около 21, а на рис. 10.4в —
около 12. При наибольшей степени сжатия (при одном главном компоненте) на
изображении сильно заметны отдельные кадры. Изображение, восстановленное
на основе пяти главных компонентов, зрительно не отличается от оригинала.
Коэффициенты РЗЫК, полученные для этих образов, равны соответственно

18,80 дБ, 25, 43 дБ и 27, 58 дБ.

10.3. Нейронные |СА-сети Херольта-Джуттена

10.3.1. Предварительные пояснения

Сети Херольта-Джуггена [62] - это ‚линейные сети с самоорганизацией,
использующие обобщенное правило Хебба и относящиеся к классу корреля-
ционных сетей. Их концепция была сформулирована в середине восьми-
десятых годов ХХ века профессорами Дж. Херольтом и К. Джуттеном из
Гренобля [62‚ 63]. Первоначально эти сети применялись для так называемой
слепой сепарации сигналов. В настоящее время они выполняют и многие другие
функции, в том числе анализ главных компонентов РСА, анализ независимых
компонентов 1СА (англ.: [пдерепдепг Сотропеп! Апа1узёз), сглаживание и ‘вп.
Первичная структура сети была рекуррентной. В настоящее время часто
используются также однонаправленные сети. Независгпио от способа соединения
нейронов между собой, эти сети обычно имеют адаптивную линейную структуру
обрабатывающую сигналы в режиме реального времени (онлайн). Нелинейные
функции, применяемые в алгоритмах обучения, играют очень важную роль при
уточнении весов, не оказывая влияния на саму структуру взвешенных связей.
Оригинальное решение Херольта-Джутгена касалось проблемы сепарации
сигналов ж!) на основе информации, содержащейся в их линейной суперпозиции.

268 10. Сети с самоовганизаиией коеее/Еиионного типа

Пусть шиеются п независимых сигналов ж!) и смешивающая матрица А

а"  с п п 
д2| 922 ' ' ' д2п

А = . (1030)
ап! ап2 ’ ' ' апп

Для измерений доступны только сигналы х;(!), представляющие собой
линейную суперпозицию ж’), причем

И

х‚(г) = ёадз] (г) (1031)
для Я = 1, 2, ..., п. Главная трудность заключается в том, что как аг, так и зд(г) не
известны. На основании гипотезы о статистической независимости сигналов Дж.
Херольт и К. Джугген предложили решать эту задачу с применением нейронной
сети. Обобщенная схема включения этой сети в измерительную систему
представлена на рис. 10.5.

Алгоритм
адаптации

 

Рис. 10.5. Обобщенная схема включения нейронной сети в систему разделения сигналов

10.3.2. Статистическая независимость сигналов

Статистическая независимость случайных сигналов — это более общее понятие,
чем некоррелируемость. В общем случае две случайные переменные у; и уу будут
статистически независимыми, если информация об одной переменной ничего не
говорит о другой. С математической точки зрения статистическая независимость
означает, что двухмерная плотность вероятности р(уд‚ и) равна произведению
одномерных функций плотности

р(у‚‚у‚) = р(у‚)р(у‚) — (1032)

ДЛЯ СТЗТИСТИЧССКИ НСЗИВИСИМЫХ СИГНЗЛОВ обобщенная МЗТРИЦЗ КОВЗРИЗЦИИ

10.1. Нейдонные 1СА-сети Хедальта-Дёдсхттена 269

функций Дуд и 309) (обе функции должны бьпъ нечегными) представляет собой
неособенную диагональную матрицу, имеющую вид:

Е[1'(у)в’(у)1— Е[!(у)1Е[в’(у)] = =-
Е!!(у1)г(у1)1—Е[/(у1)1Е[г(у1)1
= Е[/(у1)г(у2)1—Е[!(х‚ )1Е[з(у‚)1 - (“1”)

Е(/‹у„›г&„›1-гп‹у„›1гкг‹у„›1

В этом выражении символом Е обозначается ожидаемое значение.
Из условия статистической независимости следует, что все обобщенные
взаимные Являются нулевымщ поэтому Ещудгщп—ЕЫо‚›1в[г(л›1=о‚ а
собственные ковариации — ненулевыми, т.е. Е[/(у‚)3(у‚)1—Е[/(у‚)1Е[;(у‚)1==0.
Условие статистической независимости сигналов отождествляется в ста-
тистике с обнулением взаимных кумулянтов высшего порядка [12, 63].

10.3.3. Рекуррентная структура разделяющей сети

Для решения задачи сепарации
статистически независимых сиг-
налов Дж. Херольт и К. Джутген
предложили лгптейную нейрон-
ную сеть с обратной связью,
представленную на рис. 10.6.
Сеть состоит из п линейных
нейронов, связанных между со-
бой взаимными обратными свя-
зями. Синаптические веса шд в
оригинальном решении Херольта
и Джуттена отличны от нуля
только при взаимных связях

Собственные связи в ори-
гинальном решении, представ-
ленном в работе [62], отсутствуют.
Каждый нейрон сети генерирует
выходной сигнал

п и
д“) = д“) — 2 иду] (у) _ Рис. 10.6. Структура рекурреитнои сети
1=1‚1=Ч Херольта-Джугтена для разделения сигналов

(10.34)

270 10 Сети с самоорганизации? коеееляционного типа

Если обозначить А смешивающую матрицу (1030), УУ - матрицу весов:

О "912 "*’1„
“21 О  “и

‘у:  ..   › (1035)
“бы “512 О

х(!) = [х1(!), х2(г), ...‚ х„(!)]Т - вектор наблюдаемых сигналов,- преобразованных
в соответствии с выражением (10.31), в(!)=[з1(г)‚ 520), ...‚ .ъ‘„(1)]Т -— вектор
исходных сигналов, у(1) = [у;(г), у;(1)‚ ...‚ у„(!)]Т - вектор выходных сигналов,
то функционирование сети, изображенной на рис. 10.6, можно описать
матричнь1ми уравнениями:

х(1‘) = Ада) ‚ р (10.36)

УФ‘) = х(1)— “ЁУЩ - (1937)

Если матрица А и вектор в(1) не известны, то при выдвижении гипотезы о
статистической независимости компонентов вектора в(1‘) задача сети сводится к
такому определению вектора решения

у(!) = (1+\У)"х(1), (10.38)

которое позволит восстановить первичные сигналы зд(1‘), составляющие вектор в(г)
с конкретной, но не определенной заранее степенью точности д;

уо) = то), (1039)

где В — диагональная матрица, 1) = М), (12, ...‚ с1„], и с сохранением произвольной
последовательности отдельных компонентов в векторе

УО) = 980‘) ‚ (19-49)

где Р — элементарная матрица перестановок, задающая различные комбинации
компонентов вектора в(1).

Решение, определяющее вектор у(1‘), который отвечает условиям (10.39) и
(10.40), может быть получено при произвольном количестве нейронов п. Если
количество источников больше двух, а значения коэффициентов смешивающей
матрицы ад заранее не известны, сигналы можно разделить только с помощью
адаптивного алгоритмического метода подбора весов нейронной сети.

10.3.4. Алгоритм Херольта-Джутгена для рекуррентной сети

Решение задачи разделения сигналов на основе рекуррентной сети было сведено
Дж. Херольтом и К. Джуттеном к решению системы дифференциальных урав-
нений, описывающих изменения весов этой сети. Они предложили простой

271

10.3. Ней нные 1СА-сетиХ льта- ттена

й статистйческоййчезависимости

горитм, использующий критери
н”, который можно представить в

адаптивный ал
сигналов и функционирующий в режиме “онлай

виде системы дифференциальных уравнений

(1О.41)

для 1= 1, 2, ...‚ п и 1 = 1, 2, ...‚ п при 11: 1 (в оригинальном решении собственные
обратные связи отсутствуют, щ; г= 0). Значение коэффициента обучения п (г), как
правило, уменьшается в процессе обучения до нуля. Функции ](у) и 39’) нечетны

и не равны между собой, ](у) ф 39’). Следует отметить, что зависимость (10.41)

представляет собой нелинейное обобщение простого правила Хебба.
На практике применяются различные виды функций ](х) и 3(х)‚ чаще всего

одна из них имеет выпуклую, а вторая — вогнутую форму. Наиболее популярны
представления ](х) = хз, ](х) = х5. Относительно функции 3(х) можно сказать, что
хорошие результаты достигаются при 3(х) = 1ап11(х), 3(х) = агс13(х), 3(х) = х, 3(х) =
з3п(х) и т.д.

В работе [62] было доказано, что обе функции ]( ) и 3( ) соответствуют
статистическим моментам высши тической

НСЗЗВИСИМОСТИ СИГНЗЛОВ ЗВТОМЁГИЧЭСКИ О

значений ‹ 1‘ ( у, (г))3( у 1 (0)) , гарантируюшее
Правило обучения, определенное выражением (10.41), может быть записано в
обобщенной матричной форме

9дЁ=пи›г‹у‹о)г‘‹уо» ‚

х порядков, что в случае статис
беспечивает равенство нулю средних

сходимость алгоритма обучения.

(1042)

 Лу„(г))]Т‚ 300)) = [ЗОЧЩЪ 2(У2(г))‚  ШАФЛТ-
(г) имеет в начальный момент фикси-

ОКЗЗЗТСПЬНОМУ ЗЗКОНУ В ЗЗВИСИМОСТИ

где 1041)) = ИУКЙЪ Т(У2(1))‚

Чаще всего коэффициент обучения 11
рованную величину, уменьшаюшуюся по п

от времени обучения г.
Следует обратить внимание, что адаптивная зависимость (1О.42) относится к

М КОМПОНСНТЗМ сигналов. При НЗЛИЧИИ ПОСТОЯННОЙ СОСТЗВЛЯЕОЩСЙ 88

следует отфильтровать. Для этого обычно применяется фильтр первого или

ого порядка, выходной сигнал которого воспринимается как переменная
11(г) обозначает импульсную реакцию фильтра,

переменны

а =‘‹ — обозначение свертки.
Экспериментальные исследования сети

как С ПОМОЩЬЮ КОМПЬЮТВРНОГО МОДСЛИРОВЭНИЯ,

реализации, ПОДТВЭРДИЛИ ХОрОШуЮ СХОДИМОСТЬ
ИЯ МНОГИХ СТЗТИСТИЧССКИ НСЗЗВИСИМЬПХ СИГНЗПОВ различной СТруКТурЬЬ

ТУД ОТДСЛЬНЫХ КОМПОНСНТОВ СИГНЗЛОВ,

Херольта-Джуттена, проведенные
так и в процессе ее технической

ЗЛГОРИТМЗ И ВОЗМОЖНОСТЬ

272 10. Сети с самооеганизаиией ковееляиионного типа
10.3.5. Обобщенный алгоритм обучения рекуррентной сети

На практике метод Херольта-Джуттена оказывается эффективным при
небольшом разбросе амплитуд отдельных сигналов 3,0), обычно меньшем,
чем 1 : 100.

При сильных отличиях сигналов значительно более эффективным считается
модифицированный алгоритм А.Чихотского [12], в котором вводятся собст-
венные обратные связи нейронов с весами шдчёо. Эти обратные связи
вызывают самонормализацию выходных сигналов, что приводит их к одина-
ковому численному уровню и облегчает тем самым процесс сепарации.

В соответствии с модификацией Чихотского [12] адаптивные механизмы
уточнения весов (при условии, что у;(1) не содержат постоянных составляющих)
описываются формулами

(1 шд
д‘ =11(‘) Х (и (1)) го’ ‚ (1)) (10-43)
для 1:] и
Ё?=п‹’›и‹»‚«»г‹»‚‹’»—11 (1044)

для 1 = 1, 2, ..., п. Обе формулы можно представить в обобщенной матричной

форме

с!“

717=п‹’)1/(у‹’»г’(уи»—11‚ 00.45)

в которой используются те же обозначения, что и в формуле (10.42). Вектор у(г)

рассчитывается в каждый момент времени согласно (10.38), у(г) = (1 + \\’)'1х(г),

для текущих значений матрицы весов \’\’ и вектора смешанных сигналов х(1).
Главный источник повышенной эффективности алгоритма — самонорма-

лизация до единичных значений выходных сигналов у;(1). Поскольку в

стабилизированном состоянии Ш = 0 , следовательно, ‹ 1" (у, (1)) 3( у, (0)) =1 , и

(1 г
независимо от уровня сигналов 3,0) происходит масштабирование всех сигналов

в сети до единичного уровня. Имитационные исследования сети с моди-
фицированным алгоритмом продемонстрировали возможность разделения
сигналов с амплитудами, различающимися даже в отношении 1 : 10"’. Сеть с
модифицированным правилом обучения также менее чувствительна к

коэффициенту обусловленности смешивающей матрицы А.
На рис. 10.7 представлен процесс сепарации четырех сигналов ж!) со
значительно отличаюшимися амплитудами:

з1= 0,001 з1п(300! + 6соз60г);

з; = тапс1(0,00001, 1 + 6соз60г);

в; = 0,001 з3п(соз155!);

34 = 0,00001 $1п(1200 г) з1п(50г);
емешанными посредством матрицы А.

0.3. Ней онные [СА-сети Хе ольта- ттена 273

 

 

—о‚5

0,001”

||||||||||||||||||||||||||П
|||||||||||||||||||||||||||||
‚94514 ‘ р

о „
—-!э -0‚5

Рис. 10.7. Графическая иллюстрация процесса разделения сигналов сетью

Херольта-Джуггена:
а) исходные сигналы; б) сигналы, смешанные посредством матрицы А;
в) выходные сигналы нейронной сети в процессе их разделения

1 8-2162

274 10. Сети с сам ей кжзщжннаго типа

0,78 0,1 5 - 0,22 0,12

А = — 0,92 - 0,90 0,27 - 0,93
0,40 -— 0,91 0,60 - 0,78

— 0,88 0,99 0:10 0,61

На рис. 10.7а изображены исходные сигналы в;(г)‚ на рис. 10.76 - смешанные
сигналы хм), а на рис. 1О.7в -— сигналы, выделенные нейронной сетью в процессе
сепарации (это независимые сигналы, являющиеся реакцией на исходные
сигналы). В качестве входных используются смешанные сигналы (три средних
графика на рис. 10.7). Из-за огромного различия в амплитудах исходных
сигналов на графиках подаваемых на ввод сети смешанных сигналов видны
только наибольшие сигналы шума, тогда как сигналы с малой ампли-
тудой практически незаметны. Процесс сепарации осуществлялся с по-
мощью программы ВЬ‘ [13] с применением нелинейных функций ](х) = хз,
3(х)=гап11(10х), а также коэффициента обучения т1(г), адаптивно умень-
шающегося от начального значения, равного 2000. Это позволило разделить
все сигналы независимо от их амплитуд (три нижних графика на рис. 10.7).
Выделенные сетью сигналы характеризовались одинаковым уровнем
амплитуды, достигнутым благодаря собственным обратным связям ней-

ронов.

10.3.6. Однонаправленная сеть для разделения сигналов

Серьезный недостаток рекуррентной сети Херольта-Джутгена, с трудом
устраняемый на практике, состоит в
сложности обеспечения стабильности
процесса разделения сигналов, осо-
бенно тогда, когда матрица А плохо
обусловлена, а исходные сигналы
сильно отличаются друг от друга по
амплитуде. Также следует отметить, что
в рекуррентной сети на каждом шаге
возникает необходимость инверти-
ровать матрицу весов (формула
(10.38)), что заметно увеличивает
вычислительную сложность алгоритма.
Устранить эти проблемы позволяет
применение однонаправленной сети без
обратных связей.

Обобщенная структура такой сети
представлена на рис. 10.8. Источниками
Рис. 10.8. Структура однонаправленной информации для сети являются только

сетидттрагделения сигналов смешанные сигналы х;(г). В результате

 

10.3. Нейронные [СА-сети Хешльта-Еттена 275

их преобразования линейной системой синаптических весов шд формируется
вектор у

у = “б: (10.46)

Матрица Ж’ е К”’°'в этом выражении является полной. При таком решении
однонаправленная сеть равнозначна сети с обратными связями, если матрица
весов Ж’ удовлетворяет условию

‘у =‹\9и+1)—1‚ 00.47)

А
где “обозначена матрица весов рекуррентной сети. В результате простого

МВТСМЗТИЧССКОГО преобразования ПОПУЧЗСМЗ
А

уч= ‘г’ -1. (1О.48)

Алгоритм обучения весов Ж’ можно получить непосредственно из обучающих
зависимостей для рекуррентных сетей, если принять во внимание, что

^ -1
(“У (“У
———= ——- . 10.49
(1! (1! ( )
"С учётбм матричного тождества Ё$____ “ ‘ф-др получаем _‘Ё______ “ ‘д:
ат“ ауч д‘ д‘
= ‘у + —— ‘г’ = о ‚ откуда
(1! д!
ш‘ ат" ай‘
——— = — —— = — ———- . 10.50
а‘ 95’ а’ Ж’ Ж’ а‘ Ж’ ( )

Если выбрать для дальнейшей реализации одно из правил обу-
чения, сформулированных для рекуррентных сетей, то можно получить его
аналог для однонаправленной сети. Например, принимая во внимание
модифицированное правило Чихотского [17], строится адаптивная зависи-
мость, представляемая в матричной форме

Ё?’ = 11(1)“’[1 —! (У (‘Жду ‹1))1Т1“’ (19-51)

с начальным условием “’(0) = 1, имеющая свойства, идентичные свойствам
алгоритма обучения рекуррентной сети, на базе которого она была
создана. В отличие от формулы обучения рекуррентной сети в вы-
ражении (10.51) изменения весов обусловлены их фактическими значе-
ниями. К настоящему времени известно большое количество вари-
антов обучающей формулы (10.51), характеризующихся особенно выда-
ющимися качествами при плохой обусловленности матрицы А либо при
большой разнице амплитуд исходных сигналов зд(1). Среди них можно
выделить [12]:

18‘

276 ‚ _ ‚ 10. Сети с оан  ’ ией ЕЕЁЕШнного типа

’ алгоритм ЧихотскбРо-Амари-Янга

Ё} =п‹’){1 —!(у‹’›)г‘‹у‹’»1 ‘Н ‚ 0052)

’ алгоритм, основанный на естественном традиенте,

Ёжик‘ —/‹уи»г’‹у‹’»1 ‘к? (1053)

’ алгоритмы Кардоссо [3, 12]:

$21- = ПО) [1 ——У (Г) УТЩ —‘1!(у(г)ет(у(г))+де(у(г)! ТО’ (‘Ш 91’ ‚ (10-54)

Ё} =п(’) п —/‹у‹:›уТ‹’»1 и, (1055)

где аи В - это численные коэффициенты из интервала [0, 1].

Особенно хорошими качествами характеризуется алгоритм, основанный на
естественном грациенте, при реализации которого, как показано в работе [18]‚
процесс сепарации практически не зависит от соотношения амплитуд сигналов
341) и от степени обусловленности смешивающей матрицы А.

Так же как и в рекуррентных сетях, коэффициент обучения п(т)
представляется функцией, значение которой уменьшается с течением времени до
нуля. Обычно это показательная функция вида п (г) =Ае 4” со значением
амплитуды А и постоянной времени, индивидуально подбираемой в каждом
конкретном случае.

Экспериментальные исследования однонаправленной сети показали высокую
эффективность разделения исходных сигналов с большими относительнымн
различиями (доходяшими до 1010) амплитуд и плохой обусловленностью
смешивающей матрицы А. На рис. 10.9 представлены результаты сепарации семи
сигналов со значительно отличающимися уровнями амплитуд:

3; = 0,00001 33п(со31571);

31 = 0,001 31п(З101+ сов 571);
33 = 0,01 31п(90г);

34 = тап‹1(0,0001‚ г) ;

35 = гап‹1‘н(10, 0, 000001, г);

36 = 0,00О0000001 со3(155!) ;
37 = 0‚00001 з1п(800 г)‘з1п( 60 г).

О 3. Ней нные [СА-сети Хе ьта- тейш 277

Рис. 10.9. Процесс разделения семи сигналов, смешанных посредством матрицы А:
а) графики изменения сигналов; б) трафик изменения эвклидовой нормы погрешности

ИСПОЛЬЗОВЗЛЗСЬ СМСШИВЗЮЩЗЯ МЗТРИЦЗ ВИДЗ

0,70 0,15 — 0,20 0,12 — 0,48 0,13 0,1 1

- 0,91 - 0,90 0,20 - 0,90 — 0,69 0,06 0,08

0,39 — 0,90 1,00 -— 0,80 0,50 0,00 0,20

А = — 0,86 0,99 0,10 0,10 0,29 0,10 0,00
0,84 - 0,33 0,02 - 0,60 — 0,5 1 0,13 0,14

0,12 - 0,05 0,20 0,21 0,30 1,00 0,12

0,30 0,40 0,02 0,10 0,22 0,20 1,00

Применялись типовые нелинейные функции Д( у, (1)) = у? в3п( у‚) ‚
‚9‚(у‚(г))=31ап11(10у‚) для 1 = 1, 2, 3, 4, 5, 6, 7.
Коэффициент обучения п (г) изменялся в соответствии с выражением

200 для 1 < 0,253

200 ехр-би-го) для ‚2025 - (1056)

П(1)={

Веса подбирались путем решения методом Рунге—Кутта системы
дифференциальных уравнений, соответствующих алгоритму (10.53). Как видно

278 ‚ ‚ , 10. Сети с с ' т1юнндго типа

на рис. 10.9, разделение сигналов произошло менее чем за двадцать ите-
рацшй. Процесс сепарации сигналов протекал равномерно и практически не
зависел от уровня амплитуды исходных сигналов. Все выделенные сетью
сигналы были нормализованы и имели амплитуду, близкую к единице.
Вызывает интерес динамика изменения адаптировавшихся весов сети с учетом
значительных различий амплитуд исходных сигналов. На рис. 10.10 для примера

ЮА

0,3 М,
41.41 0,2 О 0,4 0,6 о,в 1 ‘

Рис. 10.10. Процесс адаптации некоторых весов нейронной сети

продемонстрирован процесс адаптации восьми весов одного из нейронов
описанной выше сети, разделяющей семь сигналов. Веса нейронов,
соответствующих самым слабым сигналам, принимают большие значения.
Благодаря этому выравнивается влияние каждого исходного сигнала на
окончательную форму выделенных сигналов у;(г).

Раздел 11

МАТЕМАТИЧЕСКИЕ ОСНОВЫ НЕЧЕТКИХ СИСТЕМ

Понятие нечетких множеств (англ; Лигу тега) как обобщение обычных
(четких) множеств было введено Л. Заде в 1965 г. [177, 178]. Традиционный
способ представления элемента множества А состоит в применении харак-
теристической функции д А(х), которая равна 1, если этот элемент принадле-
жит к множеству А, или равна О в противном случае. В нечетких системах
элемент может частично принадлежать к любому множеству. Степень
принадлежности к множеству А, представляющая собой обобщение харак-
теристической функции, называется функцией принадлежности д А(х), причем
д А(х)е [0,1]. Значения функции принадлежности являются рациональными
числами из интервала [0,1], где О означает отсутствие принадлежности к
множеству, а 1 — полную принадлежность. Конкретное значение функции принад-
лежности называется степенью или коэффициентом принадлежности. Эта
степень может быть определена явным образом в виде функциональной

х — 3 2
) либо диск етно — путем задания
0,2 р

конечной последовательности значений х е {х„} в виде

зависимости (например, д А (х) = ехр (— (

(111)

’ А ‚_ 11951) д(х2) 1411»‘)
(х)— ‚——— ——— .
х‘ х2 х„

Например, для последовательности дискретных значений переменной х,
равных х; = 7, х1 = 8, х3 = 9, х4 = 10, х5 = 11, х, = 12, х7 = 13, их коэффици-
ент принадлежности к числам, близким 10, может быть определен в виде

{од 0,3 0,8 1,0 0,8 0,3 0,1}
А(х)= ——"`——’——’——’——’——’—— .
7 8 9 10 11 12 13

В теории нечетких множеств, помимо переменных цифрового типа, сущест-
вуют лингвистические переменные с приписываемыми им значениями. Пусть
переменная х обозначает температуру (х = "температура"). Можно определить
нечеткие множества "отрицательная", "близкая к нулю", "положительная",
характеризуемые функциями принадлежности д „тр„„(х), д д„у„(х), д „„,‚‚,ж(х). Так
же как обычная переменная может принимать различные значения,
лингвистическая переменная "температура" может принимать различные

280 11. Математические основы нечетких систем

 

лингвистические значения. В нашем примере это: "отрицательная", "близкая к
нулю" и "положительная". Следовательно, лингвистическое выражение может
иметь вид: "температура отрицательная", "температура, близкая к нулю",
"температура положительная". ‘

На рис. 11.1 приведена графическая иллюстрация функции принадлежности
переменной х = Т (где Т означает температуру) для трех названных множеств
значений температуры. Непрерывными линиями обозначена классическая
(точная) принадлежность, а пунктирными линиями — нечеткая принадлежность.
Можно отметить, что футшция нечеткой принадлежности является непрерывным
приближением пороговой функции точной принадлежности.

Степень принадлежности

 

Температура

Рис. 11.1. Илшострация понятия принадлежности температуры к области отрицательной,
близкой к нулю либо положительной (пунктирные линии — нечеткая система, сплошные
линии — точная система)

Каждое нечеткое множество имеет определенный носитель (англ: виррогг).
Носителем множества $ирр(А) является подмножество тех элементов А,
для которых коэффициент принадлежности к А не равен нулю, т.е. $ирр(А) =
={х, ДА (х) > О}. В приведенном выше примере на рис. 11.1 носителем множества
"бхшзкая к нулю" является множество температур в интервале от -4°С до +4°С.

Два множества А(х) и В(х) равны между собой, когда ДА (х) = дд (х) для
каждого элемента обоих множеств. Кардинальное число нечеткого множества
А равно сумме коэффициентов принадлежности всех элементов к этому
множеству, МА) = 2‚и‚4(х). Это обобщение аналогичного понятия, относя-
щегося к обычным множествам, для которых кардинальное число равно сумме
элементов множества. Нечеткое множество является нормальным, если
хотя бы один элемент этого множества имеет коэффициент принадлежности,

равный 1. Сечение а нечеткого множества А образуется подмножеством Ад,

11.1. Опттд на нечетких множествах 281

содержащим те элементы множества А, для которых ДА (х) > а (слабое сечение)
или 11,4 (х) 2 а (сильное сечение), причем а е [О‚1].

11.1. Операции на нечетких множествах

На нечетких множествах, рассматриваемых как обобщение обычных множеств,
можно определить ряд математических операций, являющихся обобщением
аналогичных операций, выполняемых на "четких" множествах. К ним среди
прочих относятся:

1. Логическая сумма множеств А ы В
мАиВ (х) = ‘МА (х) Ы мв (х) = Мчх[‹4(х)‚13(х)1‚ (111)
ще знак и обозначает оператор Мах.

ПРИМЕР 11.1
Пусть даны два нечетких множества А и В, определенные следующим

образом:
А={ь9‚ 212,24}

Чш щ ш и}
х1’х2’хз‚ х4

Логическая сумма этих множеств С = А ы В равна:
С={ш‚ щ 22, 91}
х: х2 х: х4
2. Логическое произведение множеств А п В
м‚„„‹›‹›=м‚‹х›пм„‹х›=мп[А‹›‹›‚в‹х›]‚ (из)

где знак п обозначает оператор Мйп. Для данных из примера 11.1 множество
С, являющееся логическим произведением множеств А и В, будет иметь вид

слива, 912,2}
х2 х: х4

Ыд

3. Отрицание множества
(х)=1—м‚‹(х) . (11.4)

В отличие от обычных (четких) множеств, где отрицание элементов,
принадлежащих К МНОЖССТВУ, ДЗСТ ПУСТОС МНОЖССТВО, ОТрИЦаНИС НСЧСТКОГО
МНОЖССТВЗ ОПРСДСЛЯСТ НЁПУСТОС МНОЖССТВО, СОСТОЯЩСС ИЗ ЭЛСМСНТОВ, функции
принадлежности которых также определены на интервале [О‚1].

5

282 П. Математические основы нечетких систем

 

4. Равенство множеств А и В
Нечеткие множества А(х) и В(х) равны между собой, когда для всех элементов
х; обоих множеств выполняется условие щ (хд) = ‚ид (хд).

5. Операция концентрации СОМ (А)
#сом(Х) = [ш (1012 - (11-5)

Эта операция весьма часто выполняется при действиях с лингвистической
переменной, в которых она отождествляется с интенсификатором "очень".

6. Операция растяэлсения ВП„(А)
ШлЦХ) = [Щ (Х)1"’5- (11-5)

Лингвистическое значение этой операции формулируется как "примерно"
либо "приблизительно".

7. Алгебраическое произведение двух множеств А ъ В

дл-в (х) = щ (х) * дв (х) - ‚ (11-7)
8. Ограниченная сумма двух нечетких множеств А | + | В ‘
#4 |+|в (х) = тй‘ {1‚ ш (х) +дв (х)}- (11-3)
9. Ограниченная разница двух нечетких множеств А | — | В
#4 1-13 (х) = Шах Щ Ш (х) —дв (х))- (11-9)
10. Ограниченное произведение двух нечетких множеств А | - | В
дА|-\в(Х)=таХ {0›д‚4(х) +дв(х)— 1) (1110)
11. Норма/шзация множества ЫОКМ (А)
х
днокм(х)=г1’ай1%%щ‚ (1111)

Следует отметить, что множество А считается подмножеством мно-
жества В, т.е. А с В, когда для всех элементов выполняется неравенство
;1‚4(х;) 5 Дд (хд). Например, если А = {0,5 / х1, 0,3/ х2, 0‚1/х3} и В = {0‚6/ х1, О,5/ хг,
0,4/ х3}, то А с В.

Определенные на нечетких множествах операции обладают свойствами
ассоциативности, коммутативносги и дистрибутивности, причем эти свойства
понимаются следующим образом:

‘ ассоциативность: (А=‘‹ В)›‘‹С = А* (В“=С');

’ коммутативность: А=’‹В = 8* А (за исключением ограниченной разности);

О дистрибутивность: А‘ (В Ф С) = (А*В) О (А*С),

где операторы ч и о обозначают любую определенную выше операцию на

НСЧСТКИХ МНОЖССТВЗХ. ИЗ СВОЙСТВ НСЧСТКИХ МНОЖССТВ СЛСДУСТ, ЧТО В (УГЛИЧИС 01’
ПРОИЗВЕДЕНИЯ ОбЫЧНЫХ МНОЖССТВ ЛОГИЧССКОС ПРОИЗВСДСНИС МНОЖССТВЗ И СГО

11.2. Мееы нечеткости нечетких множеств 283

отрицание не обязательно образуют пустое множество, что можно записать в виде

АоЙЧЧд . (11.12)

' Точно так же и логическая сумма нечеткого множества А и его отрицание не
образуют полное множество П, что можно записать в виде

АЫЙЧЧЛ (1113)

11.2. Меры нечеткости нечетких множеств

Для определения степени нечеткости множества введено понятие меры
нечеткости, отвечающей так называемым условиям А..ДеЛуки и С.Термини
[173, 181], сводящейся к измерению уровня различия между множеством А
и ею отрицанием В.

Наиболее популярна мера Р.Егера‚ в соответствии с которой степень
нечеткости множества А в метрике р, обозначаемая РС/Ер (А), определяется
выражением

15,911)

ги2‚,‹‚4)=1— ш

(1114)
п ‚

г _

_ ‚г; ._
где 1)‚,(А, А )— это мера расстояния между множествами А и А , содержащими
п элементов. Значение р = 1 соответствует метрике Хемминга‚ в которой

‘Э‚‹А‚71›=>Ё|2м‚‹х‚›—1| , (11.15)

1=1

а значение р = 2 соответствует метрике Евклида, в которой
1>‚‹А‚И›=‚/Ё‹2м‚‹х‚›—1›‘ . (1116)
ПРИМЕР 11‚2

ЕСЛИ НСЧСТКОС МНОЖВСТВО А ОПРСДВЛЯСТСЯ дискретным СПОСОбОМ как
„@щ@шжищ

х‘ х: хд хд х5 хб х7

в соответствии с мерой Егера получаем:

ги2‚(‚4)=1—%(о,з+0+0,в+1+0‚в+0+0,в)=0,457 ‚

284 11. Математические основы нечетких систем

 

Риг, (А) = 1 — 1; (0‚в4 + 0 + 0,36 +1+ 0,36 + 0 + 0,в4)= 0,347 .

«Г

Другую меру нечеткости (энтропийную) предложил Б.Коско [173]. Она
основана на понятии кардинального числа множества. В соответствии с этой

мерой

———_М‹А^Я) (ил)

НЩА): М(АшЙ) ’

где М (Г) обозначает кардинальное число множества Р. Для множества А из
примера 11.2 получаем меру Коско, равную

Следует обратить внимание, что обе меры - Егера и Коско - для четких
множеств дают один и тот же нулевой результат, поскольку в мере Коско
М (А, Й) = 0, а Пр (А, Й ) = пир, что вследствие зависимости (11.14) дает в
результате также РПХР (А) = О.

11.3. Нечеткость и вероятность

В теории вероятности событие и е Н либо происходит, либо нед а вероятность
р(и) представляет меру того, что оно состоится или что случайная переменная х
примет значение и. Оценка вероятности р(и) может быть рассчитана как
отношение количества экспериментов, в которых указанное событие сверпшлось,
к общему количеству экспериментов. Например, если день 21 ноября в течение
последних 100 лет был дождливым 82 раза, то вероятность дождя в этот день в
настоящем году оценивается как 0,82. Следует подчеркнуть, что вероятность
события относится исключительно к будущему. Когда соответствующий день
наступит, данное событие либо произойдет, ‚тшбо нет, и в этот момент понятие
вероятности его свершения утрачивает смысл (например, в момент начала дня 21
ноября все еще не ясно, будет этот день дождливым или нет, однако когда он
завершится, мы будет творить о том, произошло или нет событие, а не о его
вероятности).

Понятие нечеткости оценивается совершенно по-другому. Оно измеряется
степенью, с которой событие х = и (например, только что происшедшее) принад-
лежит к некоторому множеству событий А. Фактически измеряется степень, в
которой универсальное множество Н содержится в подмножестве А. Например,
если 21 ноября дождь шел на протяжении 15 ч., то степень его принадлежности к
множеству дождливых дней можно определить как 15/24. С этой точки зрения
понятие нечеткости относится не только к прошлому как это имеет место в случае
вероятности, но также к настоящему и к будущему.

11.3; Нечеткость и вероятность 285

Следует отметить, что вероятность может быть определена как неёегкоё
значение, особенно тогда, когда оно оценивается приближенно, а не точным
способом. Поэтому можно сказать, что вероятность наступления определенного
события составляет, например, "около 0,7", поскольку переменная "около 0,7"
является лингвистической. Если же нечеткое понятие относится к будущему, ему
можно приписать некоторую вероятность.

°’ их) а их)

малое среднее большое

———

      

Рис. 11.2. Графическая иллюстрация данных из примера выбрасывания кости: ;
а) функции принадлежности; б) вероятность выпадения соответствующего номера

ПРИМЕР 11.3
Рассм им в ятностъ выпадения кости с о деленным ном ом из инте вала
(УГР
[1 — б]. Допустим, что имеются три нечетких множества чисел: "малое", "среднее"
и "большое", нкции п инаштежности к кото ь1м п едставлены на ис. 11.2а.
У Р Р
В оятность х нас пления нечеткого события, что х — это малое, с еднее или
еР Р ТУ
большое число, определяется по формуле [67, 173]

ро) = Ёщхдрбч),

Ё=1

где р(х;) обозначает вероятность выпадения определенного числа из [1 - б]. Если
допустить равномерное распределение вероятности выпадения каждого числа
(р(х;) = 1/6) так, как это представлено на рис. 11.26, получим:

р(х ="малое") =%(1+ 0,5) = 0,25,

р (х =“ среднее") = %‹0,5 +1+ 0,5) = 0,333,

р(х =“ большое") = %(0,5 + 1 + 1) = 0,418.

В приведенном результате учитывается понятие иечегкоеги лингвистической
переменной: "малое число", "среднее число", "большое число", а каждому
событию приписывается вероятность его наступления.

286 11. Математические основы нечетких систем

11.4. Нечеткие‘ правила вывода

Базовое правило вывода типа "если - то" (англ.: Ж- гИеп ги1е) называется также
нечеткой шипликацией, принимающей форму

еслих ат’ А, т’ у ат’ В ‚ (1113)

где А и В - это лингвистические значения, идентифицированные нечетким
способом через соответствующие функции принадлежности для переменных х и
у. Часть "х это А" называется условием (предпосылкой), а "у это В" — следствием
(заключением). Импликацию (11.18) можно записать в сокращенном виде А —-› В.

Нечеткое рассуждение — это процедура, которая позволяет определить
заключение, вытекающее из множества правил "если - то". Такое множество при
Н переменных х; может принять вид

еслих‚э‘т А‚их2 ат’ ‚42и...их„з‘т А„, т; узт’ В _(11_19)

Переменные хд, 1:2,  хд образуют Н-мерный входной вектор х, составля-
ющий аргумент условия, в котором Ад, А2, ...‚ Ад и В обозначают величины
соответствующего коэффициента принадлежности 11,4 (хд) и рд (у). Необходимо
обратить внимание, что здесь присутствуют индивидуальные функции
принадлежности для каждой переменной х; и отдельно для у. Случайное значение
функции принадлежности д, (х), где х — это вектор х = [х|, х2, ...‚ хм], отно-
сящееся к условию имплнкации (уровень активации правила), должно в
последующем интерпретироваться с использованием введенных ранее
нечетких операций. Возможна интерпретация в форме логического произве-
дения множеств либо в форме алгебраического произведения:

О интерпретация в форме логического произведения

11„ (х) = ШЁЧЁЫ ‚эх; ))‚ (1110)

’ интерпретация в форме алгебраического произведения

м‚‹›‹›=йм‚‹х‚›. 01.21)

Ё=1

Приписывание единственного значения функции принадлежности, описы-
вающей многомерное условие, будем называть агрегированием предпосылки.
Каждой импликации А —› В, определенной выражением (1 1 . 19), можно приписать
также единственное значение функции принадлежности 11,441; (х, у). Наиболее
популярные интерпретации этой функции также имеют форму логического или
алгебраического произведения:
’ форма логического произведения

дА-ш = Щ1Г\{#А(х)›дв()’)}‚ (1112)

‘ форма алгебраического произведения

дя-ш = #4 (ХШЫУ) . (1113)

11.5. Системы нечеткого ‘вывода Мамдани —Заде 287

Приписывание единственного значения функции принадлежности всей
импликации будем называть процедурой агрегирования на уровне импликации.

11.5. Системы нечеткого вывода Мамдани-Заде

Элементы теории нечетких множеств, правила импликации и нечетких
рассуждений образуют систему нечеткого вывода. В ней можно выделить
множество используемых в системе нечетких правил, базу данных, содер-
жащую описания функций принадлежности, а также механизм вывода и
агрегирования, который формируется применяемыми правилами импликации.
Следует упомянуть, что в случае технической реализации в качестве вход-
ных и выходных сигналов выступают измеряемые величины, однозначно
сопоставляющие входным значениям соответствующие выходные зна-
чения. Для обеспечения взаимодействия множеств этих двух видов вводится
нечеткая система с так называемыми фуззификатором (преобразо-
вателем множества входных данных в нечеткое множество) на входе и
дефуззификатором (преобразователем нечетких множеств в конкретное
значение выходной переменной) на выходе [160, 173]. Структура такой
системы представлена на рис. 11.3. Фуззификатор преобразует точное

База правил
вывода

     
  

   

      

Фуззи-
фикатор

Нечеткое
МНОЖЭСГПВО

фикатор

Нечеткое
множество

 
 

Х

Четкое
множество

У
Четкое

МНОЖЭСГПСО

  
   

Вывод
решения

Рис. 11.3. Структура нечеткой системы с фуззификатором и дефуззификатором

МНОЖССТВО ВХОДНЫХ данных В НСЧСТКОС МНОЖССТВО, ОПРСДСЛЯСМОС С ПОМОЩЬЮ

значений функций принадлежности, тогда как дефуззификатор решает
обратную задачу - он формирует однозначное решение относительно значения
выходной переменной на основании многих нечетких выводов, выраба-
ТЫВЗСМЫХ ИСПОЛНИТСЛЬНЫМ МОДУЛСМ НСЧСТКОЙ СИСТЕМЫ. ВЫХОДНОй СИГНЗЛ
этого модуля может иметь вид М нечетких множеств, определяющих диапазон

288 11. Математические основы нечетких систем

 

изменения ЁЁВЁоДной переменнбйГ“Дефуззйфикатор преобразует этот
диапазон в одно конкретное значение, принимаемое в качестве выходного сигнала
всей системы. .

Необходимо отметить, что также существуют системы нечеткого вывода, в
которых исполнительный механизм непосредственно генерирует четкие
значения, которые уже не требуется подвергать дефуззификации. В качестве
примера назовем систему Такаги-Сугено-Канга‚ которая будет подробно
описана в следующем подразделе.

Правило 1

то
Если х этод, у это В,

   
   
  

  

то
Если х этоА2 у это 82

     

1 Дефуззификатор

Нечеткое Четкое
множество множество

то
Если х этоАм у это Вм

 

Рис. 11.4. Организация вывода в нечеткой системе при наличии М правил вывода

Обобщенная функциональная структура системы, приведенная на
рис. 11.3, может быть представлена в расширенной форме, которая в
явном виде демонстрирует правила нечеткого вывода так, как это изо-
бражено на рис. 11.4. Поскольку допускается применение множества нечетких
правил, в ней также предусмотрен блок агрегирования, чаще всего реали-
зуемый в виде логического сумматора (оператор Мах). Описываемая система
вывода называется системой Мамдани-Заде. Она очень популярна в обыч-
ных (неадаптивных) нечетких системах. Как правило, в модели Мамдани-Заде
присутствуют следующие операторы:

о оператор логического или арифметического произведения для определения
результирующего уровня активации, в котором учитываются все компоненты
вектора х условия;

‘ оператор логического или арифметического произведения для определения
значения функции принадлежности для всей импликации А —-› В;

’ оператор логической суммы как агрегатор равнозначных результатов
импликации многих правил;

11.5. Системы нечеткогд дывода ЬШЭйдани-Заде  289

 

’ оператор дефуззификации, трансформирующий нечеткий результат д(у) в
четкое значение выходной переменной у.

ПРИМЕР 11.4

На рис. 11.5 представлен способ атрегирования двух правил нечеткого вывода при
существовании двух значений переменных хд и х2. Логическое произведение
(оператор Мйп) используется как для агрегирования нечетких правил относи-
тельно конкретных переменных х; (1 = 1, 2), образующих вектор х, так и на
уровне импликации А —-› В для одиночных правил вывода. Агрегирование
нмпликаций, касающихся правил 1 и 2, проводится с использованием
логической суммы (оператор Мах). В правой нижней части рисунка представлен
нечеткий результат в виде функции принадлежности переменной у. Получение
четкого значения у, соответствующего также четким значениям входных

переменных х; и х2, требовало бы в этом случае применения процедуры
дефуззификации.

Минимум

   
 

—1———_————— —— — ———-———————

Рнс. 11.5. Иллюстрация примера системы вывода Мамдани-Заде

‘ 9-2162

290 Н.   основы нечетких систем

11.5.1. Фуззификатор

Фуззификатор преобразует Н-мерный входной вектор х = [х1, х1, ..., хдДТ
в нечеткое множество А, харакгеризуемое функцией принадлежности ДА (х) с
четкими переменными. Несмотря на то, что нечеткие системы могут иметь
функции принадлежности произвольной структуры, с практической точки зрения

д)

Коэффициент принадлвжноспш

б)

Коэффициент принадлеиоюапи

—0‚5 0 0,5 1 1.5 2 2.5
Х

Рис. 11.6. Иллюстрация влияния параметров гауссовской функции на ее форму:
а) влияние размещения центра с при 0'= 1;
б) влияние значения 0’ при постоянном значении с ч 1

11.5. Системы нечетнкого вывода Мамдани-Заде 291

 

наибольшей популярностьто польйлотся функции гауссовскопо типа, а также
треугольные и трапецеидальные функции.

Общая форма гауссовской функции для переменной х с центром с и
вариацией о‘ для множества Р имеет вид: '

д‚‹х)=ех‚{—(";°)2]. (1124)

На рис. 11.6 представлена форма типовых гауссовских функций при различ-
ных параметрах с и о‘, причем на рис. 11.6а показано влияние размещения центра
с при неизменном значении о; а на рис. 11.66 — влияние значения 0‘ при фиксиро-
ванном положении с. Параметр с обозначает центр нечеткого множества, а его из-
менение соответствует смещению функции принадлежности по горизонтальной
оси. Праметр о’, иногда называемый коэффициентом широты, отвечает за форму
функции. Чем меньше его значение, тем больше крутизна функции. Следует отме-
тить, что при соответствующем смещении центра гауссовская функция может
реализовать и сигмоидальную функцию (чаще всего при смещении вправо с с =4).

В нечетких сетях также применяется обобщенная гауссовская функция,
которая определяется формулой

‘ 2ь _
ддх) =ехр {Ё} _ (1125)

Она оперирует тремя параметрами: с, о‘ и Ь. Значение параметра Ь сущест-
венным образом влияет на форму кривой, что демонстрируется на рис. 11.7.

ф’

г’
Функция принадлежности для С=1, с=1 и различных значений Ь

0, 75
0,7

о‚65 ..    

       

0 0,2 0,4 0,6 0,8 1 1,2 1,4 1,6 1,8 2
Рис. 11.7. Иллюстрация влияния параметра Ь на форму гауссовской функции
19’

292 ’ _ П‚ Математические основы нечетких систем

На нем видно, что при соответствующем подборе показателя степени Ь
(зависимость (11.25)) она может определять как функцию Гаусса, так в
треугольную или трапецеидальную функцию. Значение Ь = 1, очевидно,
соответствует стандартной гауссовской функции. Обобщенная гауссовская
функция также может быть представлена в рациональной форме:

д‚(х)=——д— (11.26)

1 + ( х - с 1
О’
которая аналогична описываемой выражением (11.25).

Помимо гауссовской функции принадлежности, на практике часто приме-
няется симметричная треугольная функция, которую можно записать в виде

 

дя (х) = д . (1117)

Интерпретация центральной точки с в
ширины д для треугольной функции
представлена на рис. 11.8. Эта функция
тоже нормирована и принимает единичное
значение в центральной точке с.

Обобщением треугольной функции
является трапецеидальная функция при-
9-4 надлежности, форма и обозначения кото-

Ри 11 8 т рой показаны на рис. 11.9.
с. . . реуюльная форма функции Если определить у=с_ 1_ 1’ 2: с+ Ь+
принадлежности 2 5 2

1
+ Ё, где в обозначает уюл наклона, то

 

трапецеидальная функция описывается зависимостью

 

Рис. 11.9. Трапецегщальная форма функции принадлежности

П‚5. Системы нечеткога вывода Шмдши-Заде 293

О для х>2 или х<у
1 для с--%$х$с+-%
дА(й)(хЁ)= $(2__х) для с+_%$х$2 
‘г

в(2——У) для у5х$с—ё—

Выбор значения 1= О редуцирует трапецеидальную функцию до треугольной
формы.

11 .5.2. Дефуззификатор

Дефуззификатор трансформирует нечегкое множество в полностью детерми-
нированное точечное решение у. Нечеткое множество представляет зависимость
д(у) = д, _‚д(у) как функцию от выходной переменной у. Преобразование этого
множества в единственное точечное решение возможно многими способами.
Наиболее известны среди них:

’ дефуззификация относительно центра области (англ.: Сетег о/Агеа)

!д(у)у‹1у
ус = !———_—— (11.29а)
1д(у)д‘у
У
либо в дискретной форме
ЕЁЦУЭУ‘
и =—Ь————— ; (11195)
ЕдОЙ)
’ дефуззификация относительно среднего центра (англ.: Сепгег Аиегаде)
М
б  с? с!
„ = #—-—-— , 11.30
у вмо/„д ‘ ’

где ус; обозначает центр й-го нечеткого правила, а д(у„д) -— значение функции
принадлежности, соответствующей этому правилу;
’ дефуззификация относительно среднего максимума (англ.: Меап о[МахЕта)

Ё)’:
ум =11-- , (11.З1)
т

где т обозначает количество точек переменной у, в которых д(у„) дости-
гает максимального значения. Если функция д(у) имеет максимальное
значение только в одной точке ушах, то ум = ушах. Если ДО’) достигает своих
максимальных значений между у; и ур, то ум=%(у\+ ур);

294  П. Математические основы нечетких систем

о в форме выбора минимального из максимальных значений у
у, -— наименьшее значение у, для которого { д (у) = шах }; (11.З2)
’ дефуззификация в форме выбора максимального из максимальных значений у
у; -— наибольшее значение у, для которого { д (у) = тах }. (11.33)
На практике чаще всего применяется дефуззификация относительно среднего

центра.
ПРИМЕР 11.5

На рис. 11.10 представлен нечеткий сигнал, полученный после агрегирования
двух правил вывода из примера 11.4.

д (У)

 

У: Ус Ум У:

Рис. 11.10. Иллюстрация влияния различных способов дефуззификации на итоговое
решение

Применение перечисленных выше способов дефуззификации приводит к
получению результатов, соответствующих точкам ус, ум, у, и у; на этом
рисунке.

11.5.3. Модель Мамдани-Заде как универсальный
аппроксиматор

Результат, интересный с точки зрения его применения в нечетких сетях, может
быть получен при использовании в качестве агрегатора оператора алгебраи-
ческого произведения с последующей дефуззификацией относительно среднего
центра. Следует ошетить, что д(у) состоит из суммы нечетких функций для
импликаций всех М правил, образующих систему нечеткого вывода. В модели
Мамдани-Заде каждое из этих М правил определяется уровнем активации

Л
условия, д(_уд)=дд‚4 (19), тогда как у; - это значение у, при котором величина д(у)

становится максимальной (либо принимает среднее из максимальных значений).
Пусть величина у; обозначает центр с; нечеткого множества заключения Е-го

!!.6. Модель вывода Таюаги-Скгено-Канаа 13 295

правила вывода. ‹Тогда дефуззификация относительно среднего центра ведет к
модели Менделя-Ванга [173], в соответствии с которой

М П
ЁС‚[ПЩ‚ 051)]

_ Ё=1 _[=1

у’???
2[ ‚и‚‚(х‚)]

1=1 1:

(11.34)

Допустим, что существует нечеткая система, описываемая зависи-
мостью (11.34), на вход которой подается последовательность векторов
х = [х;, хг, ..., хдДТ. При использовании фуззификатора в виде обобщенной
гауссовской функции д (х)=ехр [—(’:")2Ь] выходной сигнал у этой системы оп-

ределяется по формуле

(г) щ"

М Н Х] —С]

Ее; ПФХР — ‹‚‚

|=  

у= [(х)=  (1135)

м „ д „р 2‘
‚=1 ;=1 о’ ‚

в которой сЁЁсЁ" Ь?) обозначают параметры центра, ширины и формы
(условия) ]—го компонента вектора х для Е-то нечеткого правила вывода.
Выражение (11.35) определяет непрерывную функцию, которая может
использоваться для аппроксимации произвольно заданной непрерывной
функции 3(х) от многих переменных хд, образующих вектор х. В [160, 173] было
доказано, что при соответствующем подборе параметров условия (сЁЁОЁЁЬЁ) ) и
заключения (сд) функция (1135) может аппроксимировать заданную функ-
цию 3(х) с произвольной точностью г. Способность нечеткой системы,
характеризующейся рядом нелинейных функций от одной переменной, к
аппроксимации нелинейной функции от многих переменных свидетельствует о
возможностях практического применения нечетких систем. В следующем разделе
мы рассмотрим представление формулы (11.35) в виде многослойной сети со
структурой, подобной структуре нейронной сети, которая в дальнейшем будет

называться нечеткой нейронной сетью.

11.6. Модель вывода Такаги-Сугено—Канга

Наибольшую ПОПУЛЯРНОСТЬ СРЕДИ НСЧСТКИХ СИСТСМ адаптивного ТИПЗ _

приобрела модель вывода Такаги-Сутено-Канга (ТЗК) [153]. В этой модели
функция заключения определяется нечетким, но точечным образом. Благодаря

296 ‚ 11. Математические основы нечетких систем

этому дефуззификатор на выходе системы не требуется, а модель вывода
значительно упрощается. Общая форма модели ТЗК может быть пред-
ставлена в виде

если х; это А11х2 это А; 1 -—-1хд это Ад, тоу =[(х1, х2,..., хд). (1136)
В векторной записи ее можно записать еще проще:
если х это А, то у = 1‘ (х) (11.З7)

где /(х) = 1’ (хд, х2,..., хд) — четкая функция. В этой зависимости часть, относя-
щаяся к условию, точно такая же, как и в модели Мамдани-Заде. Принципиальное
отличие касается заключения, которое представляется в форме функциональной
зависимости, чаще всего - в виде полиномиальной функции нескольких пере-
менных. Классическое представление этой функции, чаще всего используемое на

практике, — ЭТО ПОЛИНОМ ПСрВОГО ПОРЯДКЕ

у=!(х)=р‹›+Ё‘3р‚х‚ . (11.38)

Ё=\

в котором коэффициенты ро, рд, ..., рд — это цифровые веса, подбираемые в про-
цессе адаптации (обучения). Еще более простая модель вывода ТЗК получается,
если применять функцию Дх) в виде полинома первого порядка, в котором

у=/‹›‹›=1›‹›‚ _ 01.39)

В этом случае значение ро можно отождествтггь с центром заключения с;
модели Мамдани-Заде, присутствующим в формуле ( 11.35).

Если в модели вывода ТЗК используется несколько (М) правил, то выход
системы определяется как их средневзвешенное. Приписывая каждому правилу
вес щ, получим выходной сигнал, представленный в виде

М
хит)’:
у=%——‚ (1140)
вщ
;=1
ИЛИ
м ш м ‚ Е
у=)3„' у‚=)3щу‚ _ (1141)
Ё=1 Ё=1

‚ 1
1=1

Необходимо огтмептть, что в выражении (11.41) веса и’; отвечают условию

М ш‘

нормализации:  М =1 . Если для каждого д-го правила (где 1 = 1, 2, ..., М)
1:! Ею]
;=1

реализуется функтщя ТЗК первого порядка

к 1
у, =рю + Ердх] ‚ (11.42)

1=1

11 .6. Модель вывода Такаги-Сугено-Канга 297

то можно получить описание выходной функции модели ТЗК в форме

м _ н
‚т: м», [до + град), (1143)
1=1 Е”! _1=
‚и зз- ;=›

которая линейна относительно всех входных переменных системы 19
для 1* 1, 2, ...,1\/‘.

Веса щ, присутствующие в формуле (11.43), являются нелинейными
параметрами функции у. В адаптивных системах они подвергаются обучению для
достижения наилучшей приспособленности модели к заданным значениям, тогда
как в неадаптивных системах они уточняюгся для определения уровня активации
условия в правиле вывода непосредственно в процессе анализа данных. Подбор
этих уровней — это результат атрегирования правил, соответствующих конкрет-
ным компонентам вектора х условия; он выполняется с использованием
логического или алгебраическото произведения так же, как это имело место в
модели Мамдани-Заде.

ПРИМЕР 11.6

Этот пример (рис. 11.11) иллюстрирует модель ТЗК с двумя правилами вывода
для системы с двумя входными переменными х; и х; (аналогично примеру 11.3

Минимум

и?’ (Х) * ‘Щ У1 ' ты Ри 11"’ та’:

д? Щ ‘ “г Уг" Рго" Р21 Х1* Рггхг

 

„Щ; ‚Д;
У у/‚дшг У! у/дшгУг

Рис. 11.11. Иллюстрация системы вывода ТЗК

298 11. Математические основы нечетких систем

для модели Мамдани-Заде). Левая часть рисунка относится к условию. Уровень
активации д‚‹(х) в этом примере определяется как логическое произведение
(минимум) от {д‚4(х1), д‚4(х1)}. Веса и’; и щ, которые учитываются при
агрегироваиии обоих правил вывода в модели ТЗК, соответственно равны:
и’; = д Я)(х), и’; = д Ё) (х). В правой части рисунка представлены соответствую-
щие формы линейной функциональной зависимости ТЗК, описывающей
заключения обоих правил вывода. Таким образом, окончательный
(агрегированный) результат вывода по этой модели ТЗК в соответствии с (11.43)

МОЖНО ПРСДСТЗВИТЬ В ВИДС

_ “’1У1+“’2У2 _ "й “2
У—'——'—'————:У1 +———У2‚
и’, + шд и’, + и’2 и1+ и’2

тел =Р1о +Р11Х1 +р12хъу2 =Р2о +Р21х1 +Р22х2- Следует Отметить. что в отличие
ОТ МОДСПИ Мамдани-Заде ВЫРЗЖСНИС, ОПИСПЯВЗЮЩЁС ВЫХОДНОй СИГНЗЛ, ЯВЛЯЁТСЯ
четким и соответственно отсутствует необходимость дефуззификации.

Раздел 12

нвчвткив нвйгонныв свти

Представленные в предыдущем разделе модели вывода Мамдани-Заде и Т$К
позволяют описать выходной сигнал многомерного процесса как нелинейную
функцию входных переменных х; (1 = 1, 2, ...‚ П) и параметров нечеткой системы
(формула (11.34) в модели Мамдани-Заде и (11.43) в модели Т$К). В литературе
[67, 160] отмечается, что эти выражения позволяют аппроксимировать с
произвольной точностью любую нелинейную функцию многих переменных
суммой нечетких функций одной переменной. Формулы (11.З4) и (11.43) имеют
модульную структуру, идеально подходящую для системного представления в
виде равномерной многослойной структуры, напоминающей структуру клас-
сических нейронных сетей. В дальнейшем мы будем называть их нечеткими
нейронными сетями (анпъ: пеиго/йггу петог/сз). Характерной особенностью этих
сетей является возможность использования нечетких правил вывода для расчета
выходного сигнала. В отличие от классических нечетких систем (англлйагу 1о31с)
в них вместо непосредственного расчета уровня активации конкретных правил
вывода выполняется адаптивный подбор параметров функции фуззификации. Мы
обсудим структуру таких сетей, а также алгоритмы обучения, способные
адаптировать и линейные веса (аналогично тому, как это производилось в
классических сетях), и параметры нечетких функций фуззификатора (аналогично
параметрам гауссовской функции в сетях КВР).

12.1. Структура нечеткой сети Т$К

Ка
Обобщенную схему вывода в модели Т$К при использовании М правил и Ы

ПСРСМСННЫХ  МОЖНО ПРСДСТЗВИТЬ В ВИДС

!Р(х1.1& А}").‚лмв.(х1_щ А;").Аи0.  _ АА/В.(х„1& А 15"),

и
ТНЕЫ У1=Рю "' ЁРцх;
1=1

   02.1)
1Р(х1.1& А{‘”‘>)_Амв.(х‚.1в. А;Щ).А1\Ю.  .А1\/В.(хм1$. А у"),

и
ТНЕЫ Ум =Рм0 + ЁРщх; -
1=1

300 12. Нгчгткиг нейронные сети

Условие 1Г(х;. 1.5’. Ад) реализуется функцией фуззификации, которая пред-
ставляется обобщенной функцией Гаусса отдельно для каждой переменной хд:

1
д‚‹(х:)=————————‘—5; ‚ (121)
1+ х’ ‘т’
б:

где ‚щ (хд) представляет оператор Ад. В нечетких сетях целесообразно задавать это
условие в форме алгебраического произведения, из которой следует, что для
/с-го правила вывода

1

(‘о = ” ———————————‚‚‚‹„
„А (х)  х _с(1‚) 1 . (123)
1= я 1
1+ ОШ
1

При М правилах вывода агрегирование выходного результата сети производится
по формуле (11.43)‚ которую можно представить в виде

у‹›=›= д‘ Ё‘:›«‚‚»‚‚‹х›‚ 014)
Е”! 1с=1

и
где у‚‚ (Х)=Рьо + ХРАМ; . Присутствующие в этом выражеъши веса щ интер-
претируются как ‘значимость компонентов д_$"’(х), определенных формулой
(12.3). При этом условии формуле (12.4) можно сопоставить много-
слойную структуру сети, изображенную на рис. 12.1. В такой сети выделяется

ПЯТЬ СЛОСВ.

’ Первый слой выполняет раздельную фуззификацию каждой переменной
х;(1 = 1, 2, ..., Н), определяя для каждого К-го правила вывода значение
коэффициента принадлежности д;")(х‚) в соответствии с применяемой
функцией фуззификации (например, (12.2)). Это параметрический слой с
параметрами сЁЁЁОЁЁЁЬЁ” , подлежащими адаптации в процессе обучения.

О Второй слой выполняет атрегирование отдельных переменных хд, определяя
результирующее значение коэффициента принадлежности и’), = дЁ‹")(х) для
вектора х (уровень активации правила вывода) в соответствии с формулой
(12.3). Это слой непараметрический.  ‚А‘

’ Третий слой представляет собой генератор функции ТБК, рассчитыватощий

А’
значения у,‚ (х) = р“, + Е рдх] . В этом слое также производится умножение
1=1

сигналов у), (х) на значения щ, сформированные в предыдущем слое. Это
параметрический слой, в котором адаптации подлежат линейные веса
рц для 1: = 1, 2, ..., М и 1 = 1, 2, ..., М определяющие функцию следствия
модели ТБК.

12.1. Ствгшша нечеткой сети ШК 301

’ Четвертый слой составляют два нейрона-сумматора, один из которых

рассчитывает взвешенную сумму сигналов уд (х), а второй определяет сумму
м

весов ЕМ . Это непараметрический слой.
[‹=

Рис. 12.1. Структура нечетной нейронной сетн Т$К

’ Последний, пятый слой, состоящий из единственного выходного нейрона, —
это нормализующий слой, в котором веса подвергаются нормализации в
соответствии с формулой (12.4). Выходной сигнал у(х) определяется
выражением, соответствующим зависимости (11.43),

у‹›‹›=/‹›‹›=д ‹ _ “2-5)
л

Это также непараметрический слой.

302 „_ 12. Нечеткиг нейеенныг сети

Из приведенного описания следует, что нечегкая сеть ТЗК содержит только
два параметрических слоя (первый и третий), параметры которых уточняются в
процессе обучения. Параметры первого слоя будем называть нелинейными
параметрами, поскольку они относятся к нелинейной функции (12.2), а
параметры третьего слоя — линейными весами, так как они относятся к
параметрам руд линейной функции ТБК.

При уточнении функциональной зависимости (12.4) для сети ТЗК получаем:

1 м и Ш к
У(х)=—‚;—7‚——————‚ё цдя (Ку) Рьо+ёряуху - (12-6)
= ‚=
‚;{Ци$"(х;›] ’ " "

Если принять, что в конкретный момент времени параметры условия
зафиксированы, то функция у(х) является линейной относительно переменных хд
(1= 1, 2, ..., М.

При наличии А’ входных переменных каждое правило формирует МН
переменных р?) линейной зависимости ТЗК. При М правилах вывода
это дает М(1\’+1) линейных параметров сети. В свою очередь, каждая функция
принадлежности использует три параметра (с, з, Ь), подлежащих адаптации.
Если принять, что каждая переменная х; характеризуется собственной
функцией принадлежности, то при М правилах вывода мы получим ЗМН
нелинейных параметров. В сумме это дает М(41\’+1) линейных и нелиней-
ных параметров, значения которых должны подбираться в процессе обучения
сети.

На практике для уменьшения количества адаптируемых параметров
оперируют меньшим количеством независимых функций принадлежнос-
ти для отдельных переменных, руководствуясь правилами, в которых ком-
бинируются функции принадлежности различных переменных. Если при-
нять, что каждая переменная х; имеет т различных функций принадлеж-
ности, то максимальное количество правил, которые можно создать при
их комбинировании, составит: М = т” (при трех функциях принадлежности,
распространяющихся на две переменные, это 32 = 9 правил вывода). Таким
образом суммарное количество нелинейных параметров сети при М правилах
вывода уменьшается с ЗМЧ в общем случае до ЗЛМШ. Количество ли-
нейных параметров при подобной модификации остается без изменений,
т.е. М(1\’+1).

12.2. Структура сети Ванга-Менделя

Если использовать в качестве основы дальнейших рассуждений выражение
(1135), вытекающее из модели вывода Мамдани-Заде, можно получить структуру
нечеткой сети (рис. 12.2), определенную Л.Вангом и Дж.Менделем [160].

12. 2. ‘Смерти сети Ванга-Менделя А‘ 303

  четырехслойная структура, в которой первый слой выполняет фуззи-
фикацию входных переменных, второй — агрегирование значений активации усло-
вия, третий (линейный) - агрегирование М правил вывода (первый нейроп) и
генерацию нормализующего сигнала (второй нейрон), тотда как состоящий из
одного нейрона выходной слой осуществляет нормализацию, формируя выходной
сигнал у(х). Только первый и третий слои являются параметрическими. В первом
слое это параметры функции фуззификации (с}*’‚о‘}"’,1›}"’ )‚ а в третьем слое —
веса щ, щ, ..., ум, интерпретируемые как центр с; функции принадлежности
следствия 1с-го нечеткого правила вывода. Представленная на рис. 12.2 сетевая
структура реализует функцию аппроксимации (11.34)‚ которую с учетом
введенных обозначений можно записать в виде

1 “‘ ” и‘)
— к . А 1 . .
_у‹х›—„ „ ‚С Е» дн (х) (т)
д[пи$’‹х‚›]

Рис. 12.2. Структура нечеткой нейронной сети Ванга-Менделя

304 12. Нечеткие нейронные сети

Следует отметить большое сходство струкхуробеих нечетких сетей. Части,
определяющие условие — первый и второй слои - у них идентичны, поскольку
они соответствуют компонентам правил вывода “Н?  “, одинаково
представляемым и в модели Мамдани-Заде, и в модели ТБК. Различия
наблюдаются в представлении компонентов “ТНЕН ...”. В сети ТЗК результат
представляется полиномом первого порядка. В сети Ванга——Менделя результат
представляется константой (щ‚=с;‚), которую можно рассматривать как полином
нулевого порядка, определяющий центр функции принадлежности следствия.
Таким образом, с функциональной точки зрения сеть Ванга-Менделя подобна
сети ТЗК, а точнее — является ее частным случаем.

Задача обеих сетей (ТЗК и Ванга-Менделя) состоит в таком отображении
пар данных (х, д), чтобы ожидаемое значение, соответствующее входному
вектору х, формировалось выходной функцией сети у(х). Несмотря на то, что
приведенные рассуждения касаются сетей с одним выходным нейроном, они
могут быть обобщены на случай систем с несколькими выходами.

Обучение нечетких сетей, так же как и классических сетей, может
проводиться либо по алгоритму с учителем, основанному на минимизации
целевой функции, задаваемой, как правило, с использованием эвклидовой
нормы как

1 ‹‘›

Е=Е;‚(у(хш)—д )2 ‚ (12.8)
где р обозначено количество обучающих пар (х, д), либо по алгоритму
самоорганизации, согласно которому выполняется группирование (кластери-
зация) данных.

12.3. Гибридный алгоритм обучения
нечетких сетей

Гибридный алгоритм применяется к обеим описанным выше сетевым
структурам. Сеть Ванга-Менделя может при этом трактоваться как
сеть ТБК, в которой все параметры (кроме подлежащего уточнению ц = рдо)
рд (1с= 1, 2, ...‚ М] = 1, 2, ...‚ Н) тождественно равны нулю. Поэтому дальнейшие
рассуждения будут касаться сети ТЗК как более общей, чем сеть Ванга—Менделя.

В гибридном алгоритме подлежащие адаптации параметры разделяются на
две группы. Первая из них состоит из линейных параметров рд третьего
слоя, а вторая группа — из параметров нелинейной функции принадлежности
первого слоя. Уточнение параметров проводится в два этапа.

’ На первом этапе при фиксации определенных значений параметров функции
принадлежности (в первом цикле — это значения, полученные в резуль-
тате инициализации) путем решения системы линейных уравнений

12.3. Гиб идный алго птм ения нечетких сетей 395

рассчитываются линейные параметры рд полинома ТЗК. При известных
значениях функции принадлежности зависимость ( 12.6) можно представить в
линейной форме

м ‚ и
И") = ЕЩЁ“; + Едут) , ‹12.9)
= ‚‚
ГДС
й 113410051)
и} =—‚;‚д%-——-——-=с‹›п“ ‘ (1210)
г= 1:
;[ц„т‹›‹‚›]

для К = 1, 2, ..., М. Прир обучающих выборках (ха), дю) (1 = 1, 2, ..., р)
и замене выходного сигнала сети ожидаемым значением д“) получим систему
из р линейных уравнений вида

Рю
М, тих?’  тих}?  и“, шЁМхЁ”  Щмх}?  д")
(1) (1) ) (2) 1”
и’; шьх,  шьхд,  нём шэмхр ...и’;Мх„ = (10) (1211)
ОП: , д
‹ › › ‹ › ‹ › рт
т}, шьх,’  шъдх}?  нём шэмх,’ ...и’;‚мх,„5’ д“)

Рш

где ищ обозначает уровень активации (вес) условия ё-го правила при
предъявлении 1с-го входного вектора х. Это выражение можно записать в

сокращенной матричной форме _
А р = 41 . (12.12)

Размерность матрицы А равна р х (1\’+ 1)М при этом обычно количество строк
значительно больше количества столбцов (Л + 1)М Решение этой системы
уравнений можно получить за один шаг при помощи псевдоинверсии

матрицы А

р =А+а. (1243)

Псевдоинверсия матрицы заключается в проведении декомпозиции
ЗУВ с последующим сокращением ее размерности так, как это пред-
ставлено в разделе 5. Подробности вычислительной реализации алгоритма
ЗУВ можно найти, например, в работе Е Голуба и К. ВанЛоана [42].

На втором этапе после фиксации значений линейных параметров рд
рассчитываются фактические выходные сигналы у(1) сети для Е = 1, 2, ..., р,

20-2162

306 _ «та 12. Нечеткие ней нныг сети

   

ДЛЯ ЧСГО ИСПОЛЬЗУСТСЯ линейная ЗЗВИСИМОСТЬ

и следом за ними - вектор ошибки г = у -— (1. Сигналы ошибок направляются
через подключенную сеть по направлению ко входу сети (обратное
распространение) вплоть до первого слоя, где могут быть рассчитаны
компоненты градиента целевой функции относительно конкретных
параметров сЁЁЁаЕЁЁЬу”. После формирования вектора градиента пара-
метры уточняются с использованием одного из градиентиых методов
обучения. Если применяется простейший метод наискорейшего спуска, то
соответствующие формулы адаптации принимают форму:

дв

су’ (п + 1) =с;"’(„) —п„ дсёз) , ‹12.15)

1

дв
а;"’‹„+1)=а;"’‹„)—п„ дай? , (12.16)

1

Ь}"’(п+1)=1›}"’(п›—п‚‚ ад") (1217)

(Н ’
_ дЬ]
где п обозначает номер очередной итерации.

После уточнения нелинейных параметров вновь запускается процесс
адаптации линейных параметров функции ТЗК (первый этап) и нелинейных
параметров (второй этап). Этот цикл повторяется вплоть до стабилизации всех
параметров процесса. Формулы (12.15)-(12.17) требуют расчета градиента
целевой функции относительно параметров функции принадлежности.
Окончательный вид этих формул зависит как от используемого определения
функции погрешности на выходе сети, так и от формы функции принадлежности.
Например, при использовании обобщенной функции Гаусса

1

х_с 2ь
а
соответствующие формулы градиента целевой функции (12.8) для одной пары

обучающих данных (х, (1) принимают вид

дЕ
дсу»

‚ид(х)= (12.18)

м и дш:
=(у(х)—д)ё гпмёрдх; дсу, , 92.19)

- к

12.3. Г ибвидный алгоеитм общения нечетких сетей _ ‚ 307

дЕ м ‘Ч д»;

806“ й(у(х)"а)ё[рг0 +ё117дхх|дбуд ‚ 
дЕ М ‘Ч д»;

(ж, = (их) — ‘Парт + это] аду . ‹12.21)

д”; д»; д»;

а“) И дь“) , ОПРСДСЛСННЫЕ на ОСНОВС ЗЗВИСИМОСТИ
1 1

дсш ’ д
1
(к) _ (к) “у”
2Ь‚ х] с]
‹’‹› ‹’‹›
О]  ‹

Производные

(12.10) и (12.18)‚ можно записать как

ЭИ’, 5гкт(х_;)—1(х;) д’ (д)
’ =—————————— ‚ —————‘—————————, 1 .2
дсуд [тосд]: ЬЕЬЁА (х Л Ё „Е“ д (2 2)
’ 1 х] —с}’
+ ————ППОЁ„
  _с;,‚› ]2Ь$Н
Ч‘) 9-9‘)
дм ‹$‚ ‹ —›—‘‹х‚› и "1 1
д, =—-Ш>7+ пи1Ь*’‹х‚›1—-——————-————;—Т‚ 02.23)
до’ ‚ [т(х])] г=1,‹=ь; (‚д 2ь}’
1+ —————х’ _с’
су‘)
д”; =бг1‹т(х_;)—](х])х
ЭЬУ” (мод)?
_ "1—СЁК‚› Щи д“?
ь
м Ш 6%) 63"
>< ПША (Хд1  ‚ (1214)

‘=1‚‘==1 х _сш щ" 2
1 1
1+ --—-—-—(‚‚)
‘д’;

м
для г = 1, 2, ..., М где 8,1, обозначает дельту Кронекера, 1(х‚)=Пд&“(х‚)‚
’=1

М д’ 1
т(х‚)=‚; цд}‹"’(х‚):|_ Несмотря на сложную структуру приведенных фор-
= ,=

мул, выражающих компоненты вектора градиента, оъш позволяют аналити-
чески определить величины, необходимые для уточнения параметров нечеткой
сети.

При практической реализации гибридного метода обучения нечетких сетей
доминирующим фактором их адаптации считается первый этап, на котором веса
рд подбираются с использованием псевдоинверсии за один шаг. Для

20’

308  ч- —== 12. Нечеткие ней нные сети

уравновешивания его влияния второй этап (подбор нелинейных параметров
градиентным методом) многократно повторяется в каждом цикле.

Представленный гибридный алгоритм — один из наиболее эффективных
способов обучения нечетких сетей. Его главная черта состоит в разделении
процесса обучения на два обособленных во времени этапа. На каждом этапе
уточняется только часть параметров сети. Если принять во внимание, что
вычислительная сложность каждого алгоритма оптимизации пропорциональна
(нелинейно) количеству параметров, то уменьшение размерности задачи
оптимизации существенным образом сокращает количество математических
операций и увеличивает скорость выполнения алгоритма. Благодаря этому
гибридный алгоритм значительно более эффективен, чем обычный градиентный
алгоритм фронтального типа, согласно которому уточнение всех параметров сети
производится параллельно и одновременно.

12.4. Применение алгоритма самоорганизации
для обучения нечеткой сети

Алгоритм самоорганизации приписывает вектор х к соответствующей группе
данных, представляемых центром сд, с использованием обучения конкурентного
‘типа подобно том); как это имело место в сетях с самоорганизацией Кохонена.
При обучении этого типа процесс самоорганизации становится возможным при
предъявлении вектора х. Базовая форма алгоритма самоорганизации позволяет
точно определять положение центров с; соответствующих групп данных
(кластеров), на которые подразделяется многомерное пространство. Эти центры в
последующем могут использоваться в гибридном алгоритме обучения нечеткой
сети в качестве начальных значений, что существенно ускоряет процесс обучения
и гарантирует сходимость решения к глобальному минимуму

12.4.1. Алгоритм нечеткой самоорганизации С-теапз

Допустим, что в сети существует К нечетких нейронов с центрами в точках с;(1=
1, 2, ..., К). Начальные значения этих центров могут быть выбраны случайным
образом из областей допустимых значений соответствующих компонентов
векторов ‚х; (1 = 1, 2, ..., р), использованных для обучения. Пусть функция
фуззификации задана в форме обобщенной функции Гаусса, выраженной
формулой (122).

Подаваемый на вход сети вектор до будет принадлежать к различным гругшам,
представляемым центрами сд, в степени ид, причем О 5 ид 5 1, а суммарная
степень принадлежности ко всем группам, очевидно, равна 1. Поэтому

к ‚‚ .‚
Еид =1 (12.25)

Ё=1

для 1 = 1, 2, ..., р. Функцию погрешности, соответствующую такому

 

12.4. П имгнгние алго итма самоо ганизации для ения нечеткой сети 309

представлению, можно определить как сумму частных погрешностей принад-
лежности к центрам с; с учетом степени принадлежности  Следовательно,

К
в= 3 Ёит м с, —х‚ м’ , (12.26)

где т — это весовой коэффициент, который принимает значения из интервала
[1, Ф’). Цель обучения с самоорганизацией состоит в таком подборе центров с),
чтобы для заданного множества обучающих векторов яд обеспечить достижение
минимума функции (12.26) при одновременном соблюдении условий
ограничения (1225). Таким образом возникает задача минимизации нелинейной
функции (12.26) с р ограничениями типа (12.25). Решение этой задачи можно
свести к минимизации функции Лагранжа, определенной в виде [60]

К П ‚и 2 К -
ЬЕ=;;:„„ (щ-хд) +Ёя‚(;„„—1 , (1227)

Ё=1 _[=1 ]=1 Ё=1

где Я.) (] = 1, 2, ..., р) — это множители Лагранжа. В [60] доказано, что решение
задачи (12.27) можно представить в виде

Ёигх]
с— = ‘— (12.28)

1’
т
Ёиу

!=1

„.. =———1——— ‚ (1229)

и 1
2 —1
к дд т

‚Ещё

где дд — это эвклидово расстояние между центром с; и вектором ‚ч,
ф; = "с; — 39". Поскольку точные значения центров с; в начале процесса не
известны, алгоритм обучения должен быть итерационным. Он может быть
сформулирован в следующем виде.

1. Выполнить случайную инициализацию коэффициентов ид, выбирая их
значения из интервала (О, 1] таким образом, чтобы соблюдалось условие
(12.25).

2. Определить К центров с; в соответствии с ( 12.28). 

3. Рассчитать значение функции погрешности согласно выражению (12.26).
Если ее значение окажется ниже установленного порога либо если
уменьшение этой погрешности относительно предыдущей итерации
пренебрежимо мало, то завершить вычисления. Последние значения центров
составляют искомое решение. В противном случае перейти к п. 4.

4. Рассчитать новые значения ид по формуле (12.29) и перейти к п. 2.

Такую процедуру нечеткой самоорганизации будем называть алгоритмом

С-теапв.

310 Ч“ 12. Нечеткие найденные сети

Многократное повторение итерационной процедуры ведет к достиже-
нию минимума функции Е, который необязательно будет глобальным
минимумом. Качество находимых центров, оцениваемое значением функции
погрешности Е, существенным образом зависит‘ от предварительного подбора
как значений иг, так и центров сд. Наилучшим может быть признано такое
размещение центров, при котором они располагаются в областях, содер-
жащих наибольшее количество предъявленных векторов ‚ху. При таком подборе
центров они будут представлять векторы данных 29 с наименьшей суммарной
погрешностью.

Поэтому начало итерационной процедуры расчета оптимальных значений
центров должно предваряться процедурой их инициализации. К наиболее
известным алгоритмам инициализации относятся алгоритмы пикового
группирования и разностного группирования данных.

12.42. Алгоритм пикового группирования

Алгоритм пикового группирования был предложен Р. Егером и Д. Филевым
[6О, 173]. В качестве меры плотности размещения векторов 29 в нем генери-
руются так называемые пиковые функции. При использовании р входных век-
торов создается сетка, равномерно накрывающая пространство векторов ху.
Узлы этой сетки рассматриваются как потенциальные центры и, и для каждого
из них рассчитывается пиковая функшы т(\’)

н»—›‹‚ н”
‚ .

12.30
20 ( )

т(\’) = Ёехр -
1=1 ‚

Коэффициент а - это константа, индивидуально подбираемая для каждой
конкретной задачи, а Ь - показатель степени обобщенной функции Гаусса, кото-
рая применяется в нечеткой сети.

Величина функции т(\›) рассматривается как оценка высоты пиковой
функции. Она пропорциональна количеству векторов ху, находящихся в
окрестности потенциального центра п’. Малое значение т(\’) свидетельствует о
том, что центр 1’ располагается в области, в которой сосредоточено неболь-
шое количество векторов ‚хд. Следует обратить внимание, что коэффициент
о’ оказывает незначительное влияние на итоговые пропорции между
т(\’) для различных значений 1’, поэтому подбор его величины не является
критичным.

После расчета значений т(\’) для всех потенциальных центров среди них
отбираются первые (сд), имеющие наибольшее значение т(\’). Для выбора
следующих центров необходимо прежде всего исключить с; и узлы,
расположенные в непосредственной близости от сд. Это можно сделать путем
переопределения пиковой функции за счет отсечения от нее функции Гаусса с

12.4. П енение алго итма самоо ганизацтт для гния нечеткой сети 311

центром в точке с). Если эту вновь определяемую функцию обозначить
ттш (г), то получим

Н ‘›—х— Н" .‚
1 . (1231)

 

тпсш(р)=т(р)—т(с1)ех ‘-

20

Необходимо обратить внимание, что новая функция ‚„„;;;Ё‘Е»5”""й’меет
нулевое значение в точке сд. Рис. 12.3 иллюстрирует типичный процесс
пикового группирования в двумерном пространстве [60]. На рис. 12.30
показан трафик исходной функции т(\’), на рис. 12.36 — график функции
тпш (г) после отсечения первого центра в точке сд, на рис. 12.3в - график после
отсечения второго центра в точке сд, а на рис. 12.32 — после отсечения третьего
центра в точке с3. Заметно, что последовательное отсечение центров (с
максимальными значениями пиковой функции) позволяет обнаруживать и

устранять очередные центры.

 

Рис. 12.3. Иллюстрация функционирования алгоритма пикового группирования

Процесс нахождения следующих центров с2, с3,  осуществляется
последовательно на модифицированных значениях функции тпш (г), полу-
чаемых при исключении ближайшего окружения центра, обнаруженного на
предыдущем этапе. Он завершается в момент локализации всех центров,
используемых в модели нечеткой сети. Метод пикового группирования
эффективен, если размерность вектора х не слишком велика. В противном
случае (при большом количестве компонентов х) число потенциальных

312 ‚‚ ‚ „ 12. Нечеткие ЕЕ’ иные сети

центров нарастает лавинообразно‚ и процесс расчета очередных пиковых
функций становится слишком длительным, а процедура малоэффективной.

12.4.3. Алгоритм разностного группирования

Алгоритм разностного групгшрования данных — это модификация предыдущего
алгоритма, в которой обучающие векторы х, рассматриваются в качестве потен-
циальных центров и Пиковая функция В(х;) в этом алгоритме задается в виде

ч

119
0(‚‹‚)=Ёе›‹ —ЁЁ—1‘%Ё— _ (1232)

!=1 га

2 7

Значение коэффициента п, определяет сферу соседства. На значение
В(хд) существенным образом влияют только те векторы 19, которые распо-
ложены в пределах этой сферы. При большой плотности точек вокруг х;
(потенциального центра) значение функции В(х;) велико. Напротив, малое ее
значение свидетельствует о том, что в окрестности х; находится незначи-
тельное количество данных. Такая точка считается “неудачным” кандидатом в
центры. После расчета значений пиковой функции для каждой точки ‚х;
отбирается вектор х, для которого мера плотности 0(х) оказалась наи-
большей. Именно эта точка становится первым отобранным центром сд.
Выбор следующего центра возможен после исключения предыдущего и всех
точек, лежащих в его окрестности. Так же, как и в методе пикового груп-
пирования, пиковая функция переопределяется в виде

рпеш(х!) = Щхд-Щсдехр — (1133)

При новом определении функции В коэффициент п, обозначает новое
значение константы, задающей сферу соседства очередного центра. Обычно
соблюдается условие гдггд. Пиковая функция В„е„‚(х‹) принимает нулевое
значение при х; = с; и бхшзка к нулю в ближайшей окрестности этой точки.

После модификации значений пиковой функции отыскивается следующая
‘ючка х, для которой величина 0„„‚(х) оказывается максимальной. Эта точка
становится следующим центром сг. Процесс поиска очередного центра
возобновляется после исключения компонентов, соответствующих уже
отобранным точкам. Инициализация завершается в момент фиксации всех
центров, предусмотренных начальными условиями.

В соответствии с описанным алгоритмом происходит самоорганизация
множества векторов х, состоящая в нахождении оптимальных значений цент-

124. Пшшенегше алгоеитма самоовёенизании для общения нечеткой сети 313

бёв,‘ представляющих множество данных с минимальной погрешностью.
Если мы имеем дело с множеством обучающих данных в виде пар векторов
(хдйд) так, как это происходит при обучении с учителем, то для нахождения
центров, соответствующих множеству векторов ф, достаточно сформировать
расширенную версию векторов х в форме

х; ‘- [хдйд]. (12.32)

Процесс группирования, проводимый с предъявлением расширенных
векторов хд, позволяет определить также расширенные версии центров сд. Если
принять во внимание, что размерность каждого нового центра равна сумме
размерностей векторов х и 11, то в описании этого центра можно легко выделить
часть р, соответствующую векторам х (первые А’ компонентов), и остаток 11,
соответствующий вектору д. Таким образом можно получить центры как входных
переменных, так ожидаемых выходных значений

с: = [Рь 011 (1235)

для Е= 1, 2, ..., К. В случае применения нечетких правил с одним выходом векторы
с! и 9 сводятся к скалярным величинам 11 и 9 соответственно. Таким образом, при
использовании правила вывода Ванга—Менделя процесс самоорганизации
позволяет восстановить функцию / (х), аппрокснмирующую множество данных
(хдйд) для 1 = 1, 2, ..., р. В частности, при введенных выше обозначениях фор-

мула (12.7) принимает вид:

(12.36)

 

согласно которому все центры подбираются оптимальньпи образом. При этом
остальные параметры (Ьд, 01), менее критичные для сходимости алгоритма,
могут эффективно подбираться гибридным методом при небольшом количестве
итераций. Конечно, итерационньхй процесс при реализации гибридного метода
охватывает также и расчеты координат центров, однако с учетом их удачного
начального размещения изменения, вносимые в процессе обучения, обычно
оказываются очень незначительными.

12.4.4. Алгоритм нечеткой самоорганизации
Г устафсона—Кесселя

В классическом алгоритме С-теапз, представленном в подразделе 12.41, нейрон-
победитель выбирается на основании обычного эвклидового расстояния между
вектором х и центром с кластера, т.е.

‘1(х‚г) =н›‹—сн= ‚/(›‹-с)‘(х-с› . (1231)

314 12. Нечеткие нейеонные сети

Определенное таким образом расстояние учитывалось в формуле (1226),
характеризующей значение функции погрешности. При подобном задании меры
расстояния между двумя векторами множество точек, равноудаленных от
центрального нейрона (победителя), принимает форму окружности с одина-
ковым масштабом по всем координатам. Если входные данные образуют
группы, форма которых отличается от окружности, либо если шкалы значений от-
дельных координат вектора сильно различаются, рассчитанные значения
будут отражать принадлежность векторов х конкретньпи кластерам. В такой
ситуации качество группирования можно существенно повысить за счет
применения усовершенствованной версии алгоритма самоорганизации,
называемой алгоритмом Г устафсона—Кесселя (ГК) [185].

По отношению к обычному алгоритму С-теапз главное изменение состоит во
введении в форщлу расчета расстояния между векторами масштабирующей
матрицы А. При этом масштабированное расстояние между вектором х и цент-

ром с определяется по формуле

с1(х,с)=|| х —‹ ||= `‚(х—с)ТА(х -с) . (12.38)

Легко показать, что определенная таким образом мера расстояния
масштабирует единичный вектор ед, где е; = [О, О, ..., О, 1, О, ..., 017,
пропорционально квадратному корню б-го диагонального значения матрицы А.

Вследствие этого
Н е ||= «ИМ = М“ . (1239)

В качестве масштабирующей обычно применяется симметричная
положительно определенная матрица, т.е. матрица, у которой все собст-
венные значения являются действительными и положительными. Множество
собственных векторов, удовлетворяющих таким собственным значениям,
образует в этом случае ортогональную базу многомерного пространства. В новом
масштабированном пространстве длины нормированных собственных векторов
матрицы А трансформируются согласно формуле

и“? и =\}\’{А"г =\“’{я:”г =\м:"{\’: =Л - (12-40)

Таким образом, длины собственных векторов масштабируются с

коэффициентом  .

Так же как и при использовании алгоритма С-теапв, цепь обучения сети с
применением алгоритма Г устафсона-Кесселя состоит в таком размещении
центров, чтобы минимизировать функцию погрешности, определяемую в
несколько более общем виде, а именно

к р т 1 .
Е=>32идд (х‚‚с‚), (1241)
:=1;=1

12.1‘. Наш’ ененй?’ а самооёантвшии для общения нечеткой сети 315

где расстШние между вектором ‚ц и центром с; определяется с учетом
масштабирования как

‹1(х‚‚‘‚) = (х, —‘‚)’А‚(х‚ щ) _ (1242)

РЕШЕНИЕ задачи ОПТИМЗЛЬНОГО размещения ЦЕНТРОВ ПО алгоритму
Густафсона-Кесселя происходит так же, как и по алгоритму С-теапь‘ путем
многократного пересчета коэффициентов принадлежности ид по формуле
(12.29) и координат центров с; по формуле (12.28)‚ но с учетом масштабиро-

вания при расчете расстояний. Алгоритм Г устафсона-Кесселя может быть ‚

сформулирован в следующем виде.

1. Произвести начальное размещение центров в пространстве данных. Эта
инициализашы может быть случайной или основанной на результатах
пикового или разностного группирования данных. Создать элементарную
форму масштабирующей матрицы Ад.

2. Сформировать матрицу коэффициентов принадлежности всех векторов
196 = 1, 2, ..., р) к центрам с;(1 = 1, 2, ..., К) путем расчета значений ид по
формуле

1
и) =——————————;— , (1243)

‚‹ а‘(х‚,с‚) 75

Е

1‹= ‹1 2 (х ‚ , с ‚„ )
где (12 (19, сд) определяется из выражения (12.42). Если для некоторого
1 = 1 фд= О, то принять и); = 1 и ид = О для всех], отличных от Ъ
3. Рассчитать новое размещение центров в соответствии с формулой

Ёиёрх;
с, = д———— . (1244)
Ёи;

1=\
4. Сгенерировать для каждого центра матрицу ковариации 8;

8, = Ёи;'(х‚ -с‚)(х] -с‚)т , Ё(12,45)

;=1
5. Рассчитать новую масштабирующую матрицу для каждого д-го центра
(Е=1,2, ...,К) по формуле
А‚ =”‹1е‘($‚›$:' ‚ (1146)

‘где А’ обозначает размерность входного вектора х.

6. Если последние изменения положений центров и матрицы ковариации
пренебрежимо малы по отношению к предыдущим значениям и не
превышают изначально заданной пороговой величины г, то завершить
итерационный процесс; в противном случае перейти к п. 2.

316 . шпдтп т" _  ‚ 12. Нечеткие нейгные сети

Функционирующий таким образом алгоритм обучения параллельно
генерирует все центры самоорганизующихся нечетких нейронов и связанные с
ними масштабирующие матрицы, используемые при расчете расстояний. По
завершении процесса обучения как положения центров,‘так и значения элементов
масштабирующих матриц фиксируются и могут использоваться в режиме
эксплуатации сети.

Работа алгоритма будет проиллюстрирована на примере множества данных,
изображенных на рис. 12.4.

6

 

Рис. 12.4. Распределение данных на четыре группы с неравномерной структурой

Это множество образовано четырьмя группами данных, сгенерированных
случайным образом и размещенных в окрестностях центров со следующими
координатами (х, у):

( 9‚ 5)‚

( О’ —5)’

( 0,7, О),

(—0,7, О).

Разбросы данных по осям О-х и О-у составляют: (1.5, 0,2) - для первого
кластера, (1.5, 0,2) - для второго кластера, (0,6‚ 4) - для третьего кластера и
(0,6‚ 4) — для четвертого кластера. Главная проблема группирования этих
данных состоит в том, что граничные данные вытянутых кластеров лежат ближе
к центру соседнего кластера, чем своего собственного. Поэтому применение
обычного алгоритма С-теапв привело бы к некорректной классификации данных.

С помощью нечеткой самоорганизации Г устафсона—Кесселя уточнено
размещение 4 центров и рассчитаны соответствующие им матрицы ковариации.

12.4. Пженение алгоштма самооеганизаиии для обучения нечеткой сети 317

Окончательные координаты центров, найденные алгоритмом ГК, равны:

первый центр: ( О,О197, - 4‚9914),

второй центр: ( 0,7085, — 0,1310),

третий центр: (-0,7080, — 0‚О951)‚

четвертый центр: (—О‚0895, 4,9894).

Заметно, что воссозданные алгоритмом позиции центров лишь незна-
чительно отличаются от принятых начальных координат центральных точек
областей, в которых случайным образом генерировались данные. Матрицы
трансформации, соответствующие конкретным нейронам, имеют вид: `

А _ О,2130 О,О224 А _ 5,7251 -О,О787
1‘ О,О224 4,б999 ’ 2 _ —О,О787 О,176О ’

А = 55401 о‚о2в1 А _ 0,1681 о,оо41
3 0,026! 0‚1812 ’ 4 ` 0,0041 5,9460 '

На рис. 12.5 представлены результаты самоорганизации тестовых данных из
примера в режиме эксплуатации. Вокруг каждого центра размещены равно-
удаленные тшнии тестовых данных, образующие эллипсовидную структуру Все
точки расположены внутри области, ограниченной внешним зллипсом. Это
свидетельствует о корректном упорядочении данных по конкретным областям.

 

Рис. 12.5. Распределение тшний равной удаленности данных о’т центров
соответствующих кластеров, полученное с помощью алгоритма Г К

Обратим внимание, что независимо от способа реализации алгоритма
обучения сеть с нечеткой самоорганизацией выполняет нечеткое группирование
данных путем приписывания их к различным центрам на основе коэффициентов
принадлежности, значения которых изменяются от нуля до единицы. Это
означает, что каждый вектор х представляется множеством центров, причем
влияние каждого из них на значение вектора различно и зависит от величины

3 18 7 12. Нечеткие нейшнные сети

коэффициента принадлежности. Если принять, что вектор ‚у представляется К
центрами с; (5 = 1, 2, ..., К), а принадлежность вектора к каждому центру
задана коэффициентом ид (формула (12.43)), то реконструкция исходного век-
тора 19 происходит согласно выражению

К

х] = анус; . 

ЗЗМСТНО, ЧТО ВЛИЯНИЕ КЗЖДОГО ЦеНТра На ОКОНЧаТСЛЬНОС ЗнаЧСНИС
рВКОНСТрУИрОВЗННОГО ВеКЮра различно и Зависит‘ от раССТОЯНИЯ Между ЭТИМ
центром и исходным вектором х. В этом существенное отличие нечеткой
СЗМООрГЗНИЗЗЦИИ ОТ КЛЗССИЧССКОЙ СЗМООрГгП-КИЗЗЦИИ КОХОНСНЗ, при КОТОрОЙ
реконструкция вектора выполняется исключительно на базе одного центра,
ближайшего данному вектору путем простого приписывания ему значения этого

центра.

12.4.5. Сеть с нечеткой самоорганизацией
в гибридной структуре

При практической реализации систем с нечеткой самоорганизацией возникает
необходимость преобразовать коэффициенты принадлежности в требуемую
форму представления выходного вектора. При реконструкции только вектора х
достаточно простого взвешенного суммирования центров в соответствии с
формулой (12.47). При более сложных операциях преобразования сигналов сеть с
нечеткой самоорганизацией используется в качестве одного из компонентов более
общей сетевой структуры. Наиболее известный пример — это гибридная сеть,
обобщенная структура которой приведена на рис. 9.13. Уточненная структура
гибридной нечеткой сети изображена на рис. 12.6.

самоорганизуд многослойный

щийся нечеткий "ерседтт"

слой

 

Рис. 12.6. Структура гибридной нечеткой сети

_‚ 12; 4. Ёшенение шготтддсамооЁнтид для общения нечеткой сети 319

Гибридная сеть объединяет в себе сеть с нечеткой самоорганизацией‚
выполняющей функции препроцессора, и многослойный (обычно двухслойный)
персептрон (МЬР) в качестве постпроцессора.

Выходы самоорганизующегося слоя используются в качестве входов
многослойного персептрона. Если на вход сети, подается вектор
х= [х1, хц, ..., хЩТ, то на выходе слоя с самоорганизацией формируется
вектор и, состоящий из коэффициентов принадлежности х к конкретным
центрам: и = [ид(х), ид(х), ..., и;1‹(х)]Т. Конкретные компоненты ид рассчи-
тываются в соответствии ‘с универсальной формулой (12.43). Они удовлетворяют

условию нормализации Ёид =! для каждого вектора 29.
т=т
Количество входов персептронной компоненты гибридной сети равно

количеству самоорганизующихся нейронов. Количество скрытых слоев и число
нейронов в этих слоях может быть, в принципе, произвольным, хотя обычно для
восстановления данных с требуемой точностью достаточно одного слоя.
Размерность выходного слоя МЬР (т.е. количество сигналов уд, составляющих
фактический выходной вектор у) зависит от размерности заданного вектора д,
сопряженного с входным вектором х. ›

На практике гибридная сеть, как правило, более эффективна, чем
одиночная сеть с нечеткой самоорганизацией и чем самостоятельный
многослойный персептрон. Этот вывод следует из’ факта, что при исполь-
зовании гибридной сети задача разделяется на два независимых этапа,
реализуемых отдельно друг от друга. На этапе самоорганизации пространство
входных данных разделяется на кластеры, при этом количество кластеров
(самоорганизующихся нейронов) может быть произвольным и определяться
условиями решаемой задачи. Многослойный персептрон приписывает каждой
труппе кластеров соответствующий ей ожидаемый результат. Например, при
решении задачи классификации это может выглядеть как отнесение к одному
конкретному классу нескольких кластеров данных.

С учетом ярко выраженной двухкомпонентной структуры гибридной
сети для ее обучения применяется алгоритм, состоящий из двух этапов. На
первом из них проводится обучение самоорганизующегося слоя, состоящее в
подборе позиций центров, представляющих данные. Для этого можно применять
как алгоритм С-теапв, так и алгоритм Густафсона—Кесселя. По завершении
первого этапа, когда стабилизировались значения коэффициентов
принадлежности всех векторов, представляющих входные сигналы для
многослойного персептрона, начинается второй этап обучения. На нем значения
параметров самоорганизующейся части сети остаются неизменными, а
уточняются только веса нейронов персептронной компоненты. Это обычное
обучение многослойного персептрона, для которого входом является множество
коэффициентов принадлежности вектора х к центрам самоорганизующегося
слоя. В зависимости от типа решаемой задачи выходом сети может быть код
класса, к которому принадлежит входной вектор х, либо ожидаемое значение
а’ выходного вектора, соответствующего вектору х. По завершении второго

320 “т” “ш 12. Нечеткие нейшнные сети

этапа обучения веса замораживаются, и сеть становится готовой к функцио-
нированию в режиме эксплуатации (в котором на нее подаются только входные
векторы х без соответствующих им векторов д).

‹‘ Функционирование гибридной нечеткой сети проиллйострируем на примере
задачи классификации трехмерных данных, принадлежащих к трем частично

пересекающимся классам. Распределение этих данных представлено на рис. 12.7.

 

Рис. 12.7. Распределение тестовых трехмерных данных для решения задачи
классификации

Количество данных, относящихся к разным классам, различно. В первом
классе содержится 600 векторов х, обозначенных точками. Второй класс
составляют 100 векторов, обозначенных звездочками, а в третий класс
входят 300 векторов, обозначенных знаком “+”. В ходе вычислительного
эксперимента классы кодировались в двоичной системе (1 означала
принадлежность к классу а О - отсутствие принадлежности). По количеству
классов размерность выходного вектора равна 3. Решение задачи при
использовании обычного классификатора Кохонена либо сети с нечеткой
самоорганизацией малоэффективно‚ поскольку количество выходных нейронов
должно быть равно числу классов, т.е. трем, что существенно обедняет
архитектуру сети, а вследствие частичного пересечения классов будет просто
нецелесообразным.

Применение гибридной нечеткой сети со структурой 10-10-8-3
(10 самоорганизующихся нейронов и многослойный персептрон со струк-
турой 10-8-3) дало хорошие результаты классификации. На 1000 тестовых дан-
ных, не участвовавших в обучении, получено только 6 ошибочных решений об
отнесении к конкретным классам (эффективность классификации составила
99‚4%). Для сравнения самостоятельный многослойный персептрон при
классификации допустил 11 ошибок (эффективность 98,9%)‚ а одиночная
сеть с нечеткой самоорганизацией — 51 ошибку (эффективность 94,9%).

12. 4. Применение алгошша самооёизаиии для общения нечеткой сети 321
12.4.6. Примеры реализации нечетких сетей

Нечеткие нейронные сети как на основе самоорганизации, так и обучаемые с
учителем, находят применение в тех же практических областях, что и
классические сети соответствующих типов. По сравнению с традиционными
решениями они демонстрируют качества, связанные с их способностью гладкой
аппроксимации пороговых функций (см. графики на рис. 11.1). В настоящем
подразделе будут приведены результаты аппроксимации нелинейной кривой с
помощью сети ТЗК (сеть обучалась с учителем), представления большого
количества многомерных данных ограниченным числом нечетких нейронов (сеть
с самоорганизацией), а также примеры использования сети ТЗК для решения
задачи распознавания газовых смесей.

В качестве первого примера рассмотрим аппроксимацию нелинейной
функции от трех переменных (х = [х1, 1:2, х3]), описываемой зависимостью

__ 0,5 —1 1,5 2
у-—(1+х‚ +х2 +х3

при диапазоне изменения входных переменных х; (Е = 1, 2, 3) от 1 до 6.
Для восстановления этой функции применялась нечеткая сеть ТЗК с функцией
принадлежности

1
дАхР-‘Ё —

1+[х_с
О’
В сети использовались восемь нечетких правил, а начальные значения всех
параметров выбирались случайным образом. Общее количество параметров сети
было равно 50, из которых 18 - это параметры нелинейной части условий, а
остальные 32 - линейные веса рд. Сеть обучалась по гибридному алгоритму,
основаниому на декомпозиции ЗУВ. После обработки 200 обучающих выборок,
равномерно распределенных в пространстве параметров, погрешность МЗЕ
уменьшилась с 57,19 в начале обучения до 1,61. Это соответствует примерно 0,7%
относительной погрешности, приходящейся на одну выборку. Наиболее
интенсивно погрешность уменьшалась в начальной фазе обучения. На рис. 12.8
иллюстрируегся процесс последовательного итерационного уточнения
нелинейных параметров сд, щ и Ь; функции принадлежности д(х). По графикам
видно, что изменения происходили в широком диапазоне значений.
Способность нечеткой сети к самоорганизации можно продемонст-
рировать на примере двумерных данных с распределением, представ-
ленным в разделе 9 на рис. 9.2. Нечеткие сети состояли из такого же количества
нейронов, что и сети Кохонена‚ т.е. 40 и 200. На рис. 12.9 и 12.10 в графи-
ческом виде показаны результаты отображения обучающих данных век-

торами весов нечетких нейронов сетями из 40 (рис. 12.9) и 200 (рис. 12.10)
нейронов соответственно. Ситуации, проиллюстрированиые на рис. 12.9 и

1 -—-2162

322 12. Нечеткие кейшкнйё сети

е). 2.8 ’_ ” _ _ : ’ _  "
2.6 5 в  = = = ' -
21
2,2
2
1,3   
1,6 -

Центры

  
  
  

1,4 -

1.2 Ё : : Ё _ _ ‘
О 1002003004005006007008009001000

Номер итерации

99
со

Параметр ширины
9 9 9
о. о ч

0 100200300400500600700800 9001000
Номер итереции

о Е ‘ ё = д : ё Е Ё
0 100 200 300400600600700 800 9001000
Номер итерации

Рис. 12.8. Процесс уточнения параметров нечеткой сети:
а) центры од функции принадлежности; б) параметры о}; в) показатели степени Ьд

12.4. Применение алгоритма самоорганизации для Ёчения нечеткой сети 323

а) Нечеткий влворитм при 40 нейронах - начальное состояние
0, 7

0, 65
0,6
0.55
0. 5
0, 45
04
0,35
0. 3
0,25

0,2
0,25 0,3 0,35 0,4 0,45 0,5 0.55 0,6 0,65

 

б) Нечеткий алворитм при 40 нейронах - конечное состояние
0.7

0,65
0,6
055
0.5
0. 45
0,4
0,35
0,3
0,25

0,2
0,25 0,3 0,35 0,4 0,45 0.5 055 0,6 0,65

 

Рис. 12.9. Результаты восстановления обучающих данных с рис. 9.2 нечеткой иейронной
сстъю с самоорганизацией, состоящей из 40 нейронов:

д) ИСХОДНОВ СОСТОЯНИЕ ПОСЛЕ РЗЗНОСТНОГО ГРУППИРОВВНИЯ; б) ОКОНЧЗТСЛЬНОС РЗЗМСЩСНИС

упорядоченных нейронов

12.10, относятся к начальному состоянию процесса обучения при исполь-
зовании алгоритма разностного группирования (рис. 12.10а) и результирующего
состояния (рис. 12106). Анализ исходного расположения нейронов пока-
зывает, что алгоритм разностного группирования обеспечивает весьма точное
позиционирование центров нечетких функций. Алгоритм самоорганизации очень
быстро приводит к их оптимальному размещению. Результаты, достигнутые с
применением нечеткой сети, оказываются конкурентоспособными по отношению
к наилучшим результатам, полученным на сети Кохонена. При использовании 40
нейронов погрешность квантования в нечеткой сети составила 0,00035
(наилучший результат в сети Кохонена бьш равен 0,0174), а при 200 нейронах

1,221:

324 ‘ 12. Нечеткие нейшнные сети

погрешностъ квантования не превысила 0,0ОО172 (в сети Кохонена — О,00705).
Различие в уровне погрешности достаточно велико; оно обусловлено разными
способами представления данных в классической системе и в нечеткой сети. В
системе Кохонена каждую точку данных в Ъмногомерном пространстве

а) Нечаткий алгоритм при 200 нейронах - начальное состояние
0, 7

0,65
0,6
0,55
0.5
0,45
0,4
0,35
0,3
0.25

0,2
0,25 0.3 0,35 0,4 0,45 0,5 0,55 0,6 0,65

 

6) Ншеткий. алгоритм при 200 нейронах - конечное состояние
0,7

0, 65
0, 6
0. 55
0,5
0,45
0,4
0,35
0, 3
0, 25

0,2
0,25 0,3 0,35 0.4 0,45 0.5 9.55 9.5 9.55

 

Рис. 12.10. Результаты восстановления обучающих данных с рис. 9.2 нечеткой
нейронной сетью с самоорганизацией, состоящей из 200 нейронов:
а) исходное состояние после разностного группирования; б) окончательное размещение
упорядоченных нейронов

представляют веса только одного нейрона, тогда как в нечеткой сети с
самоорганизацией - множество нейронов, расположенных поблизости друг от
друга. Благодаря этому становится возможным лучшее и более точное
отображение использованных при обучении исходных данных.

Эта разница наиболее отчетливо заметна при представлении данных,
соответствующих простой одномерной функции, например, синуса.

12.4. Применение шивера самоовтизаиии для общения нечеткой сети 325

На рис. 12.11 демонстрируется аппроксимация этой функции с исполь-
зованием 20 нейронов. Рис. 12.11а отображает работу нечеткой сети, а
рис. 12116 - сети Кохоиена. Классическая сегь Кохонена аппроксимирует
функцию огрезками прямой, а нечегкая сеть — непрерывной кривой линией.
Уровни погрешности восстановления различаются при этом в среднем в 2,5 раза.

Очень хорошие результаты получены при использовании нечеткой сеги ТЗК
для распознавания компонентов газовых смесей. Исследования проводились
на тех же обучающих и тестовых выборках, которые применялись в
экспериментах с гибридной сетью, описанных в разделе 9. Применялась

ч

а) Аппроксимация функции синус с применением нечеткой сети
1

0,8
0,6
(14

 

Время

б) Аппроксимация функции синус с применением сети Кохонене

 

Время

Рис. 12.11. Иллюстрация способа аппроксимации синусоидальной функции
а) сехъю с нечеткой самоорганизацией; б) сехъю Кохонена

326 —‚ —‚ . в — ‹   12.Нечеткиепей нныесети

   

пятивходовая сеть ТЗК (для учета ‘показаний пяти полупроводниковых
датчиков) с пятью нечеткими правилами. Количество выходных нейронов
было равно четырем (смесь состояла из четырех газовых компонентов).
Обучение проводилось по гибридному алгоритму подбора параметров сети,
объединенному с предварительной инициализацией центров нечетких
функций, основанной на механизме самоорганизации по принципу
разностного группирования. Этот принцип позволил получить практически
идеальное начальное размещение центров, благодаря чему адаптированный к
сети ТЗК гибридный алгоритм уже после первого прохода (выполнение
декомпозиции ЗУВ) перевел сеть в обученное состояние. На рис. 12.12
представлены результаты тестирования натренированной сети ТЗК на тех же
данных, которые применялись в экспериментах с гибридной сетью. Эти
результаты представляют собой графики относительной погрешности опреде-
ления четырех газовых компонентов (1 —двуокись углерода, 2-метан, З-метанол,
4-пропан/бутан). Среднее значение относительной погрешности по резуль-
татам экспериментов составило 0‚2З%, что свидетельствует о существенном
прогрессе по отношению к показателям, достшнутым с помощью гибрид-
нои сети.

Газ 2

Газ1

е.
:-
Ш
а
г‘
01

Ч!

чд

Ф
Ф

     

Отн. погрешность 96
9
Ш

Отн. погрешность, 96
9
Ш

     

4.5 ’ ’ ’ ‚од * ’ ’
0 5 10 15 20 0 5 10 15 20
Тестовые выборки Тестовые выборки
е)

Газ З е) Газ 4
. 1,5 _

    

чд

Отн. погрешность, 96
9
Ш
Ф

 

0 5 10 15 20 0 5 10 15 20
Тестовые выборки Тестовые выборки

Рис. 12.12. Распределение относительных погрешностей определения четырех
компонентов газовой смеси, полученных с использованием нечеткой сети ТЗК.

12.5. Адаптивный   Ьам  нечеттй сети 327

12.5. Адаптивный алгоритм самоорганизации
нечеткой сети

Представленный в предыдущем подразделе алгоритм самоорганизации

требует априорного знания количества центров (нечетких нейронов),

которые будут предоставлять данные. С этой точки зрения наиболее
универсальным представляется адаптивный алгоритм, автоматически добав-
ляющий новые центры в режшие онлайн в зависимости от распределения входных

данных х.

Адаптивный алгоритм был сформулирован только для гауссовской функции

(Ь = 1) с использованием обобщенной модели Ванга-Менделя [160]. В результате

его реализации определяются: количество центров и их расположение в части,

соответствующей условиям (множество векторов хд) и заключениям

(множество скалярных ожидаемых значений ф). Этот алгоритм можно

описать следующим образом.

1. При старте с первой пары данных (х1, 41) создается первый кластер
с центром с1=х1. Принимается, что и’1=‹11 и что мощность мно_
жества 1,1 = 1. Пусть г обозначает предельное эвклидово расстояние

г между вектором х и центром, при котором данные будут трактоваться
как принадлежащие к созданному кластеру. Для сохранения общности
решения принимается, что в момент начала обучения существует М клас-
теров с центрами сд, с2, ..., см и соответствующие им значения шд и
1.;(й= 1, 2, ..., М).

2. После считывания 1с-й обучающей пары (хд, ф) рассчитываются рас-
стояния между вектором хд и всеми существующими центрами ||х;‚—с1||
для 1 = 1, 2, ..., М Допустим, что ближайший центр -— это сдк В таком
случае в зависимости от значения Нхд-сд" может возникнуть одна из двух
ситуаций:

’ если Нхд-сдд" > г, то создается новый кластер еды = хд, при-
чем шмд(1с)=‹1д, ЬМ+1(1‹)=1. Параметры созданных до этого кластеров не
изменяются, т.е. и’‚‘(/с)=и’;(/с—1), [‚‚‘(/с)=1‚1(1с-1) для 1 = 1, 2, ..., М.
Количество кластеров М увеличивается на 1 (М ‹— М + 1);

‘ если || хд - сд‘ || 5 г, то данные включаются в 1; -й кластер, параметры
которого следует уточнитъ в соответствии с формулами [60]:

„,‚(1‹)=‚„,‚(1‹—1)+а‚ ‚ (!2.48)
д, ‹‘‹)=т,‚ ‹1‹—1)+1 ‚ ' (1149)

с,‘ (К) = Ь,‘ (ю ( 12.50)

В другой версии алгоритма фиксируется положение центров сдд после

328  ‘ 2. Нечеткие нейшнные сети

инициализации, и их координаты уже не изменяются. Во миопах случаях
такой прием улучшает результаты адаптации.

3. После уточнения параметров нечеткой системы функция, аппрокси-
мирующая входные данные системы, определяется в виде

 

М , (12.51)
2Ь,(/с)ех -

|| Х —с1(’‹) "2
1=1 о’

тогда как остальные кластеры не изменяются, т.е. при 1 #1; ш1(/с)=и’1(/г—1),
14(1с) = 1.1(1‹—1) и С‚‘(1с) = с1(/с——1)‚ для 1= 1, 2, ..., М

При повторении перечисленных этапов алгоритма до !с= р с уточне-
нием каждый раз значетшя М пространство данных разделяется на М клас-
теров, при этом мощность каждого из ьшх определяется как 14 = 1401:),
центр - как с; = с1(/с), а значение приписанной ему накопленной функции й -
как и’,=и›;(1с).

Этот алгоритм называется самоорганизующимся, поскольку разделение
пространства данных на кластеры происходит самостоятельно и без участия
человека, в соответствии с заданным значением порога г. При малом зна-
чении г’ количество кластеров возрастает, в результате чего аппроксимация
данных становится более точной, однако это достигается за счет более сложной
функции и увеличения объема необходимых вычислений при одновременном
ухудшении обобщающих свойств сети. Если значение г’ слишком велико, то
вычислительная сложность уменьшается, однако возрастает погрешность
аппроксимации. При подборе оптимальной величины порога г’ должен
соблюдаться компромисс между точностью отображения и вычислительной
сложностью. Как правило, оптимальное значение г подбирается методом проб и
ошибок с использованием вычислительных экспериментов.

На рис. 12.13 представлены результаты аппроксимации кривой

](х) = 0,1 з1п(0,2 их) + 0,2 з1п(0,3 их) + 0,6з1п(0,9 их) +
+ 1‚1з1п(1,9пх) + 2,3 з1п( 3,7пх)

нечеткой сетью с самоорганизацией при использовании адаптивного алго-
ритма обучения. Рис. 12.13а иллюстрирует результаты, полученные при
величине порога г = 0,2, а рис. 12.1Зб соответствует порогу г’ = 0,05. Пунк-
тирная линия обозначает ожидаемые значения, а непрерывная линия —
фактические значения, сгенерированные нейронной моделью. Алгоритм сам
подбирал количество нейронов, отвечающее установленному значению
порога г. В первом случае зафиксированное алгоритмом количество ней-
ронов было равно 12, а во втором - 19. Для обучения использовались
только 500 первых реализаций сигнала. Оставшиеся 500 значений приме-
нялись исключительно для тестирования.

12.5. Адаптивный алгоритм самоовганизшии нечеткой сети 329

а) Адаптивный метод при г = а 2
25

20
15 . _ 5  ‚.

    

0 100 200 300 400 500 600 700 800 9001000

б) Адаптивный метод при г = 0,05

8

 

Рис. 12.13. Пример отображения данных нечеткой сетъю с самоорганизацией при
использовании адаптивного алгоритма обучения: а) порог г = 0,2; б) порог г = 0,05

Следует обратить внимание, что алгоритм самоорганизации нечеткой
сети позволяет одновременно определять как параметры сети, так и ее
структуру (количество нейронов скрытого слоя). Его реализация подобна
модели Ванга-Менделя, описываемой формулой (12.7), в которой можно
выделить центры с‘, соответствующие множеству векторов х, и коэффи-
циенты щ, связанные с положением центров через последовательность заданных
функций {(1}. В связи с накопительным характером формирования пара-
метров и’; (формула (1248)), в знаменателе выражения (1251) суммирование
производится с весами 14, оггражающими количество уточненийпараметров
конкретных групп данных (размерность кластера).

22-2162

Литература

10.

11.

12.

13.

14.

Ваггоп А. К. Арргохйшайоп апб евйтайоп Ьоипдз Тот агййсйа! пецга! петтойв.
МасЫпе 1еагп1п3. - Уо1. 14, 1994. - Рр. 115-133,

Вгидгешз/с! К, Овошз/сй 5 (Заз апа1увйв вузгетп сотрозеё оГ а 50116 мате вепзог
аггау апб ЬуЬгЮ пеига! пеш/огК вггпсшге. Зепзогз апд Асшагогз-Вбб, 1999. - Рр. 38-46.

Сагдоззо ‚1 Е. Ве1оис/1гап1 А., ЬаИеШ В. А пеш сотрозйе сгйегйоп Тог адарйче
апб йегайче Ыйпб зоигсе зерагайоп // Ргос. 1САЗЗР-94. - А‹1а1а1‹1е. - Уо|. “ё -
Рр. 273-276.

СИиЕ С. К. Ап йппоёисйоп 10 ‘качекъйз. Ы. ‘А: Асадетйс Ргезз, 1992.

СотеЛ М, Сдал! В., С1гап1 Х, МиЛег С, Коиззегд Вайу е1естг1са1 рошег сипге: с1аз-

вййсабоп апд Гогесазйпё изйпё а Койопеп шар // Ргот Ыашга! ю Агййсйа! Ыеига!
Сотригайоп / 1. Мйга, Р. Зап6оУа1, ебз. - Ма|а3а: ГЩАЫЫ, 1995. - Рр. 1107-1113.

СотеП 6., Мипго Н, Зфзег В. Ьпаге сотргезвйоп Ьу ЬасК ргораёайоп:
ап ехатр|е о! ехгепзйопа! ргодгажпшйпд. - Тесппйса! Кероп 1С$ герогт 8702, ЮЗ-ПСЗВ
Зап 012230, Сайгошйа, ПЗА, РеЬшагу 1987.

Сйаиуйп У. А ЬасК ргорагайоп ащогйшш МШ орйта! изе оТ Ыдёеп  // Адчапсез
йп ЪПР$2 / 1). ТоигеггКу, Её. — Зап Магео: Могзап Каийпапп, 1989. - Рр. 519—526.

Сйеп 5., Сашап СЕ, Отт НМ Огйюгопа! 1еаз1 зциагев Пеагпйпг а13ог1111т
Тот гадйа! Ьазйз Ршгхсйоп петогкз // КЕЕЕ Тгапв. Наша! ЫешогКз, 1991. - Уо1‚ 2. -
Рр. 302-309.

Сйеп В., .1а1п С. А гоёизг ЬасК ргорагайоп Пеагпйпг а|3ог111пп Тог Гипсйоп
арргохйпайоп // КЕЕЕ Тгапв. Ыеига! Ыешойсз, 1994. - Уо1. 5. — Рр. 467-479.

Сйепд ХН, Ып С..$1 Ьеапяйпг а15ог1йпп Ток гасйа! Ьавйв Типсйоп пеМогК шйЬ
гЬе сараЫНгу 052166111; апё ргипйп; пеигопз: Ргос. 1994 СопЕ [СНЫ Ог1ап6о: 1994. -
Рр. 797-801.

Стпгипдгиепг С.‚ Зецидп СН Ортйта! аёарйче К-теапз ащогййпп Мг}:
бупатйс афизппепт оГ |еап11п3 гаге // [ЕЕЕ Тгапв. Меига! Ыешогкв, 1995. - Уо1. 6.
- Рр. 157-169.

Сдс/юс/сб А., Вогпе’ К, Мозгсгупзйб Ь.,Роре К. Мобййеб НегаиК-Щицеп
а13ог1111тз Ток Ыйпд зерагайоп оТ зоигсез // 131311211 5191111 Ргосевзйпд, 1997. - Уо1. 7.
- Рр. 80-93.

С1с1юс1с1 А.‚ Мовгсгупз/сй Ь. ВЗ-ргодгаш о!’ Ыйпд зерагайоп оТ зоигсез. - Шагзгаша:
РоШесЬпЖа Шагззашзка, 1994.

Сёсйос/с! А.‚ С/пЬе/‘аиеп К. ЗС пеига! пегшогкз Го: бййегептйа! орйтйгайоп
// 1:11. 1. С. 11 Арр|., 1991. - Уо|. 19. - Рр. 161-187.

лйт  331

‘15. СЕсИосИ А., С/пЬе/лаиеп К. Ыеига! пеМЪгКз РОЁЁЗЁУЕЁЁ зузгетв оГ Ипеаг ециайопз
апб ге|агед ргоЫетз // [ЕЕЕ Тгапз. САЗ, 1992. - Уо1. 39. - Рр. 124-138.

16. СйсйосН А., НпЬеИаиеп К. Ыеига! петогкз Тог орйшйгайоп ат! зйгпа!
ргосеззйпё. Ы. Ж: Шйеу, 1993.

Т7. СЁсРюс/(Ё А., НпЬеИаиеп Н.‚ МоЭЁЩпзКЁ Ь, Киттегг Е. А пеш оп-Нпе аёарйче
Ьагпйп; аПЁогШпп Гог Ыйпд зерагайоп оГ зоигое зйдхта1з. ПЗАЪПЧ. — Тайшап, 1994.
— Рр. 421-427.

18. СЕсИосН А., Атагд 51 Адаргйче Ыйпё зйгпа! ргосеззйпг - пеига! пеМогК ёрргоасйез
‹ // Ргосеебйпгв оГ ЕЕЕЕ, 1998. - Уо|. 86. - Рр. 2026-2048.

19. Со/геп МА.‚ Оговздегд 8. АЬвоппе зтаЬШту оГ 31оЬа1 рацегп Гогтагйоп ат!
рага11е1 тетогу згогаге Ьу сошретйче пеига! пеМОгКэ // 1ЕЕЕ Тгапв. ЗМС, 1983. -
Уо1. 13. — Рр. 815-826.
т;

20. СОУег Т Сеотеггйса! апё вгайзсйса! ргорегйез о!‘ вузгетз оТ Бпеаг йпесдиаййез
шйЬ аррйсайопз йп рапет гесодпййоп // КЕЕЕ Тгапз. Е1ес1гоп1с Сошрщегз, 1965. -
Уо1. 14. — Рр. 326-334.

21. С2о3а1а Е.‚ Редгус: ш Е1етепгу йшегоду теогй хЬйогуш гошпугусЬ. — Щагзгаша: РЧУЫ,
1985.

22. Ваг/сеп С., Мооду ‚Я Ьеапйпг всйефйев Гог зюсЬазйс орйтйзайоп // Ргос. 1990
КЕЕЕ СопЕ ЪПРЗ // Ыашга! апб Зутейс, 1990. - Рр. 518-523.

23. ВаиЬесйЕез 1 Теп 1есшгев оп ‘мачыетз. СВМЗ- ЫЗР Кедйопа! СопС Зейез 111 Аррйед
Машешасйсз, Мопгрейег: Сарйа! Сйу Ргезз, 1992. - Уо|. 61.

24. Ветатпез В Апа1узе де доппеез раг гевеаих де пеигопез аию-огдапйзез, Вйвв.
с1е 1’[пв11ш11\1а11опа1 Ро1утесЬпйцие де (ЭгепоЫе. - (ЭгепоЫе: 1994.

“25. Ветатпез Н, Ыауо Е КоЪюпеп вы? огдапйхйп; тарз: йз {Не погтайхайоп
песезэаху? // Сотр|ех Зувгетв, 1992. - Уо|. 6. - Рр. 105-123.

26. Ветапйпез Н, Нетаи!‘ 1 Кергевепгатйоп оГ попйпеаг дата згшсшгев ШгоиЁЬ
Газ! УОР пеша! пешогК // Ргос. Ыеигопйгпез. - Ыйшез, Ргапсе, 1993. — Рр. 1—-18.

27. Ветигй Н.‚ Веа1е М Ыеига! Ыетшогк Тоо1Ьох Го: иэе шййш МаНаЬ. - ЫайсК: ТЬе
МайМ/огкз, 1пс.‚ 1992.

28. Вепоеих ‚Л, Ьепдаде К. Ппййайгйп; ЬасК ргорагайоп пешюгКэ шт: ргоюгурез
// Мечта! Ыеш/огкз, 1993. — Уо! 6. - Рр. 351-363.

29. Вдатапгатз К, Кии; 8. Ргйпсйра! сотропеш пеига! пеш/ойсз, йхеогу ат!
аррйсайопз. - М. ‘Д: Щйеу, 1996.

‹З0. Вйпй мдиш Во, ОвошзМ 8. ЗЬаре гесодпййоп азйп; РРТ ргергосеззйп; апб пеига!
петшогк // Сотре1, 1998. — \’01. 17, Но 5/6. - Рр. 658—666.

31. Вёпй _1\"3111а 00. Зйесй пеигопоше ш зазгозошапйи до гогрогпашапйа шгогсош
бшишутйагошусц: Кохргаша докюгзка. — Шагзхаша: РоИгесЬпЁКа Шахяашзка, 1999.

32. ВиЬоЕз 0., Ргш1е Н Рииу зетз апб зузгешзё- М. Ж: Асадетйс Ргезз, 1980.

33.‚ РаЫтап ЗЁЕ. Разгег Ьатйп; чагйагйоиз оп Ьаскргораёайоп: еп етрйгйса! зшбу
‘ // Ргос. 1988 Соплесйопйв! Мос1е1в Зиттег ЗсЬооП. - Ьов А1гоз, ПЗА: Моггап
Каийпапп, 1988.-Рр. 38-51. '

22’

332 Л 

34. Гаттап $.Е., ЬеЫете С. ТЬе сазсабе-соггеьйоп |еагпйп3 агсытесшге // Адтщюез
йп ЪПРЗ2/ Её. В. ТоигешКу. - Моггап Каийпапп, 1990. - Рр. 524-532.

35. Погееп В ТЬе сопчегдепсе оТ Натгпйпг тешогу пеЩ/огкз // ЯЕЕЕ Тгапз. - Мета"
Метшогкз, 1991. - \/01_ 2. - Рр. 449-457.

36. Ридивтта К, РУа/се М Налдтйпеп а1рЬапитегйс сйагасгег гесогпййоп Ьу Ше
пеосогпйгоп // ПЕЕЕ Тгапз. ЪЪМ, 1991. — Уо1. 2, - Рр. 355—365.

37. Риггй В. А зшчеу оГ шищшеёйа тесппйцие апб ыапдагбз. - Рап 1: ЕРЕС втапбагб. Кеа!
Тйпе 1та31п3, 1995. - Рр. 49-67.

38. Сет 8., вте ‚Л Ргодгезв йп зирегчйзес! пеша! петогкз // ПЕЕЕ Тгапз. М. М, 1992. -
\/01. 3. - Рр. 621-625.

39. 6111 В, Мипау ИС, “1113111 М. Ргасйса10рНтй2айоп.- ММ: Асафтёс Рйгзз, 1981.

40. Ой-ов! Е, .1опез М. — Роггбо Т. Кедщагйгайоп Шеогу ат! пеига! пепчогК агсЬйесшге
// Маша! Сотритагйоп, 1995. - Уо1. 7. - Рр. 219-270.

41. Оаййгегу В. Ащогугту гспегусте. - Шагпаша: “ШТ, 1995.
42. 6о1иЬ 0., Уап Ьоап С. Матгйх сотритайопз. - ЫХ: Асадешйс Ргезз, 1991.

43. Натре! Е В.‚ Коиззееии’ В ф, Копсйет Е. М, Бгайе! ИЛ КоЬиЫ зшйзйсз -
Ше арргоас}: Ьазед оп йпПиепсс йшсйоп. - ИХ: Щйеу, 1986.

44. Нап 1-‚51, Лт К-УИ 1тр1етепгайоп о!‘ тййоп соппесйопз псига! Ьагдшаге М!!!
ПКАЪН // Ргос. 1САЫЫ-9З. — Атзгегдагп: 1993. - Рр. 1030-1033.

45. НавзЕЬЕ В.‚ Зюдс В. Бесопб огдег дейчатйез Тот пешогК рпшлйпд: Орйхпа! Ьгайя
зшгеоп // Абчапсев йп МР$5 / Её. 1). Тоигетгку, Зап Матео: Мотгап Каийпапп, 1993.
— Рр. 164-171.

46. НауНп 8. Меига! пеш/огкз, а сотргепепзйче Тоипбагйоп. - ММ: МастШап СоНеге
Риыйвып; Сотрапу, 1994.

АЪ Не К, Стпддюуи Ы А сЬагге Ьазед оп-сЫр адарсайоп КоЬопсп пеига! петойк //
Тгапз. Маша! Метогкз, 1993‚ - УоЛ. 4. - Рр. 462-469.

48. Не К, Стпдйгодш К, Запсйег-Здпепсйо Е. А ыдь ёспзйу ил‘! 1ош рвшег смще
Ьазеё Натгпйп; пешогк // ШЕЕ Тгапз. УЬЗ! Зузтешз, 1993. - У01. 1. - Рр. 56-62.

49. НеЬЬ 1). Огдапйгайоп о!‘ ЬеЬачйош. - ММ: 1. Шйеу, 1949.
50. Нест-Нйедчеп К. Ыеигосошршйпг. - Атзтегйшп: Аббйзоп \\’ез\еу, 1991.

51. Неггг ‚Д, 100311 А., Ра!тег К. Ч/згер 60 Феогй оЬйсгеп пеигопошусЬ. Ч/уд. П. -
Шахвгаша: “ШТ, 1995.

52. Ндпгоп 0., $е]п0и’$МТ Ьещпйпг апй гешягпйп; йп Во1шпап тасЫпез Л Рагапе!
Вйзггйьигес! Ргосеззйхад: Ехр1огайоп йп Мйсгозггисидге о!‘ Согпййоп / Ебз. В. Китгпешап,
1. МсС1е11апб. - Сшпьйбге: Мазз. Ргезз, 1986.

53. НорЛеМ „С Мечта! пешогкз апс! рпузйса! зузтетз МШ ететдепг соПесйче
сотритайопа! аЫШЭез // Ргос. Майопв! Асабешу о!‘ Зсйепсе ОЗА, 1982. - УоП. 79. -
Рр. 2554-2558.

54. НорЛеИ 1, Тапд: В. Пецга! сотритайопз о!‘ бесйзйоххз йп орйхпйийоп ргоЫапз
// Вйо1о31са1СуЬетейсз, 1985. - У01. 52. ‹ Рр. 141-152.

55.

56.

ёь

1 57.
Ё за.
59.

` 60.

61.

62.

63.

65.

367.

68.

 ‘ю.

71.

72.

73

333

НорЛеМ ‚Д, Тип]: В. Сотрпйп; ‘л/Шх псига! сйгстз: а тподс! // Зсйепсе, 1986. - Уо|.
233. — Рр. 625-633.

Нотйс К., ЗНпсЬсотЬе М, Идте Н МиШПауег Геейогшагб пешчогкз ат‘:
ппйчегза! арргохйшатогз // Маша! ЫешогКв, 1989. - Чо1. 2. - Рр. 359-366.

Низй Ц, Ноте В. Ргоггсзз йп зцреп/йве‘! пепла! петогКв // ПЗЕЕ $й3па1 Ргосевзйпв
Мадагйпе, 1993, Лаппагу. - Рр. 8—39.

Ппге! 80|70ЫХ Е|еспйса11у ФгаЁпаЫе апа|о5 пеша! пешюгК. Ргодис! Везсйрйоп ат!
Ваш Зйеег. — Ппге! Согр., 1991.

.1асо1›в К. А. {псгеаэед гагез оГ сопчегдепсе ШгоиЕЬ 1сашйп5 т: адяртабоп // Ыеша!
Ыешогкз, 1988. - Уо1. 1. - Рр. 295—307.

.1ап3 ‚Л 8., 8ип С. Г, Мйигапй Е. Меиго-Шиу апб вой сотрийпг. ‹ ИХ: Ргепйсе НаЦ,
1997.

.1о!тзоп 13., Атдоп С.‚ Бсйегоп С. Орйгпйгайоп Ьу зйгтйатед аппеайпд: ап
ехрегйтепга! ечашайоп. Рап 1: дгарЬ рагййопйп; // Орегабопз КеазеагсЬ, 1989. -
Уо|. 37. - Рр. 865-892.

.1ипеп С.‚ Негаи!‘ ‚Л ВНш! верагайоп оГ зоигсез рагг 1: ап адарйчс ащогйшт
Ьазеё оп пеиготйтейс агсййесше // Зйвпа! Ргосевзйпд, 1991. - \/01. 24. - Рр. 1-10.

.1ипеп С.‚ Лдиуеп Г, Будто Е., Уйюг Е.‚ Сае1еп ‚1 811116 зерагагйоп о!‘ зоигоез:
ап ащогййт Гог верагайоп о!" сопчошйче тйхшгез. - СЬаппоизе: Ч/огкзйор оГ Нйдйег
Огбег Згайзйсз, 1991. - Рр. 273—276.

Катеп Е., Нес!‘ В. Рппбатепгщв оТ 513112115 алб зузгетз изйп; МаНаЬ. - ИХ: Рхепгйсе
НаП, 1997.

Кагаудаппйа М Ассе1егайп3 Фгайпйп; оГ ТеедГбгшагб пеига! пеш/огК 115111;
вепегайгед ЬеЬЫап гиПев Тот Епййайгйп; (Не Епсета! гергезегпагйоп // !ЕЕЕ Ргос. ПСЪПЧ,
011211160, 1994. - Рр. 1242-1247.

Катди ЕД А зЯтрПе ргоссдиге Рог ргипйпд ЬасК-ргорадасйоп ггайпед пеша! „так:
// [ЕЕЕ Тгахтз. Мечта! Ыеш/огкз, 1990. - Уо1. 1. - Рр. 239—242.

Казадох’ М Роппёайопз о? пеига! пеМогКз, йдиу зузгетз ат! Кпомдедде епдйпеетйпг. -
Ьопдоп: ВгасКогд ВооК МЕТ Ргевз, 1996.

Кдогазап! К, Спфгю А., бгёдоуйп 11 А пеш |еагп1п3 ащогййхш Гог Ьйбйгесйопа!
аззосйагйче шетогу пеша! пе1ш0гКз// ПЕЕЕ Ргос. ЮНЫ, 0г1ап60, 1994. - Рр.1115-1120.

Кйошпгад А., Ьи ‚1 Шазвййсайоп оТ йпчагйапг йтаде гесопзтгисйоп иэйп; пепга!
пешогКз // 1ЕЕЕ Тгапз. АЗЗР, 1990. - Уо1. 38. - Рр. 1028-1038.

КйгЬу М, Зйгогйсй Ь. Аррйсайоп оГ КагЬппеп-Ьоече ргосейцгез Рог Ше
сйагшегйгатйоп оГ Ьитап Тасез // ПЕЕЕ Тгапз. Рапет Апа1узйз, 1990. — ЧоЬ 12. -
Рр. 103-108.

КМфагтЕс/с 8. Сайт С. В. - Юсст М В Орйтйгайоп Ьу зйпиПаКед аппеайп;
// Зсйепсе, 1983. - УоК. 220. - Рр. 671 - 680.

КНтаиз/‘аз О. Ыёша! Шаг: - Пзег тагшаЬ Ыайск, ПЗА: Меига! Шаге 1пс., 1992.

. Койопеп Т! ТЬе зеК огдапйзйп; шар // Ргос. о? ПЗЕЕ, 1990. - Уо1. 78. —
Рр. 1464-1479.

334 ЛшпЁ

74. Койопеп Т Зейдоггапйгйп; шарв. — ВегБп: Зргйпдег Уейад, 1995.

75. Койопеп Г, Капдаз ‚Д, Ьаа/сзоп 1 ЗОМРАК, {Ье вейбгдапйхйпг тар ртодгаш
расКаЁе. Тес11пйса1 Керогт. - Езроо, Р1п1ап6, Не1в1п1й: Чпйчегзйгу оГ ТесЬпо1о3у, 1992.

76. К01т030гт’ А. М Оп Нас гергезепгайоп оГ сопйпиоиз Шпсйопз оГ шапу чайаЫев
Ьу зирегрозййоп оГ сопйпиоиз йшсйопз оГ опе чайаЫе апб аёбййоп // 1Э01‹1. А1сас1.
ЫаиК ПЗЗК, 1957. - Чо1. 114. - Рр. 953-956. ‚ „ж

77. Когыс: ‚Д, ОЬиь-Иошйс: А., исгщы В. Згшсгпе зйесй пеигопойе - родзгашу 1
газгозошапйа. — Шагзхаша: Акадешйска Ойсупа шудашпйсга РЫ, 1994.

78. Коз/ю В. Вйдйгесйопа! аззосйайче тетогйез // 1ЕЕЕ Тгапз. Зузтетз, Мап апб
СуЬегпетйсз, 1988. — У01. 18. - Рр. 49-60.

79. Кг2у2а1с А. Мегоду пйерагатетгусгпе ‘ч рггеш/ашапйи $у3па10ш Ё ш зйесйасй
пеигопошусЬ. Ргаое Ыаикоше 1998, 1. 106, Шагзгаша: Ойсупа Шудашпйсга РЩ
1998.

80. Хггуга/с А., Хи 1., $иеп С! Мейюдз оГ сотьйпйп; ти1йр1е Ыаззйбегз апд Шейг
аррйсайопз (о Ьапбшйцеп гесоёпййоп // 1ЕЕЕ Тгапз. ЗМС. - Уо1. 22. - Рр. 418-435.

81. Кий! Ь, Ойапйпа С. Е111р11с Рошйег Геашгез оГ а с1овеб сопюигз // Сошригер

Огаршсз апб Кшаге Ргосевзйпд, 1982. - Уо1. 18. - Рр. 236-258.
82. Кии; ‚ЗЁ К Вйгйа1пеига1пешог1сз. - Ыеш 1егзеу: Ргепйсе На11‚ Еп31ешоо6 Сййв, 1993.

83. Ьапзпег 1, Ьейтапп Т Ал апа1о3 СМОЗ сЫр за! пеига! пегшогкв “11111 агЫпазу
10р01о31ев// Тгапв. Ыеига! Ыегшогкз, 1993. - Уо1. 4. - Рр. 441-444.

84. ЬеСип Х, Веп/сег ‚Л, 80110 ‚б‘. Орйгпа! Ьгайп датаге ЛАФ/апсев йп ЪГ1Р$2 /
Её. 1). ТошешКу, Зап Матео: Моггап Каийпапп, 1990. - Рр. 598—605.

85. Ьеопагй 1.4., Кгатег МА. Касйа! Ьазйв {цпсйоп пеМогКз Рог с1азв11`у1п3 ргосезз
Гаи11з// ЕЕЕЕ Сотго! Зузтет Маёагйпе, 1991, Арг11. - Рр. 31-38.

1 86. Ы 9., Гид: В. Зупйтевйийп; пеига! пешогКз Ьу зечиеххсйа! аёёййоп 05 Ьйбдеп тобез

// КЕЕЕ Ргос. КСЪПЧ, Ойапбо, 1994. — Рр. 708-713.

87. Ыапо К А гоьизт арргоасЬ 10 зиреп/йзед 1еап11п3 йп пеига! пешогк // [ЕЕЕ Ргос.
ЮМЧ, Ог1аш1о, 1994. - Рр. 513—516.

88. Ып Х, Сиппйпгйат О. А пеш арргоас11 10 Шиу пеига! вузгет тобейпг // ЕЕЕЕ `

Тгапз. Рн22у Зузтелпз, 1995. - У01. 3. - Рр. 190-198.

89. Цпде Х, Виго А., бгау К. Ап ащогййхт Рог чесгог циапйгег дезйгп // [ЕЕЕ Тгёшв.

Сотпъ, 1980. - \’01. 28. - Рр. 84-95.

90. Ыпз/сег К. Ргош Ьазйс пешогк рг1псйр1ев со пеига! агсййесгнге // Ргос. оГ Ыайопа!
Асадету оГ Зсйепсез о! Нас ПЗА, 1986. - Уо|. 83. - Рр. 7508-7512, 8390-8394,
8779-8783.

91. Ьфртапп К. Ап йпйоёисйоп 10 сотрщйпг шййш пеига! пегз // !ЕЕЕ АЗЗР ;

Маёагйпе, 1987, Арг11. - Рр. 4-22.

92. МаЛсошзКЕ А. Еазгозошапйе папзшппас]! гапмщ 1 оыйсгеп пеигопошусп ш Кошргезй
зу3па1ош, Когргаша ‹1о1‹тогз1<а.— Шахяаша: Ротесппйсашахвгашзка, 1999.

93. Мадаг 8. А ‘(Ьеогу Тот тиШгезошйоп зйгпа! бесотрозййоп: 111: ‘Мы/ей!
гергезетайоп // КЕЕЕ Тгапз. РАМП, 1989. - Уо1. 11. - Рр. 674-693.

Литташа 335

94. Магбпег: М, Бег/ссуда}: Ы, Зсйидеп К “Меигай-Ёаз” пеМОгК Тог ‘ест’ Чиапйгайоп апд
115 аррйсайоп 10 йше зейев ргесйсйоп // Тгапз. Ыеига! ЫеМогКз, 1993.- УоП. 4. -
Рр. 558-569.

95. Магциагдг В. Ап а13ог1111т Рог 1еаз$ зсдиагез езгйшёйоп оГ попйпеаг рагахпетегз,
З1АМ, 1963. - Рр. 431—442.

96. Мавгегз Т Ргасйса! пеига! пешогк гесйрез йп С++. - Вовгоп: Асадепйс Ргезз, 1993.

97. Магвиодга К Ыойве йцйесйоп 11110 йпригз йп ЬасК-ргоравайоп 1еап11пБ // КЕЕЕ Тгапз.
‹ ъ оп Зузтетв, Мап, апб СуЬегпегйсз, 1992. — Уо1.22. — Рр. 436-440.

98. МсСиНосЬ ш 8, Ртз ш Н. А 1о3йса1 са1си1из оГ Шеаз Еттапеп! йп пегчоиз асйчйту
// Ви11. МагЬ. Вйорпузйсв, 1943. — Уо1. 5. - Рр. 115-119.

99. Мейгагга К, Мо11ап С., Кап/ш 8. Воипдв оп (Не питЬег оГ ватр1ез пеебес! Гог пеига1
1еап11п3// ПЕЕЕ Тгапз. Неига! ЫешюгКз, 1991. - Уо1. 2. - Рр. 548-558.
б:

\00.М1с11е1 А.‚ Рагге! ‚1 Аззосйайче шешогйез чйа агййсйа! пеша! пешюгКв // 1ЕЕЕ
Сопгго! Зузгет Магагйпе, 14990, АргП. - Рр. 6-16.

101. М1пз19/ М, Рарегг 51 Регсерггопз: ап йпггодисгйоп го ротршайопа! деотеггу. -
СатЬгйбде, МА, 1988. 7*“

102. М011ег М Е А вса1е6 софигаге уадйеп! ащогйшш Рог Газ! зирегчйзес! 1еап11п3
// Ыеига11ЧеМогКз‚ 1993. - УоП. 6. - Рр. 525-533.

ч 103. Мооду Г 1, Ваг/сеп СЩ Раз! |еап11п3 йп пегч/огкз о! 1оса1|у шпед ргосеззйп;
ипйз // Ыеига1Сотри1айоп‚ 1989. - Уо1. 1. - Рр. 151-160.

“104. Мозгсгупйс! Ь. Пшабу аёартасурхе ш хазгозошапйи до верагасй зугпайуш
Ыекггусгпусй: Ргаса доктогзка. - Щагвгаша: РоШесЬпЖа Ч/агщашвка, 1995.

105. Моидеог М, Агепсоп К, Апёепйо! В. [шаге сотргеззйоп МН) Ьаскргорадайоп:
йтргочетеп! оГ гЬе чйзиа! гезюгайоп изйпд бййегепг сов! Гипсйопз // Ыеига!
Нет/ста, 1991. - Уо1. 4. - Рр. 467-476.

106. Могег‘ М, $то1епз1су В $Ке1еюп12айоп - а гесЬпйцие Гог Ыттйп; Нас Та! Ргот
а пешюгк чйа геПеУапое аззеввшеп: // Адчапсев Еп ЪПРЗ! / Её. В. Тоигегхку. —
Зап Матео: Могдап Каийпалп, 1989. - Рр. 107-115.

107.1\’агет1га К 8., Рапйавагагйу К [бепййсагйоп апб сотго! оГ бупахпйса! зузгетз
изйпг пеига! пешогкз // !ЕЕЕ Тгапв. Ыеига! Ыешогкз, 1990. - УоП. 1. - Рр. 4-27.

108. ШЮОО гесадпйгйоп ассе1егагог ат! дата зйее! (2рр), 11109906. Ргочйдепсе: Ыезгог 1пс.‚
1994.

109. ЪШООО с1ече1ортеп1 вувгетп, дата зйеет (2рр), КЮ9906. - Ргочйёепсе: Ыезгог 1пс., 1994.

110. 010 Е. Зйтрййед пеигоп тобе! аз а ргйпсйра! сошропепт апа1у2ег // 1. Май).
В101о3у, 1982. - Уо1. 15. - Рр. 267-273.

111. 0111 Е. Ргйпсйра! сошропепгв, тйпог сотропептз апб Нпеаг пеига! пеш/огкз
// Маша! ЫеМогКз, 1992. - Чо! 5. - Рр. 927-935.

1 12. (На Е ., Одаша Н, шапдпйшапапа 1 Ьеахпйпг йп попйпеаг сопзчайпеб ЬеЬЫап пеМОгКз
// Ргос. КСАЫЫ-И, Езроо, Р1п1ап6, 1991. - Рр. 385-390.

113. Озошз/сй ЬЁ Зйесй пешопоше. — Ч/агзгаша: Обсупа Ч/убашпйсза РЩ 1994.

114. ОзошзН 51 Зйесй пешопоше ш и]ес1и ащогуппйсгпут. — Щагзгаша: “ШТ, 1996.

336 ' Литшащш

‘ 115. ОзашзН 5. Зйдпа! По“; дгарЬз апб пейгаТ петогКз // Вйоюцйса! СуЬсгпейсз, 1994.
хы. 70. — Рр. 387-395.

116. ОзошзН 8. Ыеига! пеМогК арргоасЬ го Нас 501111101: оГ Н-пеаг сотрйътепгахйу ргоЫетз
// 1:11. Лоигпа! оТ Ыитейса! Мобепйпг, Е|ес$г0п1с ЫеМогКз, Вечйсез апб Рйе1с1з‚

1995. — ‘ы з. — Рр. 431 — 445

117. Овашзд! 5‘. Мипйауег ЧоИегга Штег апд "йз аррйсайопз // Меига! Сотрнйп; ат!
Аррйсайопз, 1996. - Чо1. 4. - Рр. 228-236. ’

118. ОвошзН 8., Вгийгешз/сб К. ТЬе ЬуЬгШ пеига! пешойс Тот газ апа1увйв шеазигйпг
зузтеш // 1МТС99, Уепйсе, 1999. - Рр. 440-445

119. ОвошзН 8., СЕсйосН А. Ьеапйп; йп бупапйс пеига! петофз изйпг вйдпа! По“:
3гар11з// 1п1. „Чошпа! оТ Сйгсий ТЬеогу апд Арр11са11опв,1999. - Уо1. 27. - Рр. 209-228.

ч

120. Овошзд! 8, НегаиЛ ‚Л Зйдпа! Бош уарЬз аз ап еРйсйеп! $001 Рог дгадйеш ат!
Ьеззйап дегеппйпагйоп // Согпр1ех Зузтетз, 1995. - Чо1. 9 . - Рр. 29-45.

121. Озошздй 8., Негаи!‘ ‚Д, Ветатпез В РаиК 1осайоп йп апа103ие сйгсийз изйп;
КоРюпеп пеига! пеМогК // ВиПейп Асадетйе Ро1опа1зе, 1995. - Уо1. 43, Ыо 1. -
Рр. 111-123.

122. Озошзй! 8., МаЛсошзИ А.‚ СЕсИосН А. КоЬизт РСА пеига! пстчогкз Рог гапбот
пойзе гебисйоп оГ тЬе дата // 1977 м. СопЕ оп Асоизйс, $реес11 ат! Зйдхта!
Ргосезвйпё. - Мипйсп, 1997. - Рр. 3397-3400.

_123. ОзошзН 8., Зйше/с К. Зшду о!‘ 3епега1й1а11оп аЬШту оГ пеига! петшогКз // Ш
КопТегепфа “Зйесй Ыещопоше й ЁсЬ газювошапйа”. Ки1е, 1997.

124. Озошзй! 8., Зйше/с К. Зейогдапйхйп; пепла! пеМОгКв (‘от зРюп гепп 10:16
Тогесазйпг йп рошег вузгетп // Епдйхаеегшг Аррйсайопз оГ Ыеига! Мешогкз (ЕАЫМ),
СйЬгаИаг, 1998. - Рр. 253-256.

‹ 125. Овашвт 51, ЗМе/с К Зейогдапшпг пеига! пешогК Тот Гаи1г 1осайоп йп е1ес1г1са1
сйгсийз // ЮЕСЗ, ЬйззаЬоц 1998. - Рр. 265-268.

126. ОзошзН 8, ЗгодоЫсЁ М. Вфагсга/с В Раз! зесопб огбег Ьатйпг ащогййпп Гот
ТеедГогч/агб ши1й1ауег пеша! петойсз апб йгз аррйсайопз // Ыеига! Ыешогкз,

1996. - Уо1. 9. - Рр. 1583-1596

127. ОвошвН 51, Тгап Ноа! Ь. Кейигепсурха зйес пешопоша ЕПшапа ‘к изтозошапйи
до ргоЫетош ргебуксй // ХХ ЗРЕТО, Пзггоп, 1997. Рр. 505-510.

‘128. Овоигзйй 8., Пап Ноа! Ь. ТЬе пешобшгу пеМогК Гог ЗРРГОХЙПЯЙОН // ККТОШЕ,
Рохпап, 1998. Рр. 607-612.

129. Рао Х Н Абарйче рацет гесогпййоп апб пеша! пегч/огкз — Кеадйпг: Абйвоп
Щеыеу, 1989.

130. Р1ап ‚Л А гезошсе-апосайп; пешогк Тот йдпсйоп 1пСегр01ай0п// Маша! Сотрщайоп,
1991. - Уо1. 3. - Рр 213-225.

131. РошеП М „С ТЬе ТЬеогу оГ габйа! Ьавйз Еипсйопз арргохйтайоп ЛАЩ/апсез
йп Ыцтейса! Апа1уз1в. Уо1. П, ‘мамы, Зиыйчйзйоп ащогйштв апд гасйа! Ьавйз
йшсйопз // Её. Ш. А. ЦЁШ / ОхГогб: ОхГогд Ппйчегзйу Ргевв, 1992. - Рр. 105-210.

  то ‚_ д . _‚__„‚ 337

132.
133.
‘ 134.

135.
136.

137.
138.

139.
140.
141.
142.

143.

— 144.

ьЁЁх
145.

146

147.

148.

149.

1 150.

км к. Ршпйп; ащотьшз — а зипеу // швв тгапздчешат ПетогКз, 1993. — ‘м. 4. —
Рр. 140-141.

Кдедттег М, Вгаип Н КРКОР — Ъ Газт адарйче 1сапйп; ащогйшш. Тесйпйса!
Кероп, Каг1зшЬег Ппйчегзйгу Кайзпше, 1992.

Кте’ Н, ЗсИиИеп К. Оп Ше вгайопагу зФаФёЧЁГ 111: КоЬапеп веН-огдапйгйп;
зепзогу таррйп; // В1о1о31са1 СуЬежтхегйсз. 1986. - Уо1. 54. - Рр. 234-249.

КозепЫап Е Ргйпсйр1е оГ пещодупазпйсв. — ИХ: Зрапап, 1992.

Китетаг: 1). Е., Ндтоп О. Е., таит: К. ‚Л Ьеагпйп; йщегпа! гергеветайопв
Ьу еггог ргора3а110п//Рага11е1 (Бвггйьщед ргосевзйпг: Ехр1огайапз 111 (Не Мйсгозтлсшгез
оГ Содпййоп / 1). Е. Китешап, 1. Ь. МсСПеПапф (Еда). Сашьгйбце: МКТ Ргезз,
1986. - Уо1. 1.

Кид}: Ш Мопйпеах Зувтепзз: а Чопепа арргоасЬ. — ИХ: 1. Норкйпз Ргезв, 1981.

Кийсошзйа 0., Ртпзй! М, Кш/соиыс! Ь. Зйесй пеигопоше, ащогуппу депегусшс
1 вувтету гошяуте. — Щаглаша: РЧЧЫ, 1997.

Кгезйошзт В. Ыеигопоше тетоёу Кшаптугасй шектогоше] ‘к газтозошапйи до Котргезй
оьгагуш: Когргаша бощогзка. - Шагзгаша: РоШесЬпЖа Шахяашзш, 1995.

Заттоп ‚1 А попйпеаг таррйпг Тот дата вггисшге апа1увйв // 1ЕЕЕ Типа.
Сотрщегз, 1969. - Уо1. 18. - Рр. 401-409.

$ап3ег Т В. Орйта! ипзирегчйзед |еагпйп3 йп зйпфе Пауег Ипеаг ГеебГоппеб
пецга! пешогК // Ыеига! Ыегшогкз, 1989. - Уо1. 2. — Рр. 459—473

зеупошш Т Зсгопг сочагйапсе шйтЬ поп1йпег1у йтегасгйпд псигопз // Лош: Мат.
В1о1о3у, 1977. - Уо1. 4. — Рр. 385-389.

ВеЗЕегю В. Аддйп; а сопвсйепсе го сотреййче 1еап11п3 // Меига! Ыешогкз, 1988. -
\/о1. %1. - Рр. 117-124.

Змей: К. 1тр\ешеп!ас]а Котритегоша ‘нуЬгапусЬ ащогуппоч’ исгасусй й аршсасуухусй
зйесй затооггапйщцасус!) зйе Копопепа. Ргаса дур1ошоша. — Щагзхаша: РоШесЬпйКа
Ч/агзшшзка, 1995.

8/саг1зе1с ш методу гергегепгасй оЬгагош суйошусЬ. — “щита: АКабешйсКа Ойсухш
Щудашпйсга, 1993.

Ысопесщу 8. С1аэвйса1 апб пеига! тейхоёз оГ йшаге (Шейпд: Ргаса бокгогзКа.
Ч/шъаша: РоШесЬпЕКа Шагзшшзка, 1994.

$рес1апапп Н, 77ю1е Е, Ваддап М, Козепйе! Ж Соргосеззогз Тот вресйа! пеша!
петофз: КОКОЗ апб КОВОЫ) // ЖЕЕЕ Ргос. КСЪШ, Ог1ап6о, 1994.

Зрес/стапп Н, Т/ю1е Е, Каветте! Ш СОКОЗ: а соргооеззсг Рог КоЬопеп зе1Т
оггапйийп; шар // 1САЪЩ-93, Ашзтегбалп, 1993. - Рр‚ 1040-1044.

Зирпёешвй! Х Еазгозошапйе ащогуппош гепегусшус!) до гепегасй зггикшг зйесй
пешопошусЬ рдпокйегипкошусй: Когргаша ФоКтогзКа. — Ж/агзгаша: РоШесЬпЯКа
Ж/агзшшзка, 1997.

Зипоп К. 8. Тетрога! сгедй аззйдтптепг Ей гсйпгогсетеп! 1еагп1п3. РЬ. В. (Ивэеп. -
МА: Ппйх’. Мазз., 1984.

338 Литташша

151.

152.

153.

154.

гёч. _

155.

156.

157.

’ 158.

159.

160.

161.

162.

163.

164.

165.

166.

г 167.

168.

Зшгег С. Ыеига! петогКз Гог зйдпа! ргосеззйпд: РЬВАйззеп. - ЬупгЬу, ТШ):
Е1ес1гоп1с$ Шзтйите, 1994.

Тайеизйешйсг К. Зйесй пешопоше. -› Штанга: Акадетйока Ойсупа Ч/уёашпйсха,
1993.

Та1га3Е 71, Зидепо М Рииу Юетййсайоп оТ зувгетз апд йз аррНсайоп 10
тоёейпд апб сохшо! // !ЕЕЕ Тгапз. ЗМС, 1985. - Рр. 116-132.

Тагаззеп/со 1... КоЬепз З. Зиреп/йвед ат! ипзирегчйзес! 1еагпйп3 йп гасйа!
Ьазйз Шпсйоп Ыазвййегз // КЕЕЕ Ргос. Уйв. Впаге Зйдпа! Ргосеза, 1994. - Уо1. 141. - Рр.
210-216.

Тттт 6., Р1ез1ег Е. Мечта! пена/ШК йпййайъайоп // Ргот Пашка! 10 Апййсйа!
Ыеига! Сошригайоп / Еда. 1. Мйга, Р. Запбочщ. - Ма1а3а: Ш/АЫЫ, 1995. - Рр. 533-542.

Тгап Ноай Ь. Зйесй пеигопоше геКщепсЩпе - дгабйепгоше ащогуппу исгасе й
газгозошапйа ш Шепгуйкасй пйейпйошусЬ оЫеКтош бупатйсшусЬ. Ргаса бур1отоша. -
‘Щагзгаша: РоШесЬпЕКа Ч/ахзгашзка, 1997.

Изрпй/с И М Рг1псйр1е оГ гйвк тйпйтйгагйоп (‘от 1еагп1п3 Шеогу // Адчапсев
йп Ы1Р84 / Едз. 1. Мообу, 8. Напзоп, К. Црртапп. - Зап Магео: Могдап Каийпапп,
1992. - Рр. 831-838.

Уарпйс И М, СИеггопеп/сда А. Оп т: ипйГопп сопчеггепсе о!‘ ге1айче
йециепсйез оГ ечешз то Шейг ргоЬаЬйНйез // ТЬеогу оГ РгоЬаЬйБту апд йз Аррйсайопз,
1971. — Уо1. 16. - Рр. 264-280.

ИМ: А.С., Но1тев О. А шодййеа цийскргор ащогййпп // Меига! Сотригайоп,
1991. - УоП. 3. - Рр. 310-311.

Юдзгиддеп 118., ВаЬизКа К. Сопэггисйп; Ециу шо6е15 Ьу ргобпс! зрасе сшзгегйп;
// Рнггу тебе! Шепййсатйоп / Едз. Н. НеПехЮот, 1). Вгйахжох‘. — Вегйп: Зргйпгег,
1998. - Рр. 53-90.

РУапд Ь. Х Абарйче Тину зувгетв апд сопгго1. Вевйдп апд вгаЬййгу апа1уз1з.
Меч’ 1егзеу: Ргепйсе На“, 1994.

т”; Х Е. Ст: 1, Митдап 1 Оп ти1йр1е ггайхйп; Тот ВАМ // !ЕЕЕ Тгапз.
Ыеша! ЫеМогКв, 1990. - Уо1. 1. - Рр. 275-276.

РУапд Х Е, Сгиг 1, Митдап ‚1 Тшо содйпг зпатеёйез Ток Ьйдйгессйопа!
аззосйатйче тетогу // [ЕЕЕ Тгапз.Ыеига1Ыетшог\‹з‚ 1990. - Уо}. 1. - Рр. 81-92.

РУапд Ш ‚Д, Ьее В. Ь. А тобйбед Ьйдйгесйопа! ёесодйп; зтгатегу Ьазеб оп ВАМ
зшшстше // ПЗЕЕ Тгапз. Ыеига1ЫешогКз‚ 1993. - Уо|. 4. - Рр. 710-717.

Мне! Ь. Е, Ватап! ЕЁ Ачойбйпг Та1зе 1оса1 шйпйта Ьу ргорег йпййайгайоп о!‘
соппесйопз // КЕЕЕ Тгапв. Ыеща1 Ыешогйз, 1992. - Уо1. 3. - Рр. 899-905.

РУеутаеге М, Мапеп: 11% Оп гЬе йпйсйайгайоп ат! орйтйиатйоп о! ггш1й1ауег
регсергйоп // 1ЕЕЕ Тгапз. Ыеша! ЫешогКз, 1994. - Уо1. 5. — Рр. 738-751.

Идти’ В., Но] М Адарйче зшйсъйп; сйгсийз // Ргос. ЖЕ ЩЕЗСОЫ Сопчепгйоп
Кесогб, 1960. - Рр. 107415.

Идти’ В., Мтег 12., Вахге’ К. Ьауегед пеига! пегз Тот рацегп гесодпййоп
// КЕЕЕ Тгапз. АЗЗР, 1988. - Уо1. 36. - Рр. 1109-1118.

 

169. Идти’ В., ВЛеНо М Ыопйпеаг абарйче зйдпа! ргосевзйп; Тог йпчегзе сошго!
// Ргос. ‘ШогШ Сопггезв оп Ыеига! ЫеМогКв, Зап Шего 1994.

170. тйгои’ В., Згеагт‘ 51 Адарйче зйдпа! ргосевзйпг. - ЫЖ: Ргепйсе На11, 1985. 171.
“йеггыскй А., Рйпбейзеп 97., Зхутапошзкй 1. Теогйа 1 шеюбу оыйсхепйоше
ортутайгасй. —- Шагззаша: “ШТ, 1977. —›

171. штат К, Зйрзег В. А |еагт1п3 ащогтпп Рог сопйпиаПу шгшйп; бЩу гесигеп‘ пецга! ’

петогКз. - Ыеига! Сотрщегз, 1989. - Уо1. 1. - Рр. 270-280.

172. Мтатз К, Зфзег 1). А 1еагпЁх3 ащогййът Тот сопйпиаПу ппшйп; йяпу гесигепг
пеша! пешогКз // Ыеша! Сотршегз, 1989. - Уо1. 1. - Рр. 270480.

173. Хие 9., Ни Х, Тотртпв Ш Ааыузйз оТ Ьйддеп ипйз оГ ЬасК ргорагайоп шоде!
Ьу $\’1)// Ргос. ПСЫМ, 1990, Шазыпгтоп. - Рр. 1739—742.

174. Уаде’ В., Рйеч В. Робэтамгу то6е1ошап1а 1 зтегошапйа гошхутего. — Щагзиша:
“ШТ, 1995. =

175. Уай‘ Е., Зедег К, Оегзйо А. Сотреййче 1еап1йп3 апб вой сотреййоп Рог чесгог
циапйгег девйдп // ПЕЕЕ Тгапв. 8й3па1Ргосеззйп3‚ 1992. - Уо1. 40. - Рр. 294—309‚

176. УатаКаша Г А Ги22у йпгегГегепсе епгйпе {п попйпеаг апа103 таде ат! Из
аррйсайоп 10 Шггу 1о81с сопггр! // 1ЕЕЕ Тгапз. Ыеига! Ыегшогкв, 1993. - УоП. 4. —
Рр. 496-522.

177. Уисеег‘ С., ОЛаге’ К. А гогайоп, зсайпг ашй ггапз|айоп йпчагйап! рацепл
Ыазвййсайоп вув1ет// Рапет Кесодтййоп, 1993. - Уо|. 26. - Рр. 687-710.

178. Задей ДА. ТЬе сопсерг оГ 11113и1вг1с чайаЫе апб 115 аррйсайоп ю арргохйтате
геазопйпг. Рап 1-3 // КпГоппайоп Зсйепсез, 1975. - Рр. 199——249.

179. 2ш1е11 ДА. Рииу зегз // [Моппайоп апд Сопгго1, 1965. - Рр. 338—353.

180. 2е11 А. $йши1а11оп Ыеигопа! Ыетге. — Ашзтегдалп: Аббйвоп шез1еу, 1994.

181. 2211 А. ЗЫЫЗ - Зшпгап Ыеига! Ыеш/огк Зйтщагог. Пзет тапиа1, Зшпгагг, 1993.
182. Здттегтапп Н 1 Рииу зе! Шеогу апд 1:5 аррйсасйопв. — Возтоп: Юишег, 1985.

183. ИиЬеп Е, Непо МА. Ехр1ог1п3 Нас попйпеаг бупатйс Ьейачйоиг о!‘ агййсйа!
пеига! пешогкз // {ЕЕЕ Вгос. КСЫЫ, Ойапбо, 1994. — Рр. 1000-1005.

184. 2а/с 8., Нрайвйпд И, Йид 8. $о1ч1п3 Нпеаг ргощшптйп; ргоЫетз МЕЬ пеига!
пешогкз: а сотрагайче вшбу ‚// КЕЕЕ Тгапз. Ыеша! пешогкв, 1995. - Уо1. 6.
-Рр. 94-104.

185. Зшада ‚Д, ВагзН М, Цедгис}: РИБгшсгпе зйесй пеигопоше. — Щагзшаша: РШЫ, 1997.

Предметный указатель

Агрегирование 288
Аксон 17 '

Алгоритм

— Видроу 33

- Вильямса-Зипсера 221

- Г аусса-Ньютона 67

- генетический 81

- гибридный 144, 304
-градиентннй 60
-Густафсона-Кесселя 313

— Даркена-Муди 141

- естественного граднекга 276
- имитации огжига 78

- Кардоссо 276

— Кохонена 233

— Левенберга-Марквардта 65
- Линде-Бузо-Грея 139

- наискорейшего спуска 62

— нейронного газа 233

- обратного распространения

ошибки 51, 146

- ортогонализахши Грзма-ШМИдта 152
- переменной метрики 63

- пикового группирования 310
- разностного хруппирования 312
- самоорганизации 308

- сопряженных градиентов 67
- Херольта-Джуггена 270

- Чихотскою 272, 276

- Эльмана 212

— ВРОЗ 64

- С-теапз 308

- СШТА 232

- ВРР 64

- К-теапз 139

- Оийснргор 71, 160

- КРКОР 73

- ШТА 184, 232

Алнроксимацй!
- глобальная 129

-локальная 129 ‚
Аесоциатнвносгь 282

Ассоциация 23

Вектор направления 61

Восстановление Сзммона 241

Выбор центров
- вероятностннй 142
- на основе самоорганизации 139

- случайный 139

Гесснаи 61, 64
Гнперплосюсгь 47

ГМ’
- поюкоанй сигналов 55
- еопряженннй 55, 147

Группнрование данных 310, 312

Дендритьх 17
Дефуззифнкатор 28, 293

Дефуззифнкация
- относительно среднего центра 293

- относительно центра области 293

Днафония 180
Дистрибутивность 282

Емкосгь ассоциагивной памяти 180

Идентификация объекта 121, 221

Инпариантносгь относительно
- количества выборок 112

- угла поворота 112

- смещения 1 11

- масштаба 112

лепнина?

Инициализация весов 86

Кардииальиое число 280
Квантование векториое 231

Классификатор
- векторный 35
- нейронный 110, 114

Кластер 139, 327

Кодирование двоичиое 82
Колатералы 17

Компрессия данных 116, 242, 267
Коммутативность 282
Контекстный слой 210

Коэффициент
- асимметрии 99
- тюмпрессии 119, 243

- обучения 52

— - адаптивный 68
- - постоянный 68

- - с направленной мииимиэацией 69

- принадлежности 279
- сопряжения 67
— РЗЫК 243, 267

Лингвистическая переменная 279

Мадалайн 33

Матрица
— авюкорреляции 259
- корреляции 43

Мера

- Егера 283’

- Коско 284

- нечеткости 283
— расстояния 228
- знтропийная 284
- УСдЕт 94

Метод
-проекций 181
-А-проекций 181
-Хе6ба 179

—ОВП 99
-ОВ$ 100

Методы звристические 71
Механизм утомления 230

Модель

- адалайн 32

- инстар 34

- МакКшшотш-Пнтса 20
- Мамдани-Заде 294
-оутстар 37

- персептронная 22
- сигмоидальная 27
- стохастическая 44
- Хебба 21

- ТЗК 295

- ШТА 37

Мутация 82, 84
МАХЫЕТ 184

Независимость статистическая 268

Нейромедиатор 17
Нейроны мертвые 40

Нечеткое множество 279

нормализация
- векторов 229
- множества 282

Носитель 280

Область Вороного 139
Обобщение 24,92

Обучение
- без учителя 25

-оилайн 51

- оффлайн 52

- с учетом момента 30, 63
- с учителем 25
- с забыванием 41

Окресптость 227

Операшп
- концентрации 282

341

3342‘ _ ‚ ‚рад, Предметный ЁЕ‘ ель

- отрицания 281 Программа

- произведения 282 — 55 274

- растяжения 282 ' Сддсд’ 162

— суммирования 281 ‘Н/йе’ 182
—Ко11оп 232

Оптимизация глобальная 75 __1уе„едс;‚ 71

Ортогонализация Грэма-Шмицга 152 “КШР 205
-КТКЫ 221

Отрицание множества 281
Произведение логическое 281

Ошибочное решение 182

Равенство множеств 282

Память

_ автоассоциативная 178 Расстояние Хемминга 177
- ассоциатнвная 177 Режим

- гетероассоциативная 177, 185 - обучения 179, 180

Переобучение сети 97 — распознавания 182

персешрон 26 Ряд Теилора 60
Погрешность Самоорганизахшя нейронов 266
- квантования 231

- обобщения 94 Селекция 82

— обучения 94 Сеть нейронная 46

- МАРЕ 125, 255 - Вольтерри 163

- МЗЕ 118 — Ванга-Менделя 302

- гибридная 252

- корреляционная 257
Правила вьхвода 286 - многослойная 50

— иечеткая 299

‹— однонаправпенная 46

- однослойная 47

- персептронная 50

- радиальная НКВР 137

-— радиальная КВР 129, 132
-—рекуррентная 176

Популяция 82

Правило

-ВИдр0у—Хоффа 27

- Гроссберга 34, 37

— Коско 190

- - модифицированное 192
- Кохонена 227

' Ой” 264 - Фальмана 159
—ПеР°°П"1Р°"а 25 -Хемминга 184

— Сенгера 255 - Херольта-Джуггена 267, 269
— Х°55а 41 - Хехта-Нильсена 254
Преобразование “Ёопфшща 178
—Карьюнена-Леве 259 — льмана 210

-Фурье 111 ‘ВАМ 189

_ ЮА 267 - ЁАМ вёодифицированная 192

— А 2 7
РСА 117, 259 __РСА 259
Прогнозирование 23 _—КМ1_Р 200
— нагрузок 124, 249 — кткы 219

— числовой последовательной‘: 73 - ТЗК 299

Предметный Житель 343

Синапс 17 — Гаусса 134

Система - Гаусса обобщенная 291
— вывода 287, 295 — Лагранж“ 3“

- - Мамданн-Заде 287 ` "иювая 3 ю

_ _ 151; 295 — принадлежности 279

- приспособленности 82
- радиальная 129, 134
Сома 17 -сигмоидальная 27

Скрещиванис 82, 83

О

Стабильность ассоциативной  180 " ‘Юседства 233
— трапецендальная 292

— треугольная 292
— целевая 27, 47
- энергетическая сети 190, 257

Сумма логическая 281

Температура 79

Теорема Ковера 130

Теория Колмогорова 90 хромосома 82

Универсальный аппроксиматор 22 Чувтительность 55

Условия ДеЛуки-Термини 283 Шаг обучения 61

Фуззшфикаюр 287 290 Ядро Вольтерри 165,169

Функция
—акгивации 26 ЗУВ-разложение 263

Учебно-справочное издание

Станислав Осовский

ивйгонньпв свти
для овмвотки инфогмнции

Научный редактор Яд Еудинский

Е Заведующая редакцией Л.А. Табакоаа
Ведущий редактор дд Григорьева
Младший редактор НА. Федорова

Художественный редактор ЮИ Артюхов
Технический редактор ИВ. Завгородняя
Корректоры ГМ Колпакова, ГЁВ. Хлопцева
Компьютерная верстка ГС. Лееыкина
Художественное оформлегше 0.8. Толмачева

ИБ М’ 4464

Подписано в печать 20.06.2002. Формат 70х100/16
Печать офсетная. Гарнитура “Т1тез"
Усл.п.л. 27,95. Уч.-изд.л. 24,36
Тираж 3000 зкз. Заказ 2162. “С” 150

Издателъспо “Финансы и статистика"
101000, Москва, ул. Покровка, 7
Телефон (095) 925-35-02, факс (095) 925-09-57
Е-тай: пъай1@йпзг‚аг.ш 1тр://хч‘чш/йпзааг.ш

ГУП "Великолукская городская типография"
Комитета по средспзам массовой информации
Псковской области,

182100, Великие Луки, ул. Полиграфистов, 78/12
Тел/факс: (811-53) 3-62-95
Е-тай: УТ1.@МА11Т.1Ш

7 ’ нейронных сетей в различных сферах электроники

Об авторе
7 Сгпанислав Осовский—профессор ‚а. ‘ё

электротехнического факультета ` ‚„ 4
Политехнического университета (Польша, Варшава).- ‘ „‘‹›‚‘1.›г%}5‚

к Специализация научной работы '-‘методы компьютерного  
 ' анализа и оптимизации проектирования электрических 
‘ Ё систем, а также обработка сигналов методами т г  "   `

“‘1
‚м.

искусственного ‘интеллекта. у ‚
В течение ‘многих лет С. Осовский ведет исследования ‘  у

в области искусственных нейронных сетей. Эти исследованйя )‘‚‘-Ё‚—

охватывают алгоритмы обучения сетей и применения 7 7 А

ищифровой ‘обработки сигналов. у
„ 3Ё‘24 года научной деятельности С. Осовский
опубликовал свыше 160 научных работ в отечественных’

‹  и зарубежных изданиях; автор либо соавтор
‘ к Тгакадемических учебных пособий.

‚‚' `

|$ВМ 5-279-02567-4

9 785279 025671 >

 

` ‘

